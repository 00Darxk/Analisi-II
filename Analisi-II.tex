\documentclass{article}

\usepackage{cancel}
\usepackage{amsmath,amssymb}
\usepackage[includehead,nomarginpar]{geometry}
\usepackage{graphicx}
\usepackage{amsfonts} 
\usepackage{verbatim}
\usepackage{mathrsfs}  
\usepackage{lmodern}
\usepackage{braket}
\usepackage{bookmark}
\usepackage{fancyhdr}
\usepackage{romanbarpagenumber}
%\usepackage{minted}
%\usepackage{subfig}
\usepackage[italian]{babel}
\usepackage{float}
%\usepackage{wrapfig}
%\usepackage[export]{adjustbox}
\usepackage{contour}
\usepackage[normalem]{ulem}
\allowdisplaybreaks

\setlength{\headheight}{12.0pt}
\addtolength{\topmargin}{-12.0pt}
\graphicspath{ {./Immagini/} }

%% TODO add metadata
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    pdftitle={Appunti di Analisi II},
    pdfauthor={Giacomo Sturm},
    pdfsubject={Analisi II},
    pdfkeywords={}
}

\newsavebox{\tempbox} %{\raisebox{\dimexpr.5\ht\tempbox-.5\height\relax}}


\makeatother
%% Derivate:
\newcommand{\df}{\mathrm{d}}
\newcommand{\diff}[2]{\displaystyle\frac{\df{#1}}{\df{#2}}}
\newcommand{\diffn}[3]{\displaystyle\frac{\df^{#3}{#1}}{\df{#2}^{#3}}}
\newcommand{\pdiff}[2]{\displaystyle\frac{\partial{#1}{\partial{#2}}}}
\newcommand{\pdiffn}[3]{\displaystyle\frac{\partial^{#3}{#1}{\partial{#2}^{#3}}}}

%% Integrali:
\newcommand{\intab}[4]{\displaystyle\int_{#1}^{#2}{#3}\df{#4}}
\newcommand{\intinf}[2]{\intab{-\infty}{+\infty}{#1}{#2}}
\newcommand{\intpinf}[2]{\intab{0}{+\infty}{#1}{#2}}
\newcommand{\intninf}[2]{\intab{-\infty}{0}{#1}{#2}}

%% Sommatorie:
\newcommand{\sumab}[4]{\displaystyle\sum_{#4=#1}^{#2}{#4}}
\newcommand{\suminf}[2]{\sumab{-\infty}{+\infty}{1}{2}}
\newcommand{\sumpinf}[2]{\sumab{0}{+\infty}{1}{2}}
\newcommand{\sumninf}[2]{\sumab{-\infty}{0}{1}{2}}

\renewcommand{\contentsname}{Indice}
\numberwithin{equation}{subsection}
\newcommand{\tageq}{\tag{\stepcounter{equation}\theequation}}
\AtBeginDocument{%
    \renewcommand{\figurename}{Fig.}
}
\renewcommand{\ULdepth}{1.8pt}
\contourlength{0.6pt}
\newcommand{\myuline}[1]{%
    \uline{\phantom{#1}}%
    \llap{\contour{white}{#1}}%
}
\fancypagestyle{link}{\fancyhf{}\renewcommand{\headrulewidth}{0pt}\fancyfoot[C]{Sorgente del file \LaTeX ed ultima versione del testo disponibile al link: \url{https://github.com/00Darxk/Analisi-II/}}}

\begin{document}

\title{%
    \textbf{Analisi II}  \\ 
    \large Appunti delle Lezioni di Analisi II \\
    \textit{Anno Accademico: 2024/25}}
\author{\textit{Giacomo Sturm}}
\date{\textit{Dipartimento di Ingegneria Industriale, Elettronica e Meccanica \\
Università degli Studi ``Roma Tre"}} 

\maketitle
\thispagestyle{link}

\clearpage


\pagestyle{fancy}
\fancyhead{}\fancyfoot{}
\fancyhead[C]{\textit{Analisi II - Università degli Studi ``Roma Tre"}}
\fancyfoot[C]{\thepage}
\pagenumbering{Roman}

\tableofcontents

\clearpage
\pagenumbering{arabic}

\section{Serie Numerica}

%% TODO aggiungere commento a qualche sezione Si vuole approssimare funzioni come la somma di una serie parametriche rispetto ad una fattore $x$, che diventerà la variabile indipendente della funzione. Una funzione algebrica si può rappresentare come una certa serie, dimostrato nel caso di una serie telescopica e geometrica. Per serie di segno definitivamente positivo è possibile rappresentarle in forma esplicita, mentre per serie che non rispettano questa condizione, molto probabilmente non è possibile, quindi non è possibile ottenere una rappresentazione algebrica di queste. 

Una serie numerica $\{a_n\}$ è una \textit{particolare} successione numerica; 
è una particolare funzione che ha come dominio l'insieme dei numeri naturali $\mathbb{N}$ e come codominio un sottoinsieme $\mathbb{C}$ dell'asse dei numeri reali $\mathbb{R}$. 
\begin{equation}
    \{a_n\}:\mathbb{N}\rightarrow\mathbb{C}\in\mathbb{R}
\end{equation}

Quindi è di interesse studiare il comportamento della serie numerica quando la variabile indipendente $n$ tende all'infinito. Data una successione numerica, si interessa quindi:
\begin{equation}
    \lim_{n\to\infty}a_n
\end{equation}

Si generalizza nel limite di una funzione quando si sostituisce alla variabile $n$ una variabile indipendente reale $x\in\mathbb{R}$. 

Una successione può convergere ad un numero reale, può divergere positivamente o negativamente, in questi due casi è regolare, quindi ha un limite definito o indefinito. Altrimenti è possibile che il limite non esiste, quindi la sequenza non si stabilisce su nessun numero reale ed oscilla per $n$ tendente ad $\infty$. 

\begin{equation}
    \lim_{n\to\infty}a_n=\begin{cases}
        i\in\mathbb{R}\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{equation}

Si costruisce una serie numerica $\{s_n\}$, partendo da una sequenza nota $\{a_k\}$, si può costruire definendo per ogni valore $n$ il valore di $s_n$ tale sia pari alla somma dei primi $a_n$ elementi della sequenza:
\begin{equation}
    \forall n\in\mathbb{N}:\,
    s_n:=a_1+\cdots+a_n
\end{equation}

$s_n$ viene chiamata somma parziale della serie $\{s_n\}$ e viene definita con il seguente simbolo:
\begin{equation}
    s_n:=\displaystyle\sum_{k=1}^\infty a_k
\end{equation}
La serie numerica è la successione delle somme parziali che costruisce sulla successione $\{a_k\}$. 

Una serie numerica si dice convergente se il limite della successione delle somme parziali, costruite a partire dalla successione $a_k$, è pari ad un numero $s$:
\begin{equation}
    \{s_n\}: \mbox{converge se}\,\lim_{n\to\infty}s_n=s\in\mathbb{R}
\end{equation}

Si dice divergente se il limite della successione delle somme parziali tende ad infinito:
\begin{equation}
    \{s_n\}: \mbox{diverge se}\,\lim_{n\to\infty}s_n=\pm\infty
\end{equation}

Se converge o diverge la serie numerica si dice regolare, se invece studiando il comportamento delle somme parziali per $n\to\infty$, il limite della somma non è definito, quindi la serie si dice irregolare:
\begin{equation}
    \{s_n\}: \mbox{irregolare se}\,\lim_{n\to\infty}s_n=\nexists
\end{equation}

Studiare il comportamento della serie vuol dire studiare il comportamento delle somme parziali. La somma parziali si avrà sempre in forma aperta, se fosse possibile esprimere in forma chiusa la forma parziale, allora il limite è di facile calcolo. 

%% ESEMPIO

Considerando il seguente limite:
\begin{equation*}
    \lim_{n\to\infty}(1+2+\cdots+n)
\end{equation*}
Esiste una funzione per esprimere in forma chiusa questa funzione, dimostrabile per induzione:
\begin{equation*}
    \lim_{n\to\infty}\left(\displaystyle\frac{n(n+1)}{2}\right)=+\infty
\end{equation*}

Quindi è facile determinare che si tratta di una serie divergente ad infinito positivo. Questo passaggio non d'ora in avanti non sarà più possibile, basterà stabilire il carattere di una serie, senza sapere il valore a cui converga. Solo nel caso della serie telescopica e della serie geometrica sarà possibile determinare il valore della convergenza. 

\subsection{Serie Telescopica}

Il caso più rappresentativo di una serie telescopica è la seguente:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k(k+1)}
\end{equation}

Analizzando la somma parziale $s_n$ fino ad un certo valore $n\in\mathbb{N}$ si ha:
\begin{gather*}
    s_n=\displaystyle\sum_{k=1}^n\frac{1}{k(k+1)}=\frac{1}{2}+\cdots+\frac{1}{n(n+1)}
\end{gather*} 

Utilizzando la tecnica dei fratti semplici si può riscrivere la somma parziale come:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k(k+1)}=\sum_{k=1}^\infty\left(\frac{1}{k}-\frac{1}{k+1}\right)
\end{gather*}

In questo modo calcolando la somma parziale si ottiene:
\begin{gather*}
    s_n=\displaystyle\sum_{k=1}^n\left(\frac{1}{k}-\frac{1}{k+1}\right)\\
    \left({1}-\frac{1}{2}\right)+
    \left(\frac{1}{2}-\frac{1}{3}\right)+
    \left(\frac{1}{3}-\frac{1}{4}\right)+
    \cdots+
    \left(\frac{1}{n-1}-\frac{1}{n}\right)+
    \left(\frac{1}{n}-\frac{1}{n+1}\right)
\end{gather*}
Si può notare come l'addendo 1/2 si cancella con l'addendo della differenza successiva, così con 1/3, così per ogni valore della sommatoria, permettendo quindi di scrivere la somma parziale $s_n$ in forma chiusa esprimendo solamente il primo addendo e l'ultimo addendo:
\begin{gather*}
    \left({1}-\cancel{\frac{1}{2}}\right)+
    \left(\cancel{\frac{1}{2}}-\bcancel{\frac{1}{3}}\right)+
    \left(\bcancel{\frac{1}{3}}-\cancel{\frac{1}{4}}\right)+
    \cdots+
    \left(\bcancel{\frac{1}{n-1}}-\cancel{\frac{1}{n}}\right)+
    \left(\cancel{\frac{1}{n}}-\frac{1}{n+1}\right)=
    1-\frac{1}{n+1}
\end{gather*}

Considerando il limite di questa serie si ha:
\begin{equation*}
    \lim_{n\to\infty}\left(1-\displaystyle\frac{1}{n+1}\right)=1
\end{equation*}

In generale una serie telescopica, ha i suoi termini $a_k$ definiti come la differenza tra il termine $k+1$-esimo ed il termine $k$-esimo di una particolare successione $\{A_k\}$:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty a_k=\sum_{k=1}^\infty\left(A_{k+1}-A_{k}\right)
\end{equation*} 

\subsection{Serie Geometrica}

La serie geometrica è esprimibile come:
\begin{equation*}
    \displaystyle\sum_{k=0}^\infty x^k
\end{equation*}
Come altre serie dipende da un parametro reale $x\in\mathbb{R}$, questo si chiama ragione della serie. 

Si costruisce la somma parziale della serie:
\begin{equation*}
    s_n=\displaystyle\sum_{k=0}^n x^k=1+x+x^2+\cdots+x^n    
\end{equation*}
Si vuole esprimere questa somma in forma chiusa. Per $x=0$, per ogni valore di $n$, la somma vale sempre $1$, poiché:
\begin{gather*}
    \forall n\in\mathbb{N}: s_n=0^0+0^1+0^2+\cdots+0^n=1
\end{gather*}

Un altro caso analogo con $x=1$, si ha la seguente somma parziale:
\begin{gather*}
    \forall n\in\mathbb{N}: s_n=1+1+1+\cdots+1=1\cdot n
\end{gather*}

Questa serie quindi converge per $x=0$, diverge per $x=1$, mentre per altri valori reali non è ancora noto il suo comportamento. 
Si considera ora il caso generale con una ragione diversa da zero e da uno $\forall x\in\mathbb{R}\setminus\{0,1\}$. 
Si considera noto il valore $s_n$:
\begin{equation*}
    s_n=\displaystyle\sum_{k=0}^n x^k=1+x+x^2+\cdots+x^n    
\end{equation*}
Si moltiplica la somma parziale per la ragione e si sottrae alla somma parziale:
\begin{gather*}
    xs_n=x\cdot\displaystyle\sum_{k=0}^n x^k=\sum_{k=1}^nx^k\\
    (1-x)s_n=1+x+x^2+\cdots+x^n-\left(x+x^2+x^3+\cdots+x^n+x^{n+1}\right)=1-x^{n+1}
\end{gather*}

Della prima somma sopravvive solamente il primo addendo $1$, e della seconda l'ultimo addendo $x^{n+1}$, tutti gli altri si cancellano a vicenda, quindi per ottenere il valore della somma parziale si divide il primo ed il secondo membro per il fattore $1-x$:
\begin{equation}
    s_n=\displaystyle\frac{1-x^{n+1}}{1-x}
\end{equation}
Si provvede ora a calcolare il limite di questa somma parziale, dividendolo per la proprietà di linearità, supponendo che questi due limiti risultanti non corrispondono ad una forma indeterminata:
\begin{equation*}
    \lim_{n\to\infty}\displaystyle\frac{1-x^{n+1}}{1-x}=\lim_{n\to\infty}\frac{1}{1-x}-\lim_{n\to\infty}\frac{x^{n+1}}{1-x}
\end{equation*}
Il primo fattore non dipende da $n$, per il limite corrisponde a sé stesso, in seguito si mette in evidenza il fattore $1-x$ ottenendo:
\begin{equation*}
    \displaystyle\frac{1}{1-x}\left(1-\lim_{n\to\infty}x^{n+1}\right)
\end{equation*}
Il comportamento di questo limite dipende dalla ragione:
\begin{gather*}
    \lim_{n\to\infty}x^{n+1}=\begin{cases}
        0 &-1<x<1\\
        +\infty  & x>1\\
        \nexists & x\leq-1
    \end{cases}
\end{gather*}
Per $|x|<1$ la funzione è decrescente, e tende a zero, mentre per $x>1$, la funzione è esponenziale e quindi tende ad infinito. Invece per $x<-1$ si considera il limite, mettendo in evidenza il segno negativo:
\begin{gather*}
    \lim_{n\to\infty}(-|x|)^{n+1}=
    \lim_{n\to\infty}\left[(-1)^{n+1}\cdot |x|^{n+1}\right]
\end{gather*}
Il secondo fattore diverge, mentre il primo fattore oscilla di segno in base alla parità di $n$, per cui questa funzione oscilla di ampiezza sempre maggiore, per cui è irregolare. 
Per $x=-1$ il secondo fattore vale uno, mentre il primo fattore si considera comunque, per cui continua ad oscillare alla stessa ampiezza, quindi rappresenta allo stesso modo un comportamento irregolare. 

Noto il comportamento di questo limite allora il valore della serie geometrica in base alla ragione è dato da:
\begin{equation*}
    \displaystyle\sum_{k=0}^\infty=\begin{cases}
        \displaystyle\frac{\strut 1}{\strut 1-x} &-1<x<1\\
        +\infty & x\geq1\\
        \nexists & x\leq-1
    \end{cases}
\end{equation*}

Questa serie ha un addendo in più poiché parte da $k=0$, per cui esprimendola come una serie partendo da $k=1$:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty=\displaystyle\sum_{k=0}^\infty-1
\end{equation*}
Il valore di questa successione quindi si comporta analogamente al precedente, considerando l'addendo in più:

\begin{equation*}
    \displaystyle\sum_{k=1}^\infty=\begin{cases}
        \displaystyle\frac{\strut 1}{\strut 1-x}-1 &-1<x<1\\
        +\infty & x\geq1\\
        \nexists & x\leq-1
    \end{cases}
\end{equation*}

\subsection{Criteri di Convergenza}

Esistono vari criteri per determinare la convergenza di una serie numerica. 

%% PRIMO CRITERIO

Il primo criterio definisce una condizione necessaria per la convergenza di una serie geometrica. 
Si considera per ipotesi che una data serie numerica converge, equivale a dire che la serie delle somme parziali converge:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty a_k\rightarrow s_n=\sum_{k=1}^n a_k\\
    \lim_{n\to\infty}s_n=s
\end{gather*}

Considerando il limite della successione generata aumentando l'indice di uno $n+1$, la combinazione lineare tra queste due successioni converge a zero, poiché rappresentano la stessa successione traslata di un elemento:
\begin{gather*}
    \lim_{n\to\infty}s_{n+1}=s\\
    \lim_{n\to\infty}(s_{n+1}-s_n)=0
\end{gather*}
La successione $s_{n+1}$ corrisponde alla prima successione $s_n$ sommata ad un ulteriore elemento $a_{n+1}$, per cui si può riscrivere la loro differenza come:
\begin{gather*}
    s_{n+1}=s_n+a_{n+1}\\
    s_{n+1}-s_{n}=a_{n+1}
\end{gather*}
Quindi la successione può convergere se il termine infinitesimo della serie converge:
\begin{equation}
    \lim_{n\to\infty}a_{n+1}=0
\end{equation}
Queste rappresenta solo una condizione necessaria, non garantisce che una serie converga, non è quindi una condizione sufficiente. 
Se il termine infinitesimo di una serie non converge, allora la serie non può convergere, quindi diverge oppure è irregolare. 

%% ESEMPIO

Si considera la seguine serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{3k^2+1}{2k^2+3}
\end{gather*}
Si vuole studiare il carattere della seguente serie utilizzando la condizione appena descritta:
\begin{gather*}
    \lim_{k\to\infty}\displaystyle\frac{3k^2+1}{2k^2+3}=\frac{3}{2}\neq0
\end{gather*}
Questa serie quindi non può converge, potrebbe quindi divergere oppure essere irregolare. 


Esiste un teorema che tratta le successioni numeriche, e si riflette sulle serie. Questo teorema afferma che data una successione monotona crescente $\{a_k\}\uparrow$ o decrescente $\{a_k\}\downarrow$, ovvero se tra il termine $a_k$ ed il termine $a_{k+1}$ esiste una relazione d'ordine, definitivamente, $\forall k\geq k_0$. Allora la successione non può essere irregolare. 

Sia una serie $\sum_{k=0}^\infty a_k$, se $\forall k\geq k_0$ si ha $a_k>0$, allora la serie non è irregolare. Considerando un valore di $n\geq k_0$, si ha:
\begin{gather*}
    s_{n+1}=s_n+\overbrace{a_{n+1}}^{>0}\implies s_{n+1}>s_n
\end{gather*}

Poiché viene sommato ad $s_n$ un valore non nullo positivo, quindi una serie di termini di segno costante positivo corrisponde ad una successione di somme parziali definitivamente monotona crescente. Questa serie allora converge o diverge, è regolare. 

Considerando la serie dell'esempio precedente, con il primo criterio si è confermato che la serie non converge, analizzando i segni della serie si ha:
\begin{gather*}
    3k^2+1>0\,\land\,2k^2+3>0\implies\displaystyle\frac{3k^2+1}{2k^2+3}
\end{gather*}

Quindi la serie è composta da termini definitivamente positivi, quindi la serie non può essere irregolare. Questa serie allora diverge ad infinito positivo. 

%% PROPRIETÀ

Si considerano due serie $\sum a_k$ e $\sum b_k$, convergenti rispettivamente a $\alpha$ e $\beta$, la serie combinazione lineare delle due serie $\sum(Aa_k+Bb_k)$ allora converge al valore $A\alpha+B\beta$. Tramite questa proprietà è possibile scomporre una serie ed analizzare i singoli termini per determinare il carattere della serie da cui derivano. Se una delle due diverge, mentre l'altra converge, allora la serie combinazione lineare diverge, allo stesso segno della serie divergente, per qualunque valore di $A$ e $B$, vale anche se entrambe le serie convergono ad infinito di segno concorde. Se invece entrambe le serie divergono ed il segno discorde, allora questo genera una forma indeterminata e quindi non è possibile determinare il comportamento della serie combinazione lineare. 

\subsubsection{Criterio del Confronto}

Siano $\sum_{k=1}^\infty a_k$ e $\sum_{k=1}^\infty b_k$ due serie di segno definitivamente costante tale che vale la seguente condizione: $\forall k\geq k_0\rightarrow 0<a_k\leq b_k$. Allora se lla serie maggiorante $\sum_{k=1}^\infty b_k$ converge, allora si dimostra che anche la serie minorante $\sum_{k=1}^\infty a_k$ converge. Analogamente vale il duale di questa proprietà se la serie minorante $\sum_{k=1}^\infty a_k$ diverge, allora anche la serie maggiorante $\sum_{k=1}^\infty b_k$ diverge anch'essa. 

%% ESERCIZIO 

Si considera la seguente serie, bisogna analizzarne il comportamento, tramite il criterio del confronto:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{|\sin k|}{2^k}
\end{gather*}
Si considera il modulo per avere termini definitivamente positivi, allora il termine generico della serie sarà maggiorato dal termine generico:
\begin{gather*}
    \displaystyle\frac{|\sin k|}{2^k}<\frac{1}{2^k},\,\forall k\in\mathbb{N}
\end{gather*}
È certamente diverso dal termine generico, poiché $k$ non può essere un multiplo di $\pi$. 
La serie maggiorante corrisponde ad una serie geometrica di ragione $1/2$, e converge poiché la ragione è di modulo minore di uno, quindi converge anche la serie minorante. 

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{2+\cos k}{k}
\end{gather*}
Si può esprimere una serie maggiorante e minorante di questa serie:
\begin{gather*}
    \displaystyle\frac{1}{k}<\frac{2+\cos k}{k}<\frac{3}{k}
\end{gather*}

La serie minorante è una serie armonica, si dimostrerà che diverge a più infinito:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k}=+\infty
\end{equation*}
Mentre la serie armonica generalizzata, per $\alpha\in\mathbb{R}$ diverge solo per certi valori di $\alpha$:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k^\alpha}
\end{equation*}

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{|\cos k|}{k}
\end{gather*}
La serie maggiorante rappresenta la serie armonica descritta precedentemente, per cui non è possibile utilizzare il criterio del confronto. Non è possibile stabilire il carattere della serie utilizzando questo criterio. 

\subsubsection{Criterio della Radice}

Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si basa sulla definizione di una successione ausiliaria. Per costruire questa successione ausiliaria si considera, da $k>k_0$, $\{\sqrt[k]{a_k}\}$. Si considera per ipotesi che questa successione sia regolare:
\begin{equation*}
    \lim_{k\to\infty}\sqrt[k]{a_k}=\Lambda
\end{equation*}

Se questo limite converge ad un valore positivo maggiore di uno, oppure diverge ad infinito positivo, allora è dimostrabile che la serie di partenza diverge. 
Se questo limite è positivo e minore di uno, allora la serie converge. Mentre se il limite è esattamente pari ad uno, allora il problema rimane aperto, e non è possibile stabilire il comportamento della serie tramite questa successione. 

\begin{equation}
    \displaystyle\sum_{k=1}^\infty a_k:\begin{cases}
        \text{diverge}&\Lambda > 1\,\lor\Lambda=+\infty\\
        \text{converge}&0\leq\Lambda<1\\
        ?&\Lambda=1
    \end{cases}
\end{equation}

Considerando la seguente serie, determinare il carattere tramite il metodo della radice:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\left(\frac{1}{k}\right)^k
\end{gather*}
La sua serie ausiliaria è:
\begin{gather*}
    \displaystyle\left\{\sqrt[k]{\left(\frac{1}{k}\right)^{k}}\right\}=\left\{\frac{1}{k}\right\}
\end{gather*}
Questa successione corrisponde alla serie armonica, e diverge quindi la serie di partenza diverge. 

\subsubsection{Criterio del Rapporto}

Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si basa sulla definizione di una successione ausiliaria. Per costruire questa successione ausiliaria si considera, da $k>k_0$:
\begin{equation*}
    \displaystyle\left\{\frac{a_{k+1}}{a_k}\right\}
\end{equation*}
Si considera per ipotesi che questa successione sia regolare:
\begin{equation*}
    \lim_{k\to\infty}\displaystyle\frac{a_{k+1}}{a_k}=\Lambda
\end{equation*}

Esistono casi dove la successione ausiliaria creata è irregolare, e quindi non è possibile utilizzare questi criteri. %% !! base55555555555555555555555555
Analogamente al criterio precedente, in base al valore del limite la serie diverge, converge, oppure non è possibile determinarne il carattere:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty a_k:\begin{cases}
        \text{diverge}&\Lambda > 1\,\lor\Lambda=+\infty\\
        \text{converge}&0\leq\Lambda<1\\
        ?&\Lambda=1
    \end{cases}
\end{equation}

%% ESEMPIO

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{2^k}{k!}
\end{gather*}

La sua serie ausiliaria è quindi:
\begin{gather*}
    \displaystyle\frac{\frac{2^{k+1}}{(k+1)!}}{\frac{2^k}{k!}}=
    \frac{2^{k+1}}{(k+1)!}\cdot\frac{k!}{2^k}=\cancelto{\frac{1}{k+1}}{\frac{k!}{(k+1)!}}\cdot\cancelto{2}{\frac{2^{k+1}}{2^k}}=\frac{2}{k+1}\\
    \lim_{k\to\infty}\frac{2}{k+1}=0
\end{gather*}

La serie quindi converge, invece se i termini della serie fossero inversi:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{k!}{2^k}
\end{gather*}

\subsubsection{Criterio dell'Integrale}
Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si considera la funzione associata che sostituisce $\{a_k\}\rightarrow\{f(x)\}$. La funzione associata deve essere decrescente a partire da $k_0$: $f(x)\downarrow \forall x>k_0$. Sia:
\begin{equation*}
    t_n=\displaystyle\int_{k_0}^n f(x)\mathrm{d}x
\end{equation*}

Allora la successione definita su $t_n$: $\{t_n\}$ e la serie $\sum a_k$ hanno lo stesso carattere. 

Si applica il criterio dell'integrale sulla serie armonica generalizzata, questa soddisfa l'ipotesi da $k_0=1$:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k^\alpha},\,\alpha\in\mathbb{R}\\
    f(x)=\displaystyle\frac{1}{x^\alpha}
\end{gather*}
Se $\alpha$ fosse negativo, la funzione associata sarebbe monotona crescente, ma se fosse negativo la serie sarebbe $\sum k^{|\alpha|}$, per cui diverge. 
Per $\alpha=0$, tutti i termini della serie sono pari ad uno, quindi il termine generico è uno e quindi la serie diverge allo stesso modo. Quindi solo per $\alpha>0$ la serie converge, e quindi solo per questo caso ha senso lo studio della serie armonica generalizzata

Nel caso $\alpha>0$ la condizione necessaria è soddisfatta, quindi la funzione potrebbe convergere. Si studia il suo carattere con il criterio dell'integrale, si ha la seguente serie ausiliaria:
\begin{gather*}
    t_n=\displaystyle\int_{1}^n\frac{1}{x^\alpha}\mathrm{d}x=\begin{cases}
        \bigg|\log(x)\bigg|_1^n &\alpha=1\\
        \displaystyle\frac{1}{1-\alpha}\bigg|x^{1-\alpha}\bigg|_1^n&\alpha\neq1
    \end{cases}=\begin{cases}
        \log(n)&\alpha=1\\
        \displaystyle\frac{1}{1-\alpha}\left(n^{1-\alpha}-1\right)&\alpha\neq1
    \end{cases}
\end{gather*}

Per $\alpha=1$, la successione diverge, poiché il logaritmo è una funzione monotona crescente, mentre per $\alpha\neq1$:
\begin{gather*}
    \displaystyle\frac{1}{1-\alpha}\lim_{n\to\infty}\left(n^{1-\alpha}-1\right)=\begin{cases}
        +\infty&\alpha<1\\
        \displaystyle\frac{1}{1-\alpha}&\alpha>1
    \end{cases}
\end{gather*}
La serie quindi diverge per $\alpha<1$, mentre converge per $\alpha>1$

Il carattere della serie armonica generalizzata è quindi dato dal seguente:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k^\alpha}:\begin{cases}
        \text{diverge}&\alpha\le1\\
        \text{converge}&\alpha>1        
    \end{cases}
\end{equation}


Conviene applicare il criterio dell'integrale quando la funzione associata è facilmente integrabile. Considerata la seguente serie:
\begin{equation*}
    \displaystyle\sum_{k=1}^{\infty}\frac{\text{arctan}\, k}{1+k^2}
\end{equation*}

Per valutare il carattere di questa serie si potrebbe considerare il criterio del confronto, poiché l'arcotangente è una funzione superiormente limitata da $\pi/2$:
\begin{gather*}
    \displaystyle\frac{\text{arctan}\,k}{1+k^2}<\frac{\pi/2}{1+k^2}<\frac{\pi}{2k^2}
\end{gather*}

Considerando la serie maggiorante, questa è una serie armonica generalizzata con parametro $\alpha=2>1$, questa converge, quindi per il criterio del confronto converge anche la serie di partenza. 

In questo caso funziona anche il criterio dell'integrale. La sua funzione associata è:
\begin{gather*}
    f(x)=\displaystyle\frac{\text{arctan}\, x}{1+x^2}
\end{gather*}

Si può notare come la funzione associata è il prodotto dell'arcotangente per la sua derivata, quindi l'integrale è immediato. Per utilizzare il criterio dell'integrale bisogna determinare che la funzione è monotona decrescente, si analizza quindi la sua derivata:
\begin{gather*}
    \displaystyle\frac{\mathrm{d}f(x)}{\mathrm{d}x}=\displaystyle\frac{\cancelto{1}{\frac{1}{1+x^2}(1+x^2)}-2x\text{arctan}\,x}{(1+x^2)^2}\\
    1-2x\text{arctan}\,x <0
\end{gather*}
Il numeratore è sempre negativo per $x\in(1,\infty)$, per cui la funzione ausiliaria è monotona decrescente ed è possibile utilizzare il criterio dell'integrale:
\begin{gather*}
    t_k=\displaystyle\int_{1}^kf(x)\mathrm{d}x=\int_1^k\frac{\text{arctan}\,x}{1+x^2}\mathrm{d}x\\
    u=\text{arctan}\,x\rightarrow\int_1^{\text{arctan}\,k}u \mathrm{d}u=\bigg|\frac{u^2}{2}+c\bigg|_1^{\text{arctan}\,k}=\frac{\arctan^2k}{2}-\frac{\pi^2}{8} %% TODO finire
\end{gather*}

\subsubsection{Criterio di Condensazione}

Sia una serie di segno definitivamente positivo: $\sum_{k=1}^\infty a_k | a_k>0\,\forall k\geq k_0$. Si considera la serie monotona decrescente $a_k\downarrow$, allora la serie $\sum 2^ka_{2^k}$ ha lo stesso carattere della serie di partenza. Generalmente si applica solo nel caso dove in $a_k$ è presente un fattore logaritmo di $k$. 

Si considera la serie:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty\frac{\ln k}{k}
\end{equation*}

Si calcola la derivata della sua funzione ausiliaria:
\begin{gather*}
    \displaystyle f(x)=\frac{\ln x}{x}\\
    f'(x)=\displaystyle\frac{1-\ln x}{x^2}<0
\end{gather*}
Si è verificata l'ipotesi della monotonia della serie. 
Si applica quindi il criterio di condensazione:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty \cancel{2^k}\frac{\ln 2^k}{\cancel{2^k}}
\end{gather*}

Sfruttando le proprietà del logaritmo questo diventa:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty k\cdot{\ln 2}=\ln 2\displaystyle\sum_{k=1}^\infty k
\end{gather*}

Non verificando l'ipotesi di convergenza, non può convergere. 

Si considera ora la serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{\ln k}{k^2}\\
    \displaystyle f(x)=\frac{\ln x}{x^2}\\
    f'(x)=\displaystyle\frac{x-2x\ln x}{x^4}=\frac{\cancel{x}(1-2\ln x)}{x^{\cancelto{3}{4}}}<0
\end{gather*}

Si applica il criterio di condensazione:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty \cancel{2^k}\frac{\ln 2^k}{(2^k)^{\cancel{2}}}=\ln2\sum_{k=1}^\infty\frac{k}{2^k}
\end{gather*}
Si studia il criterio del rapporto per poter determinarne il carattere:
\begin{gather*}
    \displaystyle\frac{\frac{k+1}{2^{k+1}}}{\frac{k}{2^k}}=\frac{k+1}{k}\frac{\cancel{2^k}}{2^{\cancel{k+1}}}=\frac{1}{2}\frac{k+1}{k}\\
    \frac{1}{2}\lim_{k\to\infty}\frac{k+1}{k}=\frac{1}{2}<1
\end{gather*}
Poiché $a_{k+1}/a_{k}<1$ la serie converge, e quindi per il criterio di condensazione anche la serie di partenza converge.  

\subsubsection{Criterio del Confronto Asintotico}

In questo criterio si considerano due serie, entrambe a termini definitivamente positivi $\sum_{k=1}^\infty a_k \land \sum_{k=1}^\infty b_k | a_k>0,\,b>0\,\forall k\geq k_0$. Allora se il limite del rapporto all'infinito converge ad un numero reale non nullo, allora hanno lo stesso carattere
\begin{gather*}
    \lim_{k\to\infty}\frac{a_k}{b_k}=l\in\mathbb{R}\setminus\{0\}
\end{gather*}
Se $l=1$ allora le due successioni, analogamente per le funzioni, si dicono asintoticamente equivalenti per $k\to\infty$: $a_k$~$b_k$. %% TODO tilde c'è?
Spesso si userà questo simbolo generalizzandolo come due funzioni asintoticamente equivalenti a meno di una costante, poiché è di interessa solamente il carattere e non il valore effettivo esplicito di una serie. 
Se invece il rapporto converge a zero e la serie $\sum b_k$ converge, allora anche la serie $\sum a_k$ converge, ovvero $a_k$ è un infinitesimo di ordine superiore a $b_k$. 
Se invece il limite di questo rapporto tende ad infinito, e la serie $\sum b_k$ diverge, allora divergerà anche la serie $\sum a_k$, $b_k$ è un infinitesimo di ordine superiore di $a_k$. 

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\sin\left(\frac{1}{k}\right)
\end{gather*}
È soddisfatta la condizione necessaria per la convergenza, avendo:
\begin{gather*}
    \displaystyle\lim_{k\to\infty}\sin\left(\frac{1}{k}\right)=0
\end{gather*}

Bisogna ora trovare una serie $\sum b_k$, tale che:
\begin{gather*}
    \displaystyle\lim_{k\to\infty}\frac{\sin\left(\frac{1}{k}\right)}{b_k}=l\in\mathbb{R}\setminus\{0\}
\end{gather*}
Per il limite notevole $\sin x/x$, questa serie è $b_k=1/k$, per cui il limite converge ad uno:
\begin{gather*}
    \displaystyle\lim_{k\to\infty}\frac{\sin\left(\frac{1}{k}\right)}{\frac{1}{k}}=1
\end{gather*}

Queste due serie sono asintoticamente equivalenti tra di loro:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\sin\left(\frac{1}{k}\right)\sim\sum_{k=1}^\infty\frac{1}{k}
\end{gather*}
La serie di destra è una serie armonica e diverge, quindi diverge anche la serie di partenza. 5

Data ora la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\sin\left(\frac{1}{k^2}\right)
\end{gather*}

I termini sono sempre positivi, ed è soddisfatta la condizione necessaria, la serie asintoticamente equivalente è data da:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\sin\left(\frac{1}{k^2}\right)\sim\displaystyle\sum_{k=1}^\infty\frac{1}{k^2}
\end{gather*}

Questa è una serie armonia generalizzata per $\alpha=2>1$, quindi converge. Allora anche la serie di partenza converge.  


Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\ln\left(\frac{k+1}{k}\right)
\end{gather*}

La serie ha termini di segno definitivamente positivo, poiché l'argomento è certamente maggiore di uno: $k+1>k$. Si scrive in forma equivalente l'argomento per evidenziare il limite notevole:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\ln\left(\frac{k+1}{k}\right)=
    \displaystyle\sum_{k=1}^\infty\ln\left(1+\frac{1}{k}\right)\sim\sum_{k=1}^\infty\frac{1}{k}
\end{gather*}

Questa serie ha lo stesso carattere di una serie armonica divergente, quindi diverge. 

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\left(e^{1/k}-1\right)\sim\sum_{k=1}^\infty\frac{1}{k}
\end{gather*}
Per il limite notevole è asintoticamente equivalente ad una serie armonica divergente, quindi diverge. 

Considerando ora la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\left(e^{1/\sqrt{k}}-1\right)\sim\sum_{k=1}^\infty\frac{1}{k^{1/2}}
\end{gather*}
Essendo asintoticamente equivalente ad una serie armonica generalizzata divergente, diverge. 
Per avere avere una serie convergente, deve avere come argomento almeno un $k^\alpha$, con $\alpha>1$.. 


Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\ln\left(\frac{k^2+5k-2}{k^2+3}\right)
\end{gather*}
Sicuramente è una serie a termini positivi, si vuole quindi riscrivere l'argomento del logaritmo nella forma $1+x$:
% !! 55555555555555555555
% ?? 55555555555555555555555555555555555555555555558555555555555555555555555555555555555555555555555555555555555
% todo 55555555555555555555255555555555555555525555555585555555555555555554555555555555555555555565565555565656565555555555555555555555555555
\begin{gather*}
    \displaystyle\frac{k^2+5k-2}{k^2+3}=1+\frac{5k-5}{k^2+3}
\end{gather*}
Questa serie si comporta in modo equivalente alla serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\ln\left(\frac{k^2+5k-2}{k^2+3}\right)=
    \displaystyle\sum_{k=1}^\infty\ln\left(1+\frac{5k-5}{k^2+3}\right)\sim\sum_{k=1}^\infty\frac{5k-5}{k^2+3}\sim\sum_{k=1}^\infty\frac{5k}{k^2}=5\sum_{k=1}^\infty\frac{\cancel{k}}{k^{\cancel{2}}}
\end{gather*}
Essendo asintoticamente equivalente ad una serie armonica divergente, anche essa diverge. 

\subsubsection{Criterio di Leibniz}

Una prima famiglia di serie a termini di segno alterni permette comunque di poter calcolare. Considerata una serie con $a_k>0\forall k>k_0$, si esprime il fattore che rende la serie alterna:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty(-1)^ka_k
\end{gather*}

Il criterio di Leibniz suppone di avere una serie del genere, siano i termini della serie decrescenti, tendenti a 0: $\{a_k\}\downarrow0$, allora la serie converge. 


Detta $S$ la somma della serie:
\begin{gather*}
    s=\displaystyle\sum_{k=0}^\infty(-1)^ka_k
\end{gather*}

All'aumentare di $n$, la somma $s_n$ dei primi $n$ elementi della serie, la serie oscilla sorpassando in positivo o in negativo la somma $s$, di valori sempre più piccoli, convergendo al valore $s$:

%% TODO asse reale con S1, S2, ... S oscillazione
\begin{gather*}
    |s-s_1| < |s_1-s_2|\\
    |s-s_n| \leq |s_n-s_{n-1}|=|a_n|
\end{gather*}

La somma $s_n$ si posizione al lato opposto di $s_{n-1}$ e si trova ad una posizione più vicina alla somma $s$ rispetto al precedente, quindi ha una distanza minore. 

\subsubsection{Criterio di Convergenza Assoluta}

Il criterio di Leibniz si può utilizzare solo quando le serie hanno segno alterno, mentre, per altri tipo di serie in cui il segno non è né definitivamente positivo, o negativo, e né alterno, è necessario un altro criterio per poter determinarne il carattere. 

Un criterio generale consiste nell'analizzare il carattere della serie $|a_k|$, questa serie risultante è a termini di segno costante positivo:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty|a_k|
\end{gather*}

Un teorema dimostrabile afferma che se una serie ha termini di segno non costante $\sum a_k$, se la serie formata mettendo in valore assoluto i termini della prima $\sum|a_k|$ converge, allora converge anche la serie iniziale. Si dice che converge in modo assoluto, o assolutamente. 

Se la serie $\sum a_k$ converge assolutamente, allora la serie converge semplicemente, la convergenza studiata con i criteri precedenti. 

\subsection{Serie di Potenze}

In generale una serie di potenza viene espressa, partendo da 0 o 1, come:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty a_k(x-x_0)^k
\end{gather*}
Con $x_0\in\mathbb{R}$, si dice serie di potenze con centro in $x_0$. Le serie di potenze sono molto importanti e di facile analisi, anche se il calcolo del loro limite non è triviale. 

Quando si analizzano serie di potenze si parla di intervallo di convergenza, poiché si analizza per quali valori del parametro $x$ la serie converge. Una serie geometrica è una particolare serie di potenze centrata in $x_0=0$, con $a_k=1$ per ogni valore di $k$, di cui si conosce anche la somma, per valori del parametro $x\in(-1,1)$:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty x^k=\frac{1}{1-x}
\end{gather*}

Tutte le volte che si ha una serie di potenze, la prima cosa che bisogna calcolare è il cosiddetto raggio di convergenza. La sua definizione è molto più ampia, ma studiando casi particolari non sarà necessario approfondirlo. Per calcolarlo si introduce una successione ausiliaria:
\begin{gather*}
    \left\{\displaystyle\left|\frac{a_k}{a_{k+1}}\right|\right\}
\end{gather*}
Questa serie si riferisce al criterio del rapporto, alternativamente si può usare la serie ausiliaria: %% TODO quale criterio
\begin{gather*}
    \left\{\displaystyle\frac{1}{\sqrt[k]{a_k}}\right\}
\end{gather*}
Bisogna dare per ipotesi che queste successioni siano regolari, per $k\to\infty$. Questo valore $R$ si trova calcolando il limite per $k\to\infty$ di una di queste due successioni:
\begin{equation}
    R=\lim_{k\to\infty}\displaystyle\left|\frac{a_k}{a_{k+1}}\right|=\lim_{k\to\infty}\frac{1}{\sqrt[k]{a_k}}=\begin{cases}
        +\infty\\
        0\\
        \in\mathbb{R}^+
    \end{cases}
\end{equation}

Se il limite esiste assume uno di questi tre possibili valori. Una volta determinato il raggio di convergenza, esiste un teorema che stabilisce dove questa serie risulta sicuramente convergente. 

Sia $R$ il raggio di convergenza della serie di potenze $a_k$ con centro in $x_0$: $\sum a_k(x-x_0)^k$. Allora si può affermare:
\begin{enumerate}
    \item Se $R=0$, la serie converge solo nel centro $x_0$. 
    \item Se $R=+\infty$, la serie converge in $\mathbb{R}$, ovvero qualunque sia il valore reale del parametro $x$. 
    \item Se $R\in\mathbb{R}^+$, finito positivo e diverso da zero, la serie converge assolutamente, e quindi semplicemente, in $(x_0-R, x_0+R)$. Inoltre la serie non converge nell'intervallo $(-\infty,x_0-R)$ e $(x_0+R, +\infty)$. 
\end{enumerate}

Nell'ultimo caso $R$ rappresenta il centro dell'intervallo di convergenza, se il raggio è zero, contiene solo il centro, se è infinito, contiene tutti i numeri reali. 
Per determinare il valore al limite dell'intervallo $x=x_0\pm R$, bisogna sostituire questo valore ad $x$ e studiare per via diretta il carattere della serie risultante. Per questo si distingue tra intervallo di convergenza ed insieme di convergenza, poiché potrebbero non coincidere, potrebbero comprendere gli estremi. Coincidono solo se ai valori estremi la serie non converge. 

\subsubsection{Teorema della Serie Derivata e Integrale}

Sia una serie di potenze con centro $x_0$:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty a_k(x-x_0)^k
\end{gather*}
Tale che il raggio di convergenza è un numero reale positivo, oppure diverge ad infinito: $R\in\mathbb{R}^+$ o $R=+\infty$. 
Allora per ogni valore nell'intervallo di insieme di convergenza centrato in $x_0$: 
$\forall x\in I_R(x_0)$, la funzione somma è di classe $S(x)\in C^{\infty}(I_R(x_0))$, quindi è derivabile infinite volte, e tutte le sue derivate sono funzioni continue. La derivata rispetto alla variabile $x$ della somma è:
\begin{gather*}
    \forall x \in I_R(x_0)\implies\displaystyle\frac{\mathrm{d}}{\mathrm{d}x}S(x)=
    \frac{\mathrm{d}}{\mathrm{d}x}\sum_{k=0}^\infty a_k(x-x_0)^k=
    \sum_{k=0}^\infty a_k\frac{\mathrm{d}}{\mathrm{d}x}(x-x_0)^k=
    \sum_{k=1}^\infty a_kk(x-x_0)^{k-1}
\end{gather*}
Il termine con $k=0$ è costante per cui la serie parte da $k=1$.
Oltre a poter derivare termine a termine è possibile integrare termine a termine della funzione somma:
\begin{gather*}
    \forall x\in I_R(x_0)\implies\displaystyle\int_{x_0}^xS(t)\mathrm{d}t=\int_{x_0}^x\sum_{k=0}^\infty a_k(t-x_0)^k\mathrm{d}t=\sum_{k=0}^\infty a_k\int_{t_0}^x(t-x_0)^k\mathrm{d}t\\
    \displaystyle\int_{x_0}^xS(t)\mathrm{d}t=
    \sum_{k=0}^\infty a_k\frac{t-x_0}{k+1}^{k+1}
\end{gather*}
L'integrale della somma è uguale alla serie degli integrali, analogamente alla derivata. 

\subsubsection{Espansione in Serie}

Per ogni $x$ nell'intervallo $(-1,1)$ si è dimostrato per via diretta che la funzione definita in $\mathbb{R}\setminus\{1\}$: $(1-x)^{-1}$ si può esprimere come una serie di potenze con raggio di convergenza uno e centro nell'origine:
\begin{gather}
    \forall x\in(-1,1)\implies\displaystyle\frac{1}{1-x}=\sum_{k=0}^\infty x^k
\end{gather}
Si considera nell'intervallo $I_1(0)$ l'integrale di questa funzione, per il teorema appena enunciato si può esprimere come la somma di integrali, effettuando il passaggio sotto il segno dell'integrale alla sommatoria: %% TODO fix wording
\begin{gather*}
    \forall x \in I_1(0)\implies\displaystyle\int_{0}^x\frac{1}{1-t}\mathrm{d}t=
    \sum_{k=0}^\infty\int_{0}^x t^k\mathrm{d}t=
    \sum_{k=0}^\infty\frac{t^{k+}1}{k+1}\bigg|_{0}^x=
    \sum_{k=0}^\infty\frac{x^{k+1}}{k+1}=\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather*}
Calcolando l'integrale direttamente si ottiene che vale:
\begin{gather*}
    \forall x\in(-1,1)\implies\displaystyle\int_0^x\frac{1}{1-t}\mathrm{d}t=-\ln(1-x)
\end{gather*}
Si è scoperto che se la $x$ è contenuta in questo intervallo dato lo sviluppo in serie di una funzione si ottiene anche lo sviluppo in serie della funzione:
\begin{gather*}
    \forall x\in I_1(0)\implies -\ln(1-x)=\displaystyle\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather*}
L'uguaglianza si può estendere all'estremo $-1$ per il criterio di Leibniz, ma non per $x=1$:
\begin{gather}
    \forall x\in [-1,1)\implies -\ln(1-x)=\displaystyle\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather}

Effettuando il cambio di variabile $-x=u$, l'intervallo di convergenza diventa $u\in(-1, 1]$:
\begin{gather*}
    -\ln(1+u)=\displaystyle\sum_{k=1}^\infty\frac{(-u)^k}{k}=
    \displaystyle\sum_{k=1}^\infty(-1)^k\frac{u^k}{k}\\
    \ln(1+u)=-\displaystyle\sum_{k=1}^\infty(-1)^k\frac{u^k}{k}=
    \displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{u^k}{k}\\
    \forall x\in(-1,1]\implies\displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{x^k}{k}\tageq
\end{gather*}


%% TODO \ref alla prima eq
Considerando la prima espansione, si effettua la sostituzione $x=-u^2$: 
\begin{gather*}
    -1<x<1\\
    -1<-u^2<1\\
    -u^2<1\,\forall n\in\mathbb{R}\implies u^2<1:\,-1<n<1\\
    u\in(-1,1)
\end{gather*}

La funzione e corrispondente serie diventa quindi:
\begin{gather*}
    \forall u\in(-1,1)\,\displaystyle\frac{1}{1+n^2}=\sum_{k=0}^\infty(-n^2)^k=
    \sum_{k=0}^\infty(-1)^kn^{2k}
\end{gather*}
A questo punto si integra membro a membro e si scambia l'integrale sotto il segno della sommatoria:
\begin{gather*}
    \displaystyle\int_0^u\frac{1}{1+u^t}\mathrm{d}t=
    \int_0^u\sum_{k=0}^\infty(-1)^kt^{2k}\mathrm{d}t=
    \sum_{k=0}^\infty(-1)^k\int_0^ut^{2k}\mathrm{d}t=
    \sum_{k=0}^\infty(-1)^k\frac{u^{2k+1}}{2k+1}\\
    \arctan u=\sum_{k=0}^\infty(-1)^k\frac{u^{2k+1}}{2k+1}
\end{gather*}

Quindi l'arcotangente di $x$ nell'intervallo $(-1,1)$ si può esprimere come la seguente serie:
\begin{equation*}
    \forall x\in(-1,1)\,\arctan x=\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{2k+1}
\end{equation*}
Bisogna comunque controllare se questa serie converge anche agli estremi dell'intervallo di convergenza. Per $x=1$ si ha:
\begin{gather*}
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^k}{2k+1}
\end{gather*}
Questa serie converge per il criterio di Leibniz poiché la serie ha termini strettamente decrescenti convergenti a zero; mentre per $x=-1$ si ha:
\begin{gather*}
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^k(-1)^{2k+1}}{2k+1}=
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^{k+1}}{2k+1}
\end{gather*}
Analogamente alla precedente vale il criterio di Leibniz quindi converge. L'identità diventa quindi:
\begin{equation}
    \forall x\in[-1,1]\,\arctan x=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{2k+1}
\end{equation}
Questa serie venne utilizzata per calcolare il valore di pi greco, considerando la serie per il valore $x=1$:
\begin{gather*}
    \arctan(1)=\displaystyle\frac{\pi}{4}=\displaystyle\sum_{k=0}^\infty\frac{(-1)^k}{2k+1}\\
    \pi=4\displaystyle\sum_{k=0}^\infty\frac{(-1)^k}{2k+1}
\end{gather*}
Con un indice molto elevato si può ottenere un'approssimazione molto accurata del pi greco. 

\subsubsection{Serie di Taylor Swift}

Questa serie di potenze si può chiamare serie di Taylor. Data una funzione derivabile con continuità infinite volte $f\in C^\infty(I_R(x_0)) $, la sua serie di Taylor si definisce come la seguente:
\begin{equation}
    \displaystyle\sum_{k=0}^\infty\frac{f^{(k)}(x_0)}{k!}(x-x_0)
\end{equation}

Per certe funzioni, e certi intervalli, si può estendere il grado del polinomio di Taylor fino all'infinito. 

Il polinomio di Maclaurin della serie esponenziale è la seguente:
\begin{gather*}
    e^x=\displaystyle\sum_{k=0}^n\frac{x^k}{k!}+o[x^n]
\end{gather*}
Si può dimostrare che tendendo $n\to\infty$ la serie di Maclaurin ottenuta continua a coincidere alla serie esponenziale; si vuole ottenere lo sviluppo in serie dell'esponenziale. 
Partendo dalla serie di potenze si cattura il suo raggio di convergenza:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}\\
    R=\lim_{k\to\infty}\displaystyle\left|\frac{a_k}{a_{k+1}}\right|=
    \lim_{k\to\infty}\frac{1}{\cancel{k!}}(k+1)\cancel{!}=\lim_{k\to\infty}{k+1}=+\infty
\end{gather*}
Essendo il raggio di convergenza infinito, la serie converge in $\mathbb{R}$:
\begin{gather*}
    \forall x\in\mathbb{R}\, S(x)=\displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}
\end{gather*}
Si vuole dimostrare che la somma di questa serie $S(x)$ coincide all'esponenziale $e^x$. Si applica il teorema del passaggio della derivata sotto il segno della sommatoria:
\begin{gather*}
    \displaystyle\frac{\mathrm{d}}{\mathrm{d}x}S(x)=\frac{\mathrm{d}}{\mathrm{d}x}\sum_{k=0}^\infty\frac{x^k}{k!}=
    \displaystyle\sum_{k=0}^\infty\frac{1}{k!}\frac{\mathrm{d}}{\mathrm{d}x}x^k=
    \sum_{k=1}^\infty x^{k-1}\frac{\cancel{k}}{\cancel{k}(k-1)!}=
    \displaystyle\sum_{k=1}^\infty\frac{x^{k-1}}{(k-1)!}\\
\end{gather*}
La serie della derivata parte da $k=1$, poiché il primo addendo $a_0$ è costante e nel passaggio della derivata si annulla. 
\begin{gather*}
    S'(x)=\displaystyle\sum_{k=1}^\infty\frac{x^{k-1}}{(k-1)!}=
    \displaystyle\sum_{k=0}^\infty\frac{x^{k}}{k!}=S(x)
\end{gather*}

La derivata prima di questa funzione coincide con la funzione di partenza, a meno di una costante, per ogni $x\in\mathbb{R}$. Inoltre si ha che $S(0)=1$, questo rappresenta un problema di Cauchy:
\begin{gather*}
    \begin{cases}
        S'(x)=S(x)&\forall x\in\mathbb{R}\\
        S(0)=1
    \end{cases}\\
    \displaystyle\frac{S'(x)}{S(x)}=1\implies\int_0^x\frac{S'(t)}{S(t)}\mathrm{d}t=x\\
    \ln|S(t)|\bigg|_0^x=x\implies \ln|S(x)|-\cancelto{0}{\ln|S(0)|}=x\\
    S(x)=e^x
\end{gather*}
Per cui si è dimostrato che la funzione somma $S(x)$ è la funzione esponenziale, e si è definita la sua espansione:
\begin{equation}
    \forall x\in\mathbb{R}\implies\,e^x=\displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}
\end{equation}

Si considera l'approssimazione di Maclurin della funzione coseno:
\begin{gather*}
    \cos x=\displaystyle\sum_{k=1}^n(-1)^k\frac{x^{2k}}{(2k)!}+o[x^{2n}]
\end{gather*}
Si effettua un procedimento analogo, partendo dalla serie, tendendola all'infinito, e ci si aspetta che $o[x^{2n}]$ tende a zero. Si dimostra che la somma di questa serie $S(x)$ non può essere altro che la funzione coseno. 
Si determina il raggio di convergenza della serie:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k}}{(2k)!}=S(x)\\
    %% TODO calcolo del raggio
    R=+\infty
\end{gather*}

Analogamente all'esponenziale la serie converge per ogni $x$ reale $x\in\mathbb{R}$. Si deriva membro a membro l'equazione:
\begin{gather*}
    S'(x)=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{\mathrm{d}}{\mathrm{d}x}\frac{x^{2k}}{(2k)!}=
    \sum_{k=1}^\infty(-1)^k\frac{\cancel{2k}}{\cancel{2k}}\frac{x^{2k-1}}{(2k-1)!}
\end{gather*}
ANalogamente all'esponenziale il termine $a_0$ è una costante, quindi si annulla e la serie parte da $k=1$. Questa serie rappresenta, a meno del segno, lo sviluppo in serie del seno. Si deriva nuovamente membro a membro e si ottiene la seguente:
\begin{gather*}
    S''(x)=\displaystyle\sum_{k=1}^\infty(-1)^k\frac{\cancel{2k-1}}{\cancel{2k-1}}\frac{x^{2k-2}}{(2k-2)!}
\end{gather*}
Si effettua una traslazione, per impostare il valore iniziale a $k=0$:
\begin{gather*}
    S''(x)=\displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{x^{2k-2}}{(2k-2)!}=
    -\sum_{k=0}^\infty(-1)^{k+1}\frac{x^{2k}}{(2k)!}=-S(x)
\end{gather*}
La seconda derivata della funzione iniziale coincide alla funzione stessa, quindi la funzione è o un coseno o un seno, le uniche due funzioni che rispettano questa condizione. Inoltre deve soddisfare $S(0)=1$, e solo la funzione coseno rispetta questo problema di Cauchy:
\begin{gather*}
    \begin{cases}
        S''(x)=-S(x)&\forall x\in\mathbb{R}\\
        S(0)=1
    \end{cases}
\end{gather*}

Quindi la funzione coseno si può esprimere nell'intero asse reale con la seguente espansione:
\begin{equation}
    \forall x\in\mathbb{R}\cos x=\displaystyle\sum_{k=0}^\infty (-1)^k\frac{x^{2k}}{(2k)!}
\end{equation}

%% TODO seno dimostrare

Si può dimostrare allo stesso modo l'espansione seno sull'intero asse dei reali:
\begin{gather*}
    \forall x\in\mathbb{R} \sin x=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{(2k+1)!}
\end{gather*}

\clearpage

\section{Serie di Fourier}

Prima di trattare la serie di Fourier, un altro metodo per esprimere funzioni tramite serie, oltre la serie di Taylor, necessita di conoscere gli integrali impropri. 

\subsection{Integrali Impropri}

L'unica ipotesi per cui si definisce un integrale proprio su intervallo $[a,b]$ di una funzione $f$ è che sia continua nell'intervallo. Si dimostra che l'integrale:
\begin{gather*}
    \displaystyle\int_a^b f(x)\mathrm{d}x
\end{gather*}
È definito. 

Si vuole allentare l'ipotesi per considerare intervalli con una o più discontinuità. Sia una funzione $f$ continua e limitata in $[a,b)$, 
Per definire in termini più generali il concetto di integrale, con un punto di non continuità, si considera un intorno infinitesimo di $b$, ed agli estremi di questo interno $b-\varepsilon$, la funzione è continua: $[a,b-\varepsilon]$. In questo modo si rimuove la singolarità e si può definire l'integrale come:
\begin{gather*}
    \displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x
\end{gather*}
Ottenuta una funzione in termini di $\varepsilon$, si calcola il valore del limite per $\varepsilon\to0^+$, sotto queste ipotesi si dimostra che questo limite esiste ed è finito:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x=\int_a^bf(x)\mathrm{d}x
\end{gather*}
Si poteva scegliere come punto di discontinuità $a$ oppure un punto intermedio, si può sempre utilizzare la proprietà di additività degli integrali. 
Si allenta ulteriormente l'ipotesi, si suppone che la funzione $f$ sia continua ed illimitata nell'intervallo $[a,b)$.  

Analogamente si toglie l'intorno sinistro di $b$, e si forma un'intervallo dove la funzione è continua $[a, b-\varepsilon]$, si calcola in seguito l'integrale in funzione di $\varepsilon$ in questo intervallo. Per ottenere il valore dell'integrale sull'intervallo $[a,b]$ si calcola il valore del limite per $\varepsilon\to0$. 
Rinunciando all'ipotesi di limitatezza, non è più garantito che l'integrale sia definito, potrebbe esistere finito, infinito o irregolare:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x=
    \begin{cases}
        l\in\mathbb{R} &l=\displaystyle\int_a^bf(x)\mathrm{d}x\\
        \pm\infty&\\
        \nexists&
    \end{cases}
\end{gather*}
Nel primo caso l'integrale è convergente al valore $l$, la funzione $f$ si dice integrabile in senso improprio nell'intervallo $[a,b]$ oppure in senso equivalente l'integrale improprio della funzione $f$ è convergente. Questo integrale si dice integrale improprio della seconda specie. Nel secondo caso è divertente ad infinito, la funzione non è integrabile nel senso improprio, l'integrale improprio di seconda specie diverge. Nell'ultimo caso l'integrale oscilla ed il limite non esiste, l'integrale improprio di seconda specie è irregolare. 

%% ESEMPIO

Calcolare questo integrale:
\begin{gather*}
    \displaystyle\int_0^1\frac{1}{\sqrt{1-x^2}}\mathrm{d}x
\end{gather*}
Per prima cosa bisogna categorizzare l'integrale, presenta una singolarità di seconda specie nel punto $x=1$. La funzione integranda è una funzione continua ed illimitata nell'intervallo $[0,1)$. 
Si rimuove la singolarità e si calcola il suo limite:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{1-\varepsilon}\frac{1}{\sqrt{1-x^2}}\mathrm{d}x=\lim_{\varepsilon\to0^+}\left\{\arcsin x\bigg|_0^{1-\varepsilon}\right\}=\lim_{\varepsilon\to0^+}\arcsin(1-\varepsilon)=\frac{\pi}{2}
\end{gather*}

Si considera il seguente integrale:
\begin{gather*}
    \displaystyle\int_1^e\frac{\mathrm{d}x}{x\sqrt[3]{\ln x}}
\end{gather*}
La funzione integranda è illimitata nel punto $x=1$, si rimuove il suo intorno destro per rimuovere la singolarità e si calcola il limite:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\displaystyle\int_{1+\varepsilon}^e\frac{\mathrm{d}x}{x\sqrt[3]{\ln x}}=\lim_{\varepsilon\to0^+}\int_{1+\varepsilon}^e(\ln x)^{-1/3}\mathrm{d}\left(\ln x\right)=\lim_{\varepsilon\to0^+}\left\{\frac{3}{2}\left(\ln x\right)^{2/3}\bigg|_{1+\varepsilon}^e\right\}\\
    \displaystyle\int_1^e\frac{\mathrm{d}x}{x\sqrt[3]{\ln x}}=
    \frac{3}{2}\lim_{\varepsilon\to0^+}\left\{1-\left(\ln 1-\varepsilon\right)^{2/3}\right\}=\frac{3}{2}
\end{gather*}
In questo caso converge, quindi la funzione è integrabile. 


Calcolare al variare del parametro reale $\alpha\in\mathbb{R}$ la convergenza del seguente integrale:
\begin{gather*}
\displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}    
\end{gather*}
Se $\alpha<0$ l'integrale converge, poiché diventa un integrale classico, se $\alpha=0$, l'integrale converge. Diventa un'integrale improprio di seconda specie per $\alpha>0$, poiché $b$ diventa un punto singolare. In un caso si applica l'a regola delle potenze, nell'altro si %% TODO add qualcosa logaritmo

Per $\alpha=1$:
\begin{gather*}
    \displaystyle\int_a^b\frac{\mathrm{d}x}{b-x}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}\frac{\mathrm{d}x}{b-x}=
    \lim_{\varepsilon\to0^+}\left\{-\ln(b-x)\bigg|_a^{b-\varepsilon}\right\}=
    -\lim_{\varepsilon\to0^+}\left\{\ln(\varepsilon)-\ln(b-a)\right\}=+\infty
\end{gather*}
Quindi l'integrale diverge per $\alpha=1$, la funzione non è integrabile in questo intervallo per questo valore del parametro reale $\alpha$.

Per $\alpha\neq1$:
\begin{gather*}
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}\frac{\mathrm{d}x}{(b-x)^{\alpha}}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}(b-x)^{-\alpha}\mathrm{d}x=
    -\lim_{\varepsilon\to0^+}\int_a^{b-\varepsilon}(b-x)^{-\alpha}\mathrm{d}(b-x)\\
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=
    -\lim_{\varepsilon\to0^+}\left\{\frac{(b-x)^{1-\alpha}}{1-\alpha}\bigg|_a^{b-\varepsilon}\right\}=
    \frac{\lim_{\varepsilon\to0^+}\left\{\varepsilon^{1-\alpha}-(b-a)^{1-\varepsilon}\right\}}{\alpha-1}\\
    \lim_{\varepsilon\to0^+}\varepsilon^{1-\alpha}=\begin{cases}
        0&1-\alpha>0\\
        +\infty&1-\alpha<0
    \end{cases}\\
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=\begin{cases}
        \displaystyle\frac{(b-a)^{1-\alpha}}{1-\alpha}&1-\alpha>0\\
        -\infty&1-\alpha<0
    \end{cases}
\end{gather*}
L'integrale improprio di seconda specie converge se $\alpha<1$, e diverge ad infinito se $\alpha\geq1$. 

%% TODO caso analogo: 
Calcolare al variare del parametro reale $\alpha\in\mathbb{R}$ la convergenza del seguente integrale:
\begin{gather*}
\displaystyle\int_a^b\frac{\mathrm{d}x}{(x-a)^\alpha}    
\end{gather*}
%% fine caso analogo


\subsubsection{Teormea ??} %% TODO add nome

Sia $f$ una funzione continua ed illimitata in $[a,b)$, inoltre sia $f(x)\geq0$, o $\leq0$, nell'intorno sinistro del punto singolare $(b-\varepsilon, b)$. Allora l'integrale improprio di seconda specie su $f(x)$ in questo intervallo è regolare. 

\subsubsection{Teoream del Criterio del Confronto}

Siano $f$ e $g$ continue e illimitate in $[a, b)$, e sia $\forall x\in(b-\varepsilon, b)$ la funzione $f$ maggiorata dalla funzione $g$: $0\leq f(x)\leq g(x)$. 
Allora se l'integrale improprio della funzione maggiorante converge, allora converge anche l'integrale improprio della funzione minorante converge:
\begin{gather*}
    \displaystyle\int_a^b g(x)\mathrm{d}x:\mbox{converge}\implies
    \displaystyle\int_a^b f(x)\mathrm{d}x:\mbox{converge}
\end{gather*}
Inoltre se l'integrale improprio della funzione minorante diverge, allora pure l'integrale improprio della funzione maggiorante diverge. 
\begin{gather*}
    \displaystyle\int_a^b f(x)\mathrm{d}x=\pm\infty\implies
    \displaystyle\int_a^b g(x)\mathrm{d}x=\pm\infty
\end{gather*}


%% ESEMPIO

Studiare la convergenza di questo integrale improprio:
\begin{gather*}
    \displaystyle\int_0^1\frac{3-\sin x}{\sqrt{x}}\mathrm{d}X
\end{gather*}
È un integrale improprio di seconda specie, poiché in $x=0$ è presente una singolarità, ed è sempre positivo per $x\geq0$, essendo $\sin x<3$. 
Si può maggiorare e minorare il numeratore:
\begin{gather*}
    2\leq3-\sin x\leq4
\end{gather*}
Poiché il valore massimo e minimo del seno sono $\pm1$. La funzione integranda è sicuramente maggiorabile con la funzione:
\begin{gather*}
    \displaystyle\frac{3-\sin x}{\sqrt{x}}\leq\frac{4}{\sqrt{x}}
\end{gather*}
Sicuramente questa condizione vale nell'intervallo $[0,1]$. Si calcola l'integrale improprio di seconda specie della funzione maggiorante:
\begin{gather*}
    \displaystyle\int_0^1\frac{\mathrm{d}x}{\sqrt{x}}:\mbox{converge}
\end{gather*}
Converge poiché è un integrale immediato già trattato. 


%% ALTRO CRITERIO/TEOREMA

Siano $f$ e $g$ continue e illimitate in $[a, b)$, e sia $\forall x\in(b-\varepsilon, b)$ che entrambi le funzioni $f(x)$ e $g(x)$ nell'intervallo $(b-\varepsilon, b)$ mantengano lo stesso segno: $0\leq f(x)\land0\leq g(x)$. %% TODO fix wording

Allora se:
\begin{gather*}
    \lim_{x\to b^-}\frac{f(x)}{g(x)}=l\in\mathbb{R}^+\implies \int_a^b f(x)\mathrm{d}x\land\int_a^b f(x)\mathrm{d}x:\mbox{hanno lo stesso carattere}
\end{gather*}
Un caso particolare è che $f(x)\sim g(x)$, se questo è verificato allora gli integrali impropri di queste due funzioni hanno lo stesso carattere. Questa è una condizione parallela ed indipendente. 
Se invece il limite del rapporto per $x\to b^-$ è nullo ed inoltre, l'integrale sull'intervallo $[a,b)$ di $g(x)$ converge, allora converge anche l'integrale di $f(x)$:
\begin{gather*}
    \displaystyle\lim_{x\to b^-}\frac{f(x)}{g(x)}=0\land\int_a^bg(x)\mathrm{d}x\in\mathbb{R}\implies\int_a^bf(x)\mathrm{d}x\in\mathbb{R}
\end{gather*}
Invece se questo limite diverge ad infinito, e la funzione $g(x)$ non è integrabile in senso improprio, allora diverge anche l'integrale improprio della funzione $f(x)$:
\begin{gather*}
    \displaystyle\lim_{x\to b^-}\frac{f(x)}{g(x)}=\pm\infty\land\displaystyle\int_a^bg(x)\mathrm{d}x=\pm\infty\implies\int_a^bf(x)\mathrm{d}x=\pm\infty
\end{gather*}


%% ALTRO CRITERIO/TEOREMA ?? Convergenza Assoluta?

Siano $f$ continue e illimitate in $[a, b)$.  Se il modulo della funzione $|f(x)|$ è integrabile in senso improprio in $[a,b]$, allora converge anche l'integrale in senso improprio della funzione $f(x)$ in $[a,b]$. Si dice che la funzione $f(x)$ è assolutamente integrabile, se l'integrale converge in modo assoluto allora converge anche in modo semplice. 



%% ESEMPIO

Studiare la convergenza di questo integrale:
\begin{gather*}
    \displaystyle\int_0^1\frac{\sin\left(\frac{1}{x}\right)}{\sqrt[3]{x}}\mathrm{d}x
\end{gather*}
La funzione è continua ed illimitata in questo intervallo $(0,1]$. Questa funzione assume valori di segno diverso, e l'ampiezza dell'oscillazione aumenta per $x\to0^+$. Si valuta la convergenza della funzione di modulo per valutare eventuale convergenza assoluta:
\begin{gather*}
    \displaystyle\int_0^1\frac{\left|\sin\left(\frac{1}{x}\right)\right|}{\sqrt[3]{x}}\mathrm{d}x
\end{gather*}
Si utilizza il metodo del confronto:
\begin{gather*}
    \displaystyle\frac{\left|\sin\left(\frac{1}{x}\right)\right|}{\sqrt[3]{x}}\leq\frac{1}{\sqrt[3]{x}}
\end{gather*}
L'integrale improprio della funzione maggiorante converge, quindi anche l'integrale della funzione minorante converge. 
%% TODO motivo: poiché $\alpha<1$. 


%% ESERCIZIO

Si considera il carattere del seguente integrale:
\begin{gather*}
    \displaystyle\int_0^1\frac{x^2}{\sqrt{1-x}}\mathrm{d}x
\end{gather*}
La funzione integranda è continua ed illimitata in $[0,1)$ ha un punto critico in $x=1$, ha segno definitivamente positivo nell'intervallo $(1-\varepsilon, 1)$. 

\begin{gather*}
    \mbox{per}x\to1^-\displaystyle\frac{x^2}{\sqrt{1-x}}\sim\frac{1}{(1-x)^{1/2}}
\end{gather*}
È asintoticamente equivalente ad una funzione campione $(1-x)^{-\alpha}$, essendo $\alpha<1$ la funzione converge. 

\subsection{Integrali Impropri di Prima Specie}

Sia la funzione $f$ continua in $[a,+\infty)$, allora ha senso parlare dell'integrale:
\begin{gather*}
    \displaystyle\int_a^hf(x)\mathrm{d}x
\end{gather*}
Per $h>a$, una volta calcolato questo integrale, per ottenere il valore dell'integrale improprio sull'intero intervallo $[a,+\infty)$ si calcola il limite:
\begin{gather*}
    \lim_{h\to+\infty}\displaystyle\int_a^hf(x)\mathrm{d}x=\begin{cases}
        \exists\displaystyle\int_a^{+\infty}f(x)\mathrm{d}x\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{gather*}
Se il limite esiste, la funzione è integrabile in modo improprio nell'intervallo $[a,+\infty)$, analogamente l'integrale improprio di prima specie della funzione $f$ converge. Altrimenti il limite può non converge, oppure può essere irregolare e non esistere. 

Si determini il valore del seguente integrale improprio:
\begin{gather*}
    \displaystyle\int_{-\infty}^{+\infty}\frac{\df x}{1+x^2}
    =\lim_{h\to+\infty}\int_{-h}^h\frac{1}{1+x^2}\df x
\end{gather*}
Essendo una funzione pari si può esprimere come:
\begin{gather*}
    \displaystyle\int_{-\infty}^{+\infty}\frac{\df x}{1+x^2}=
    2\lim_{h\to+\infty}\int_0^h\frac{1}{1+x^2}\df x=
    2\lim_{h\to+\infty}\arctan x\bigg|_0^h=\pi\in\mathbb{R}
\end{gather*}


Studiare la convergenza del seguente integrale:
\begin{gather*}
    \displaybreak\intpinf{xe^{-x}}{x}=\lim_{h\to+\infty}\int_0^hxe^{-x}\df x=-\lim_{h\to+\infty}\int_0^he\df(e^{-x})=
    -\lim_{h\to+\infty}\left\{xe^{-x}\bigg|_0^h-\int_0^he^{-x}\df x\right\}\\
    -\lim_{h\to+\infty}\left\{he^{-h}+e^{-x}\bigg|_0^h\right\}=
    -\lim_{h\to+\infty}\left\{\overbrace{he^{-h}}^{\to0}+\underbrace{e^{-h}}{\to0}-1\right\}=-1
\end{gather*}


Studiare il seguente integrale:
\begin{gather*}
    \displaystyle\intab{e^2}{+\infty}{\frac{1}{x\ln^3 x}}{x}=\lim_{h\to+\infty}\int_{e^2}^{h}\frac{\df (\ln x)}{(\ln x)^3}=
    \lim_{h\to+\infty}\int_{e^2}^h(\ln x)^{-3}\df(\ln x)=\lim_{h\to+\infty}\frac{(\ln x)^{-2}}{2}\bigg|_{e^2}^h\\
    -\frac{1}{2}\lim_{h\to+\infty}\left\{\overbrace{\frac{1}{\ln^2 h}}^0-\frac{1}{\ln^2e^2}\right\}=\frac{1}{2}\frac{1}{4}=\frac{1}{8}
\end{gather*}


Studiare la convergenza del seguente integrale, al variare del parametro reale $\alpha\in\mathbb{R}$, con $a>0$:
\begin{gather*}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}
\end{gather*}
Si considera il primo caso per $\alpha=1$:
\begin{gather*}
    \displaystyle\int_a^{+\infty}\frac{1}{x}\df x=\lim_{h\to\infty}\ln x\bigg|_a^h=\lim_{h\to\infty}(\ln h-\ln 0)=+\infty
\end{gather*}
Per $\alpha\neq1$:
\begin{gather*}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}=\lim_{h\to\infty}\int_a^{+\infty}x^{-\alpha}\df x=\lim_{h\to\infty}\frac{x^{-\alpha+1}}{-\alpha+1}\bigg|_a^h=
    \frac{1}{1-\alpha}\lim_{h\to\infty}\left\{h^{1-\alpha}-a^{1-\alpha}\right\}
\end{gather*}
Si considera per quali esponenti si ha $h$ divergente o convergente a zero:
\begin{gather*}
    h^{1-\alpha}=\begin{cases}
        +\infty & \alpha<1\\
        0^+ & \alpha>1
    \end{cases}
\end{gather*}
Quindi l'integrale di partenza:
\begin{gather*}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}=
    \begin{cases}
        +\infty& \alpha\leq1\\
        l\in\mathbb{R}&\alpha>1
    \end{cases}
\end{gather*}

\subsubsection{Teorema Condizione Necessaria di Convergenza}

Sia $f$ continua nell'intervallo $[a,+\infty)$ e sia l'integrale $\int_a^{+\infty}f(x)\df x$ convergente, allora:
\begin{gather*}
    \lim_{x\to+\infty}f(x)=0
\end{gather*}

\subsubsection{Teorema ??}

Sia $f$ continua nell'intervallo $[a,+\infty)$ e sia $f$ definitivamente non negativa $f(x)\geq0$ in $(\delta, +\infty)$.
Allora l'integrale improprio della funzione $f(x)$ sull'intervallo $[a,+\infty)$ è regolare. 

\subsubsection{Criterio del Confronto}

Il criterio del confronto afferma le stesse nozioni enunciate nel criterio del confronto per integrali impropri di seconda specie. 
Siano $f$ e $g$ due funzioni continue nello stesso intervallo illimitato superiormente $[a,+\infty)$. E sia $0\leq f(x)\leq g(x)$ definitamente. 
%% TODO riscrivere in modo migliore
Allora se l'integrale di $g(x)$ converge, allora converge anche l'integrale di $f(x)$, invece se l'integrale sulla funzione $f(x)$ diverge, anche l'integrale di $g(x)$ diverge. 



Studiare il carattere del seguente integrale:
\begin{gather*}
    \displaystyle\int_1^{+\infty}\frac{2+\cos x}{x^2}\df x
\end{gather*}
Si può maggiorare e minorare:
\begin{gather*}
    \displaystyle\frac{1}{x^2}\leq\frac{2+\cos x}{x^2}\leq\frac{3}{x^2}\\
    \displaystyle\int_1^{+\infty}\frac{3}{x^2}\df x\in\mathbb{R}
\end{gather*}
Quindi converge anche l'integrale di partenza. 


Studiare il carattere del seguente integrale:
\begin{gather*}
    \displaystyle\int_0^{+\infty}\frac{2+\cos x}{x^2}\df x
\end{gather*}
Questo integrale è sia di prima che seconda specie. Si divide in due integrali per studiarne il carattere separatamente:
\begin{gather*}
    \displaystyle\int_0^{+\infty}\frac{2+\cos x}{x^2}\df x=
    \int_0^{1}\frac{2+\cos x}{x^2}\df x+
    \underbrace{\int_1^{+\infty}\frac{2+\cos x}{x^2}\df x}_{\mbox{converge}}
\end{gather*}

Per il teorema del confronto si ha:
\begin{gather*}
    \displaystyle\frac{1}{x^2}\leq\frac{2+\cos x}{x^2}\leq\frac{3}{x^2}\implies
    \displaystyle\int_0^{1}\frac{3}{x^2}\df x=\infty
\end{gather*}
Poiché $\alpha<1$, quindi l'integrale di partenza non converge. 

\subsubsection{Teorema del Confronto Asintotico}

Siano $f$ e $g$ due funzioni continue nello stesso intervallo illimitato superiormente $[a,+\infty)$. E sia $f(x),\,g(x)\geq0$ definitamente.

Allora se il limite:
\begin{gather*}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=l\in\mathbb{R}^+
\end{gather*}
Allora gli integrali impropri di $f(x)$ e $g(x)$ hanno lo stesso carattere, in particolare $f(x)\sim g(x)$ per $x\to\infty$. 

Invece se:
\begin{gather*}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=0
\end{gather*}
E l'integrale impropri della funzione $g(x)$ converge, allora anche l'integrale improprio di $f(x)$ converge. 


Se:
\begin{gather*}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=+\infty
\end{gather*}
E l'integrale improprio della funzione $g(x)$ diverge, allora anche l'integrale improprio sulla funzione $f(x)$ diverge. 

\subsubsection{Teorema Convergenza Assoluta}

Sia $f$ continua in $[a,+\infty)$, allora se l'integrale improprio:
\begin{gather*}
    \displaystyle\int_a^{+\infty}|f(x)|\df x
\end{gather*}
Converge, anche l'integrale improprio senza valore assoluto converge. Questo si dice criterio di convergenza assoluta ed implica la convergenza semplice. La funzione $f$ si dice assolutamente integrabile. 

%% TODO sin x/x^2 [1, inf) |sin x|/x^2
%% TODO sin x/x [1, inf) |sin x|/x => conv smp, div abs

\begin{gather*}
    \displaystyle\int_{1}^{+\infty}\frac{\sin x}x\df x
\end{gather*}
Non potendo utilizzare i teoremi, si calcola direttamente:
\begin{gather*}
    \displaystyle\int_{1}^{+\infty}\frac{\sin x}x\df x=
    \lim_{h\to\infty}\int_{1}^{h}\frac{-\df(\cos x)}x=
    -\lim_{h\to\infty}\left\{\frac{\cos x}{x}\bigg|_1^h+\intab{1}{h}{\frac{\cos x}{x^2}}{x}\right\}\\
    -\lim_{h\to\infty}\left\{\cancelto{0}{\frac{\cos h}{h}}-\cos1+\intab{1}{h}{\frac{\cos x}{x^2}}{x}\right\}=
    \lim_{h\to\infty}\left\{\cos1-\intab{1}{h}{\frac{\cos x}{x^2}}{x}\right\}\\
    \displaystyle\int_{1}^{+\infty}\frac{\sin x}x\df x=\cos1-\int_1^{+\infty}\frac{\cos x}{x^2}\df x
\end{gather*}
Si è trasformato l'integrale di partenza in un integrabile dove è applicabile il teorema del confronto, e si dimostra che converge. %% TODO

%% TODO Dimostrare convergenza di cos x/x sullo stesso intervallo 

Dimostrare che:
\begin{gather*}
    \displaystyle\int_1^{+\infty}\frac{|\sin x|}{x}\df x=+\infty
\end{gather*}
Si suppone per assurdo che questo integrale converga, la funzione è sicuramente maggiorabile da:
\begin{gather*}
    \sin^2x\leq|\sin x|\leq1
\end{gather*}
Ma per il teorema del confronto converge anche l'integrale della funzione minorante:
\begin{gather*}
    \displaystyle\int_{1}^{+\infty}\frac{\sin^2 x}x\df x
\end{gather*}
sfruttando la formula di duplicazione del coseno:
\begin{gather*}
    \displaystyle\int_{1}^{+\infty}\frac{\sin^2 x}x\df x=
    \int_1^{+\infty}\frac{1-\cos2x}{2x}\df x=
    \frac{1}{2}\int_1^{+\infty}\frac{\df x}{x}-\int_1^{+\infty}\frac{\cos(2x)}{2x}\df (2x)
\end{gather*}
Il secondo integrale corrisponde a quello dimostrato precedentemente, il primo è un integrale notevole che diverge, ma per ipotesi converge, quindi l'ipotesi iniziale è errata e quindi l'integrale non converge. 

\subsection{Funzioni}
%% DEF 1
Le serie di Fourier sono serie di funzioni utilizzate per approssimare funzioni periodiche. Una funzione $f$ definita su $D_f$ illimitato, si dice periodica di periodo $T$ se $\forall x\in D_f$ si ha:
\begin{enumerate}
    \item $x+kT\in D_f\,\,\forall k\in\mathbb{Z}$
    \item $f(x+kT)=f(x)$
\end{enumerate}
%% DEF 2
Una funzione $f$ si dice continua a tratti in un intervallo limitato $I$, se $f$ è continua in $I$, tranne che in una quantità finita di punti di discontinuità di prima o terza specie. 

È integrabile in $I$ ed il suo integrale esiste, è utile poiché per determinare la serie di Fourier bisognerà risolvere integrali. 

%% DEF 3
Una funzione $f$ si dice regolare a tratti in un intervallo limitato $I$, se è continua a tratti in $I$, e se ha derivata continua in $I$ tranne che nel punto di discontinuità più altri punti dove $f$ non è derivabile, in quantità finita. In tali punti esistono finiti i limiti $\lim_{x\to x_0^-}f'(x)\neq\lim_{x\to x_0^+}f'(x)$. 

% punto angoloso , discontinuità a tratti
Una funzione si dire continua o regolare a tratti in $\mathbb{R}$, se in lo è in ogni arbitrario intervallo limitato. 


%% IMG serie di triangoli /\/\/\/\/\

Sia $f$ una funzione continua a tratti in $\mathbb{R}$ è periodica di periodo $T$, l'integrale su un periodo $T$, $\forall a\in\mathbb{R}$, si può esprimere in maniera equivalente come:
\begin{gather*}
    \displaystyle\intab{a}{a+T}{f(x)}{x}=
    \displaystyle\intab{0}{T}{f(x)}{x}=
    \displaystyle\intab{-T/2}{T/2}{f(x)}{x}
\end{gather*}
Per semplicità si vuole considerare un intervallo simmetrico, per facilitare il calcolo, sfruttando eventuali simmetrie della funzione. 


La serie di Fourier di $f$ viene definita come:
\begin{gather}
    \displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)+b_k\sin\left(\frac{2k\pi}{T}x\right)
\end{gather}
Dove i coefficienti $a_k$ e $b_k$ sono dati da:
\begin{gather}
    a_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x\\
    b_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x
\end{gather}

Può succedere che la funzione $f$ rispetta la simmetria, e quindi si possono semplificare queste formule. Se $f$ è pari:
\begin{gather*}
    a_k=\displaystyle\frac{4}{T}\int_{0}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x\\
    b_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x=0\\
    \displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)
\end{gather*}
Mentre se $f$ è dispari si ha:

\begin{gather*}
    a_k=\displaystyle\frac{4}{T}\int_{-T/2}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x=0\\
    b_k=\displaystyle\frac{4}{T}\int_{0}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x\\
    \displaystyle\sum_{k=1}^\infty b_k\sin\left(\frac{2k\pi}{T}x\right)
\end{gather*}

\subsubsection{Teorema}
Sia $f$ regolare a tratti in $\mathbb{R}$ ed inoltre sia periodica di periodo $T$. Allora se $f$ è continua in $x_0$:
\begin{gather*}
    \displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)+b_k\sin\left(\frac{2k\pi}{T}x\right)=f(x_0)
\end{gather*}
Se $f(x)$ non è continua in $x_0$ allora:
\begin{gather*}
    \displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)+b_k\sin\left(\frac{2k\pi}{T}x\right)=\frac{f(x_0^-)+f(x_0^+)}{2}\,\mbox{dove}\\
    f(x_0^-)=\lim_{x\to x_0^-}f(x)\\
    f(x_0^+)=\lim_{x\to x_0^+}f(x)
\end{gather*}

    
\clearpage

\section{Equazioni Differenziali} 
%% 3/4/25

Le equazioni differenziali sono un modello matematico di tipo algebrico, sono un modo di studiare un fenomeno, in genere fisico. Prima di studiare il fenomeno bisogna studiare le grandezze di questo fenomeno, ed in seguito bisogna individuare un legame per definire o possibilmente determinare l'evoluzione del fenomeno stesso. 

Un'equazione differenziale è un'equazione dove l'incognita è una funzione $y=f(x)$, continua nell'intervallo su cui è definita l'equazione, e sono presenti dei termini differenziali di $n$-esimo ordine della funzione $y$:
\begin{equation}
    f(x, y, y', \cdots, y^{(n)})=0
\end{equation}
La funzione e tutte le sue derivate sono tutte definite su un insieme dell'asse reale $\mathbb{R}$. 

Considerando il valore generico della variabile indipendente $x$, l'equazione differenziale è una relazione tra i valori della $x$ ed i valori assunti dalla funzione incognita e le sue derivate. 
Per ordine dell'equazione si intende ordine massimo della derivata presente nell'equazione, $n-$esimo. Se è possibile esplicitare la derivata $n-$esima dell'equazione, allora l'equazione si dice espressa in forma normale:
\begin{equation}
    y^{(n)}=f(x, y, y', \cdots, y^{(n-1)})
\end{equation}

Un'equazione differenziale si dice lineare se sia la funzione che le sue derivate sono elevate ad una potenza massima pari ad uno, e non sono presenti termini misti. 


Si considera un'equazione differenziale ordinaria di primo ordine $y'=f(x,y)$, si possono rappresentare sul piano le coppie di questa funzione $(\bar{x},\bar{y})$, e la derivata ha un significato grafico ovvero la pendenza in questo punto. Questa funzione viene definita in un intervallo che individua un rettangolo, se per ogni punto di questo insieme si può disegnare 
un segmento che rappresenta la pendenza in questo punto, si genera una figura simile ad un campo vettoriale. La funzione $y'$ è l'inviluppo di tutti questi segmenti così individuati. 

%% TODO ??
% Sia un valore $x_0\in I$, dove $I$ è l'intervallo su cui è definita l'equazione differenziale, e la funzione $f(x)$ è continua. Se $y_0=y(x_0)\neq0$, nell'intorno di $x_0$, $I(x_0)$, la funzione $y(x)$ ha sempre lo stesso segno:
% \begin{gather*}
%     x\in I(x_0):y(x)\neq0\implies \displaystyle\frac{y(x)}{y_0}>0
% \end{gather*}


\subsection{Equazione a Variabili Separabili}

Un'equazione differenziale ordinaria a variabili separabili è un'equazione che può essere ricondotta ad una forma nota come la seguente:
\begin{equation}
    y'=g(x)\cdot h(y)
\end{equation}
Si considerano integrali singolari, che corrispondono alle soluzioni di $h(y)=0$, questi integrali singolari vengono esclusi dai procedimenti successivi, per $h(y)\neq0$, si può risolvere considerando:
\begin{gather*}
    \displaystyle\frac{\df y}{\df x}=g(x)\cdot h(y)\\
    \displaystyle\frac{1}{h(y)}\df y=g(x)\df x\\
    \displaystyle\int\frac{1}{h(y)}\df y=\int g(x)\df x
\end{gather*}
In seguito si prova ad esprimere esplicitamente l'incognita $y$ in funzione della variabile indipendente $x$. Questo primo modo di procedere è laborioso. 
Si può risolvere in modo più rigoroso considerando la primitiva del primo membro:
\begin{gather*}
    H(y)=\displaystyle\int\frac{1}{h(y)}\df y\implies H'(y)=\frac{1}{h(y)}
\end{gather*}
Sostituendola nell'equazione di partenza si ottiene:
\begin{gather*}
    H'(y)y'=g(x)
\end{gather*}
Il primo membro ora somiglia alla derivata di una funzione composta, quindi si può riscrivere come:
\begin{gather*}
    \displaystyle\frac{ \df H}{\df x}=g(x)\\
    \displaystyle H(y(x))=\int g(x)\df x+c
\end{gather*}
Quindi in teoria $H(y)$ è una funzione monotona, e quindi continua, poiché la sua derivata è il reciproco di $h(y)$ e non si annulla, quindi è invertibile. Si può quindi considerare la funzione inversa di $H(y)$: $H^{-1}(y)$. Applicandola membro a membro all'equazione ottenuta precedentemente si ottiene:
\begin{gather}
    H^{-1}\left[H(y(x))\right]=y(x)=H^{-1}\left[\displaystyle\int g(x)\df x+c\right]
\end{gather}
Anche se la funzione è invertibile non è detto che si riesca ad individuare la sua inversa, per cui a volte bisogna accontentarsi dell'espressione implicita: 
\begin{gather*}
    \displaystyle H(y(x))=\int g(x)\df x+c
\end{gather*}


%% ESEMPIO

Si considera la seguente equazione differenziale:
\begin{gather*}
    y'=y(1-y)
\end{gather*}
Si individuano gli integrali singolari in $y_0=0$ e $y_1=1$, si separano ora le variabili e si ottiene la seguente:
\begin{gather*}
    \displaystyle\frac{\df y}{y(1-y)}=\df x\\
    \displaystyle\int \frac{\df y}{y(1-y)}=\int \df x=x+c_0
\end{gather*}
Si separa la funzione integranda del primo membro in fratti semplici:
\begin{gather*}
    \displaystyle\int\frac{\df y}{y(1-y)}=\int\frac{\df y}{y}-\int\frac{\df y}{y-1}=x+c_0\\
    \ln|y|-\ln|y-1|+c_1=x+c_0\,\land c_2=c_0-c_1\\
    \ln|y|-\ln|y-1|=x+c_2\\
    \ln\left|\displaystyle\frac{y}{y-1}\right|=x+c_2
\end{gather*}

Per eliminare il logaritmo si considera entrambi i membri come l'argomento dell'esponenziale:
\begin{gather*}
    \displaystyle\frac{y}{y-1}=e^{c_2}e^x=c_3e^x\\
    y=c_3e^x(y-1)=c_3ye^x-c_3e^x\\
    y(1-c_3e^x)=-c_3e^x\implies y=-\frac{c_3e^x}{1-c_3e^x}=\frac{c_3e^x}{c_3e^x-1}
\end{gather*}


Si considera la seguente equazione differenziale:
\begin{gather*}
    y'=\displaystyle\frac{e^x+1}{e^y+1}
\end{gather*}
Integrali singolari corrispondono a $e^y+1=0$, ma non esistono valori reali di $y$ tali da annullare il denominatore: $\nexists y\in\mathbb{R}$. 
Si separano le variabili:
\begin{gather*}
    \displaystyle\int(e^y+1)\df y=\int (e^x+1)\df x\\
    e^y+y+c_0=e^x+x+c_1\implies e^y+y=e^x+x+c_2
\end{gather*} 

\subsection{Problema di Cauchy}

Il problema di Cauchy consiste nell'assegnare una condizione iniziale ad un'equazione differenziale:
\begin{gather*}
    \begin{cases}
        y'=f(x,y)\\
        y(x_0)y_0
    \end{cases}
\end{gather*}


%% TODO esercizi y'=(1+y^2)?? y'=cos^2y->y=arctan(x+c)
\subsection{le equazioni differenziali lieari del primo ordine}

Sono equazioni del tipo:
\begin{gather*}
    y'+p(x)y=f(x)
\end{gather*}
Dove le funzioni $p$ ed $f$ sono definite su un intervallo dove è definita anche la funzione incognita $y(x)$. La funzione $p$ viene chiamata funzione coefficiente e la funzione $f$ funzione forzante. Per risolvere questo tipo di equazioni è fondamentale la determinazione del fattore integrante.
% cia u sei kattivaciaOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO

Si considera la seguente equazione differenziale:
\begin{gather*}
    y'+\displaystyle\frac{2}{x}y=\frac{2}{x^3}\\
    x^2y'+2xy=\displaystyle\frac{\df (x^2y)}{\df x}=\frac{2}{x}\\
    \displaystyle x^2y=\int \frac{2}{x}\df x=2\ln x + c
\end{gather*}

Si vuole lavorare in modo che un membro diventi una derivata, considerando l'equazione generale si moltiplicano ambo i lati per la funzione $\mu$:
\begin{gather*}
    \mu y'+\mu p(x)y=\mu f(x)
\end{gather*}% !! <3 ily 2
Si vuole avere la derivata del prodotto al primo membro:
\begin{gather*}
    (\mu y)'=\mu'x+\mu y'\\
    \cancel{\mu y'}+\mu p(x)y=\mu'x+\cancel{\mu y'}\\
    \mu p(x)=\mu'\implies\displaystyle\int\frac{y'}{y}=p(x)\\
    \ln\mu=\displaystyle\int p(x)\df x\\
    \mu=e^{\int p(x)\df x}
\end{gather*}

%% TODO si può riportare in equazione a variabili separabili

%% ESEMPIO

Si considera il seguente problema di Cauchy:
\begin{gather*}
    \begin{cases}
        y'+5y=0\\
        y(1)=-2
    \end{cases}
\end{gather*}
Si determina il fattore integrante:
\begin{gather*}
    A(x)=\displaystyle\int p(x)\df x=\int5\df x=5x\\
    e^{A(x)}=e^{5x}
\end{gather*}
Si moltiplica l'equazione differenziale per il fattore integrante appena trovato e si determina la derivata di partenza:
\begin{gather*}
    e^{5x}(y'+5y)=D[y\cdot e^{5x}]=0
\end{gather*}
Poiché la derivata è nulla, la funzione è costante quindi si ha:
\begin{gather*}
    y\cdot e^{5x}=c\implies y=ce^{-5x}
\end{gather*}
Per determinare il valore della costante $c$ si inserisce il vincolo:
\begin{gather*}
    y(1)=ce^{-5(1)}=-2\implies c=-2e^5\\
    y=-2e^5e^{-5x}=-2e^{5(1-x)}
\end{gather*}


Considerare il seguente problema di Cauchy :
\begin{gather*}
    \begin{cases}
        \displaystyle x'(t)-\frac{1}{t+1}x(t)=3\\
        x(0)=1 & t\in(-1,+\infty)
    \end{cases}\\
    A(t)=\displaystyle-\int\frac{1}{t+1}\df t=-\ln(t+1)+c_0\implies e^{A(t)}=\frac{e^{c_0}}{t+1}\\
    \displaystyle\frac{e^{c_0}}{t+1}\left[ x'(t)-\frac{1}{t+1}x(t)\right]=\frac{3}{t+1}=D\left[\frac{x}{t+1}\right]\\
    \displaystyle\cancel{\int}\cancel{\df}\left(\frac{x}{t+1}\right)=e^{-c_0}\int \frac{3}{t+1}=3e^{-c_0}\ln(t+1)+c_1e^{-c_0}\\
    x=(t+1)e^{-c_0}\ln(t+1)^3+c_1e^{-c_0}(t+1)
\end{gather*}

\end{document}
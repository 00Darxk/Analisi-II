\documentclass{article}

\usepackage{cancel}
\usepackage{amsmath,amssymb}
\usepackage[includehead,nomarginpar]{geometry}
\usepackage{graphicx}
\usepackage{amsfonts} 
\usepackage{verbatim}
\usepackage{mathrsfs}  
\usepackage{lmodern}
\usepackage{braket}
\usepackage{bookmark}
\usepackage{fancyhdr}
\usepackage{romanbarpagenumber}
%\usepackage{minted}
%\usepackage{subfig}
\usepackage[italian]{babel}
\usepackage{float}
%\usepackage{wrapfig}
%\usepackage[export]{adjustbox}
\usepackage{contour}
\usepackage[normalem]{ulem}
\allowdisplaybreaks

\setlength{\headheight}{12.0pt}
\addtolength{\topmargin}{-12.0pt}
\graphicspath{ {./Immagini/} }

%% TODO add metadata
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    pdftitle={Appunti di Analisi II},
    pdfauthor={Giacomo Sturm},
    pdfsubject={Analisi II},
    pdfkeywords={}
}

\newsavebox{\tempbox} %{\raisebox{\dimexpr.5\ht\tempbox-.5\height\relax}}


\makeatother
%% Derivate:
\newcommand{\df}{\mathrm{d}}
\newcommand{\diff}[2]{\displaystyle\frac{\df{#1}}{\df{#2}}}
\newcommand{\diffn}[3]{\displaystyle\frac{\df^{#3}{#1}}{\df{#2}^{#3}}}
\newcommand{\pdiff}[2]{\displaystyle\frac{\partial{#1}{\partial{#2}}}}
\newcommand{\pdiffn}[3]{\displaystyle\frac{\partial^{#3}{#1}{\partial{#2}^{#3}}}}

%% Integrali:
\newcommand{\intab}[4]{\displaystyle\int_{#1}^{#2}{#3}\df{#4}}
\newcommand{\intinf}[2]{\intab{-\infty}{+\infty}{#1}{#2}}
\newcommand{\intpinf}[2]{\intab{0}{+\infty}{#1}{#2}}
\newcommand{\intninf}[2]{\intab{-\infty}{0}{#1}{#2}}

%% Sommatorie:
\newcommand{\sumab}[4]{\displaystyle\sum_{#4=#1}^{#2}{#4}}
\newcommand{\suminf}[2]{\sumab{-\infty}{+\infty}{1}{2}}
\newcommand{\sumpinf}[2]{\sumab{0}{+\infty}{1}{2}}
\newcommand{\sumninf}[2]{\sumab{-\infty}{0}{1}{2}}

\renewcommand{\contentsname}{Indice}
\numberwithin{equation}{subsection}
\newcommand{\tageq}{\tag{\stepcounter{equation}\theequation}}
\AtBeginDocument{%
    \renewcommand{\figurename}{Fig.}
}
\renewcommand{\ULdepth}{1.8pt}
\contourlength{0.6pt}
\newcommand{\myuline}[1]{%
    \uline{\phantom{#1}}%
    \llap{\contour{white}{#1}}%
}
\fancypagestyle{link}{\fancyhf{}\renewcommand{\headrulewidth}{0pt}\fancyfoot[C]{Sorgente del file \LaTeX ed ultima versione del testo disponibile al link: \url{https://github.com/00Darxk/Analisi-II/}}}

\begin{document}

\title{%
    \textbf{Analisi II}  \\ 
    \large Appunti delle Lezioni di Analisi II \\
    \textit{Anno Accademico: 2024/25}}
\author{\textit{Giacomo Sturm}}
\date{\textit{Dipartimento di Ingegneria Industriale, Elettronica e Meccanica \\
Università degli Studi ``Roma Tre"}} 

\maketitle
\thispagestyle{link}

\clearpage


\pagestyle{fancy}
\fancyhead{}\fancyfoot{}
\fancyhead[C]{\textit{Analisi II - Università degli Studi ``Roma Tre"}}
\fancyfoot[C]{\thepage}
\pagenumbering{Roman}

\tableofcontents

%% TODO numerare equazioni

\clearpage
\pagenumbering{arabic}

\section{Serie Numerica}

%% TODO aggiungere commento a qualche sezione Si vuole approssimare funzioni come la somma di una serie parametriche rispetto ad una fattore $x$, che diventerà la variabile indipendente della funzione. Una funzione algebrica si può rappresentare come una certa serie, dimostrato nel caso di una serie telescopica e geometrica. Per serie di segno definitivamente positivo è possibile rappresentarle in forma esplicita, mentre per serie che non rispettano questa condizione, molto probabilmente non è possibile, quindi non è possibile ottenere una rappresentazione algebrica di queste. 

Una serie numerica $\{a_n\}$ è una \textit{particolare} successione numerica; 
è una particolare funzione che ha come dominio l'insieme dei numeri naturali $\mathbb{N}$ e come codominio un sottoinsieme $\mathbb{C}$ dell'asse dei numeri reali $\mathbb{R}$. 
\begin{equation}
    \{a_n\}:\mathbb{N}\rightarrow\mathbb{C}\in\mathbb{R}
\end{equation}

Quindi è di interesse studiare il comportamento della serie numerica quando la variabile indipendente $n$ tende all'infinito. Data una successione numerica, si interessa quindi:
\begin{equation}
    \lim_{n\to\infty}a_n
\end{equation}

Si generalizza nel limite di una funzione quando si sostituisce alla variabile $n$ una variabile indipendente reale $x\in\mathbb{R}$. 

Una successione può convergere ad un numero reale, può divergere positivamente o negativamente, in questi due casi è regolare, quindi ha un limite definito o indefinito. Altrimenti è possibile che il limite non esiste, quindi la sequenza non si stabilisce su nessun numero reale ed oscilla per $n$ tendente ad $\infty$. 

\begin{equation}
    \lim_{n\to\infty}a_n=\begin{cases}
        i\in\mathbb{R}\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{equation}

Si costruisce una serie numerica $\{s_n\}$, partendo da una sequenza nota $\{a_k\}$, si può costruire definendo per ogni valore $n$ il valore di $s_n$ tale sia pari alla somma dei primi $a_n$ elementi della sequenza:
\begin{equation}
    \forall n\in\mathbb{N}:\,
    s_n:=a_1+\cdots+a_n
\end{equation}

$s_n$ viene chiamata somma parziale della serie $\{s_n\}$ e viene definita con il seguente simbolo:
\begin{equation}
    s_n:=\displaystyle\sum_{k=1}^\infty a_k
\end{equation}
La serie numerica è la successione delle somme parziali che costruisce sulla successione $\{a_k\}$. 

Una serie numerica si dice convergente se il limite della successione delle somme parziali, costruite a partire dalla successione $a_k$, è pari ad un numero $s$:
\begin{equation}
    \{s_n\}: \mbox{converge se}\,\lim_{n\to\infty}s_n=s\in\mathbb{R}
\end{equation}

Si dice divergente se il limite della successione delle somme parziali tende ad infinito:
\begin{equation}
    \{s_n\}: \mbox{diverge se}\,\lim_{n\to\infty}s_n=\pm\infty
\end{equation}

Se converge o diverge la serie numerica si dice regolare, se invece studiando il comportamento delle somme parziali per $n\to\infty$, il limite della somma non è definito, quindi la serie si dice irregolare:
\begin{equation}
    \{s_n\}: \mbox{irregolare se}\,\lim_{n\to\infty}s_n=\nexists
\end{equation}

Studiare il comportamento della serie vuol dire studiare il comportamento delle somme parziali. La somma parziali si avrà sempre in forma aperta, se fosse possibile esprimere in forma chiusa la forma parziale, allora il limite è di facile calcolo. 

%% ESEMPIO

Considerando il seguente limite:
\begin{equation*}
    \lim_{n\to\infty}(1+2+\cdots+n)
\end{equation*}
Esiste una funzione per esprimere in forma chiusa questa funzione, dimostrabile per induzione:
\begin{equation*}
    \lim_{n\to\infty}\left(\displaystyle\frac{n(n+1)}{2}\right)=+\infty
\end{equation*}

Quindi è facile determinare che si tratta di una serie divergente ad infinito positivo. Questo passaggio non d'ora in avanti non sarà più possibile, basterà stabilire il carattere di una serie, senza sapere il valore a cui converga. Solo nel caso della serie telescopica e della serie geometrica sarà possibile determinare il valore della convergenza. 

\subsection{Serie Telescopica}

Il caso più rappresentativo di una serie telescopica è la seguente:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k(k+1)}
\end{equation}

Analizzando la somma parziale $s_n$ fino ad un certo valore $n\in\mathbb{N}$ si ha:
\begin{gather*}
    s_n=\displaystyle\sum_{k=1}^n\frac{1}{k(k+1)}=\frac{1}{2}+\cdots+\frac{1}{n(n+1)}
\end{gather*} 

Utilizzando la tecnica dei fratti semplici si può riscrivere la somma parziale come:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k(k+1)}=\sum_{k=1}^\infty\left(\frac{1}{k}-\frac{1}{k+1}\right)
\end{gather*}

In questo modo calcolando la somma parziale si ottiene:
\begin{gather*}
    s_n=\displaystyle\sum_{k=1}^n\left(\frac{1}{k}-\frac{1}{k+1}\right)\\
    \left({1}-\frac{1}{2}\right)+
    \left(\frac{1}{2}-\frac{1}{3}\right)+
    \left(\frac{1}{3}-\frac{1}{4}\right)+
    \cdots+
    \left(\frac{1}{n-1}-\frac{1}{n}\right)+
    \left(\frac{1}{n}-\frac{1}{n+1}\right)
\end{gather*}
Si può notare come l'addendo 1/2 si cancella con l'addendo della differenza successiva, così con 1/3, così per ogni valore della sommatoria, permettendo quindi di scrivere la somma parziale $s_n$ in forma chiusa esprimendo solamente il primo addendo e l'ultimo addendo:
\begin{gather*}
    \left({1}-\cancel{\frac{1}{2}}\right)+
    \left(\cancel{\frac{1}{2}}-\bcancel{\frac{1}{3}}\right)+
    \left(\bcancel{\frac{1}{3}}-\cancel{\frac{1}{4}}\right)+
    \cdots+
    \left(\bcancel{\frac{1}{n-1}}-\cancel{\frac{1}{n}}\right)+
    \left(\cancel{\frac{1}{n}}-\frac{1}{n+1}\right)=
    1-\frac{1}{n+1}
\end{gather*}

Considerando il limite di questa serie si ha:
\begin{equation*}
    \lim_{n\to\infty}\left(1-\displaystyle\frac{1}{n+1}\right)=1
\end{equation*}

In generale una serie telescopica, ha i suoi termini $a_k$ definiti come la differenza tra il termine $k+1$-esimo ed il termine $k$-esimo di una particolare successione $\{A_k\}$:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty a_k=\sum_{k=1}^\infty\left(A_{k+1}-A_{k}\right)
\end{equation*} 

\subsection{Serie Geometrica}

La serie geometrica è esprimibile come:
\begin{equation*}
    \displaystyle\sum_{k=0}^\infty x^k
\end{equation*}
Come altre serie dipende da un parametro reale $x\in\mathbb{R}$, questo si chiama ragione della serie. 

Si costruisce la somma parziale della serie:
\begin{equation*}
    s_n=\displaystyle\sum_{k=0}^n x^k=1+x+x^2+\cdots+x^n    
\end{equation*}
Si vuole esprimere questa somma in forma chiusa. Per $x=0$, per ogni valore di $n$, la somma vale sempre $1$, poiché:
\begin{gather*}
    \forall n\in\mathbb{N}: s_n=0^0+0^1+0^2+\cdots+0^n=1
\end{gather*}

Un altro caso analogo con $x=1$, si ha la seguente somma parziale:
\begin{gather*}
    \forall n\in\mathbb{N}: s_n=1+1+1+\cdots+1=1\cdot n
\end{gather*}

Questa serie quindi converge per $x=0$, diverge per $x=1$, mentre per altri valori reali non è ancora noto il suo comportamento. 
Si considera ora il caso generale con una ragione diversa da zero e da uno $\forall x\in\mathbb{R}\setminus\{0,1\}$. 
Si considera noto il valore $s_n$:
\begin{equation*}
    s_n=\displaystyle\sum_{k=0}^n x^k=1+x+x^2+\cdots+x^n    
\end{equation*}
Si moltiplica la somma parziale per la ragione e si sottrae alla somma parziale:
\begin{gather*}
    xs_n=x\cdot\displaystyle\sum_{k=0}^n x^k=\sum_{k=1}^nx^k\\
    (1-x)s_n=1+x+x^2+\cdots+x^n-\left(x+x^2+x^3+\cdots+x^n+x^{n+1}\right)=1-x^{n+1}
\end{gather*}

Della prima somma sopravvive solamente il primo addendo $1$, e della seconda l'ultimo addendo $x^{n+1}$, tutti gli altri si cancellano a vicenda, quindi per ottenere il valore della somma parziale si divide il primo ed il secondo membro per il fattore $1-x$:
\begin{equation}
    s_n=\displaystyle\frac{1-x^{n+1}}{1-x}
\end{equation}
Si provvede ora a calcolare il limite di questa somma parziale, dividendolo per la proprietà di linearità, supponendo che questi due limiti risultanti non corrispondono ad una forma indeterminata:
\begin{equation*}
    \lim_{n\to\infty}\displaystyle\frac{1-x^{n+1}}{1-x}=\lim_{n\to\infty}\frac{1}{1-x}-\lim_{n\to\infty}\frac{x^{n+1}}{1-x}
\end{equation*}
Il primo fattore non dipende da $n$, per il limite corrisponde a sé stesso, in seguito si mette in evidenza il fattore $1-x$ ottenendo:
\begin{equation*}
    \displaystyle\frac{1}{1-x}\left(1-\lim_{n\to\infty}x^{n+1}\right)
\end{equation*}
Il comportamento di questo limite dipende dalla ragione:
\begin{gather*}
    \lim_{n\to\infty}x^{n+1}=\begin{cases}
        0 &-1<x<1\\
        +\infty  & x>1\\
        \nexists & x\leq-1
    \end{cases}
\end{gather*}
Per $|x|<1$ la funzione è decrescente, e tende a zero, mentre per $x>1$, la funzione è esponenziale e quindi tende ad infinito. Invece per $x<-1$ si considera il limite, mettendo in evidenza il segno negativo:
\begin{gather*}
    \lim_{n\to\infty}(-|x|)^{n+1}=
    \lim_{n\to\infty}\left[(-1)^{n+1}\cdot |x|^{n+1}\right]
\end{gather*}
Il secondo fattore diverge, mentre il primo fattore oscilla di segno in base alla parità di $n$, per cui questa funzione oscilla di ampiezza sempre maggiore, per cui è irregolare. 
Per $x=-1$ il secondo fattore vale uno, mentre il primo fattore si considera comunque, per cui continua ad oscillare alla stessa ampiezza, quindi rappresenta allo stesso modo un comportamento irregolare. 

Noto il comportamento di questo limite allora il valore della serie geometrica in base alla ragione è dato da:
\begin{equation*}
    \displaystyle\sum_{k=0}^\infty=\begin{cases}
        \displaystyle\frac{\strut 1}{\strut 1-x} &-1<x<1\\
        +\infty & x\geq1\\
        \nexists & x\leq-1
    \end{cases}
\end{equation*}

Questa serie ha un addendo in più poiché parte da $k=0$, per cui esprimendola come una serie partendo da $k=1$:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty=\displaystyle\sum_{k=0}^\infty-1
\end{equation*}
Il valore di questa successione quindi si comporta analogamente al precedente, considerando l'addendo in più:

\begin{equation*}
    \displaystyle\sum_{k=1}^\infty=\begin{cases}
        \displaystyle\frac{\strut 1}{\strut 1-x}-1 &-1<x<1\\
        +\infty & x\geq1\\
        \nexists & x\leq-1
    \end{cases}
\end{equation*}

\subsection{Criteri di Convergenza}

Esistono vari criteri per determinare la convergenza di una serie numerica. 

%% PRIMO CRITERIO

Il primo criterio definisce una condizione necessaria per la convergenza di una serie geometrica. 
Si considera per ipotesi che una data serie numerica converge, equivale a dire che la serie delle somme parziali converge:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty a_k\rightarrow s_n=\sum_{k=1}^n a_k\\
    \lim_{n\to\infty}s_n=s
\end{gather*}

Considerando il limite della successione generata aumentando l'indice di uno $n+1$, la combinazione lineare tra queste due successioni converge a zero, poiché rappresentano la stessa successione traslata di un elemento:
\begin{gather*}
    \lim_{n\to\infty}s_{n+1}=s\\
    \lim_{n\to\infty}(s_{n+1}-s_n)=0
\end{gather*}
La successione $s_{n+1}$ corrisponde alla prima successione $s_n$ sommata ad un ulteriore elemento $a_{n+1}$, per cui si può riscrivere la loro differenza come:
\begin{gather*}
    s_{n+1}=s_n+a_{n+1}\\
    s_{n+1}-s_{n}=a_{n+1}
\end{gather*}
Quindi la successione può convergere se il termine infinitesimo della serie converge:
\begin{equation}
    \lim_{n\to\infty}a_{n+1}=0
\end{equation}
Queste rappresenta solo una condizione necessaria, non garantisce che una serie converga, non è quindi una condizione sufficiente. 
Se il termine infinitesimo di una serie non converge, allora la serie non può convergere, quindi diverge oppure è irregolare. 

%% ESEMPIO

Si considera la seguine serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{3k^2+1}{2k^2+3}
\end{gather*}
Si vuole studiare il carattere della seguente serie utilizzando la condizione appena descritta:
\begin{gather*}
    \lim_{k\to\infty}\displaystyle\frac{3k^2+1}{2k^2+3}=\frac{3}{2}\neq0
\end{gather*}
Questa serie quindi non può converge, potrebbe quindi divergere oppure essere irregolare. 


Esiste un teorema che tratta le successioni numeriche, e si riflette sulle serie. Questo teorema afferma che data una successione monotona crescente $\{a_k\}\uparrow$ o decrescente $\{a_k\}\downarrow$, ovvero se tra il termine $a_k$ ed il termine $a_{k+1}$ esiste una relazione d'ordine, definitivamente, $\forall k\geq k_0$. Allora la successione non può essere irregolare. 

Sia una serie $\sum_{k=0}^\infty a_k$, se $\forall k\geq k_0$ si ha $a_k>0$, allora la serie non è irregolare. Considerando un valore di $n\geq k_0$, si ha:
\begin{gather*}
    s_{n+1}=s_n+\overbrace{a_{n+1}}^{>0}\implies s_{n+1}>s_n
\end{gather*}

Poiché viene sommato ad $s_n$ un valore non nullo positivo, quindi una serie di termini di segno costante positivo corrisponde ad una successione di somme parziali definitivamente monotona crescente. Questa serie allora converge o diverge, è regolare. 

Considerando la serie dell'esempio precedente, con il primo criterio si è confermato che la serie non converge, analizzando i segni della serie si ha:
\begin{gather*}
    3k^2+1>0\,\land\,2k^2+3>0\implies\displaystyle\frac{3k^2+1}{2k^2+3}
\end{gather*}

Quindi la serie è composta da termini definitivamente positivi, quindi la serie non può essere irregolare. Questa serie allora diverge ad infinito positivo. 

%% PROPRIETÀ

Si considerano due serie $\sum a_k$ e $\sum b_k$, convergenti rispettivamente a $\alpha$ e $\beta$, la serie combinazione lineare delle due serie $\sum(Aa_k+Bb_k)$ allora converge al valore $A\alpha+B\beta$. Tramite questa proprietà è possibile scomporre una serie ed analizzare i singoli termini per determinare il carattere della serie da cui derivano. Se una delle due diverge, mentre l'altra converge, allora la serie combinazione lineare diverge, allo stesso segno della serie divergente, per qualunque valore di $A$ e $B$, vale anche se entrambe le serie convergono ad infinito di segno concorde. Se invece entrambe le serie divergono ed il segno discorde, allora questo genera una forma indeterminata e quindi non è possibile determinare il comportamento della serie combinazione lineare. 

\subsubsection{Criterio del Confronto}

Siano $\sum_{k=1}^\infty a_k$ e $\sum_{k=1}^\infty b_k$ due serie di segno definitivamente costante tale che vale la seguente condizione: $\forall k\geq k_0\rightarrow 0<a_k\leq b_k$. Allora se lla serie maggiorante $\sum_{k=1}^\infty b_k$ converge, allora si dimostra che anche la serie minorante $\sum_{k=1}^\infty a_k$ converge. Analogamente vale il duale di questa proprietà se la serie minorante $\sum_{k=1}^\infty a_k$ diverge, allora anche la serie maggiorante $\sum_{k=1}^\infty b_k$ diverge anch'essa. 

%% ESERCIZIO 

Si considera la seguente serie, bisogna analizzarne il comportamento, tramite il criterio del confronto:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{|\sin k|}{2^k}
\end{gather*}
Si considera il modulo per avere termini definitivamente positivi, allora il termine generico della serie sarà maggiorato dal termine generico:
\begin{gather*}
    \displaystyle\frac{|\sin k|}{2^k}<\frac{1}{2^k},\,\forall k\in\mathbb{N}
\end{gather*}
È certamente diverso dal termine generico, poiché $k$ non può essere un multiplo di $\pi$. 
La serie maggiorante corrisponde ad una serie geometrica di ragione $1/2$, e converge poiché la ragione è di modulo minore di uno, quindi converge anche la serie minorante. 

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{2+\cos k}{k}
\end{gather*}
Si può esprimere una serie maggiorante e minorante di questa serie:
\begin{gather*}
    \displaystyle\frac{1}{k}<\frac{2+\cos k}{k}<\frac{3}{k}
\end{gather*}

La serie minorante è una serie armonica, si dimostrerà che diverge a più infinito:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k}=+\infty
\end{equation*}
Mentre la serie armonica generalizzata, per $\alpha\in\mathbb{R}$ diverge solo per certi valori di $\alpha$:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k^\alpha}
\end{equation*}

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{|\cos k|}{k}
\end{gather*}
La serie maggiorante rappresenta la serie armonica descritta precedentemente, per cui non è possibile utilizzare il criterio del confronto. Non è possibile stabilire il carattere della serie utilizzando questo criterio. 

\subsubsection{Criterio della Radice}

Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si basa sulla definizione di una successione ausiliaria. Per costruire questa successione ausiliaria si considera, da $k>k_0$, $\{\sqrt[k]{a_k}\}$. Si considera per ipotesi che questa successione sia regolare:
\begin{equation*}
    \lim_{k\to\infty}\sqrt[k]{a_k}=\Lambda
\end{equation*}

Se questo limite converge ad un valore positivo maggiore di uno, oppure diverge ad infinito positivo, allora è dimostrabile che la serie di partenza diverge. 
Se questo limite è positivo e minore di uno, allora la serie converge. Mentre se il limite è esattamente pari ad uno, allora il problema rimane aperto, e non è possibile stabilire il comportamento della serie tramite questa successione. 

\begin{equation}
    \displaystyle\sum_{k=1}^\infty a_k:\begin{cases}
        \text{diverge}&\Lambda > 1\,\lor\Lambda=+\infty\\
        \text{converge}&0\leq\Lambda<1\\
        ?&\Lambda=1
    \end{cases}
\end{equation}

Considerando la seguente serie, determinare il carattere tramite il metodo della radice:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\left(\frac{1}{k}\right)^k
\end{gather*}
La sua serie ausiliaria è:
\begin{gather*}
    \displaystyle\left\{\sqrt[k]{\left(\frac{1}{k}\right)^{k}}\right\}=\left\{\frac{1}{k}\right\}
\end{gather*}
Questa successione corrisponde alla serie armonica, e diverge quindi la serie di partenza diverge. 

\subsubsection{Criterio del Rapporto}

Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si basa sulla definizione di una successione ausiliaria. Per costruire questa successione ausiliaria si considera, da $k>k_0$:
\begin{equation*}
    \displaystyle\left\{\frac{a_{k+1}}{a_k}\right\}
\end{equation*}
Si considera per ipotesi che questa successione sia regolare:
\begin{equation*}
    \lim_{k\to\infty}\displaystyle\frac{a_{k+1}}{a_k}=\Lambda
\end{equation*}

Esistono casi dove la successione ausiliaria creata è irregolare, e quindi non è possibile utilizzare questi criteri. %% !! base55555555555555555555555555
Analogamente al criterio precedente, in base al valore del limite la serie diverge, converge, oppure non è possibile determinarne il carattere:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty a_k:\begin{cases}
        \text{diverge}&\Lambda > 1\,\lor\Lambda=+\infty\\
        \text{converge}&0\leq\Lambda<1\\
        ?&\Lambda=1
    \end{cases}
\end{equation}

%% ESEMPIO

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{2^k}{k!}
\end{gather*}

La sua serie ausiliaria è quindi:
\begin{gather*}
    \displaystyle\frac{\frac{2^{k+1}}{(k+1)!}}{\frac{2^k}{k!}}=
    \frac{2^{k+1}}{(k+1)!}\cdot\frac{k!}{2^k}=\cancelto{\frac{1}{k+1}}{\frac{k!}{(k+1)!}}\cdot\cancelto{2}{\frac{2^{k+1}}{2^k}}=\frac{2}{k+1}\\
    \lim_{k\to\infty}\frac{2}{k+1}=0
\end{gather*}

La serie quindi converge, invece se i termini della serie fossero inversi:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{k!}{2^k}
\end{gather*}

\subsubsection{Criterio dell'Integrale}
Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si considera la funzione associata che sostituisce $\{a_k\}\rightarrow\{f(x)\}$. La funzione associata deve essere decrescente a partire da $k_0$: $f(x)\downarrow \forall x>k_0$. Sia:
\begin{equation*}
    t_n=\displaystyle\int_{k_0}^n f(x)\mathrm{d}x
\end{equation*}

Allora la successione definita su $t_n$: $\{t_n\}$ e la serie $\sum a_k$ hanno lo stesso carattere. 

Si applica il criterio dell'integrale sulla serie armonica generalizzata, questa soddisfa l'ipotesi da $k_0=1$:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k^\alpha},\,\alpha\in\mathbb{R}\\
    f(x)=\displaystyle\frac{1}{x^\alpha}
\end{gather*}
Se $\alpha$ fosse negativo, la funzione associata sarebbe monotona crescente, ma se fosse negativo la serie sarebbe $\sum k^{|\alpha|}$, per cui diverge. 
Per $\alpha=0$, tutti i termini della serie sono pari ad uno, quindi il termine generico è uno e quindi la serie diverge allo stesso modo. Quindi solo per $\alpha>0$ la serie converge, e quindi solo per questo caso ha senso lo studio della serie armonica generalizzata

Nel caso $\alpha>0$ la condizione necessaria è soddisfatta, quindi la funzione potrebbe convergere. Si studia il suo carattere con il criterio dell'integrale, si ha la seguente serie ausiliaria:
\begin{gather*}
    t_n=\displaystyle\int_{1}^n\frac{1}{x^\alpha}\mathrm{d}x=\begin{cases}
        \bigg|\log(x)\bigg|_1^n &\alpha=1\\
        \displaystyle\frac{1}{1-\alpha}\bigg|x^{1-\alpha}\bigg|_1^n&\alpha\neq1
    \end{cases}=\begin{cases}
        \log(n)&\alpha=1\\
        \displaystyle\frac{1}{1-\alpha}\left(n^{1-\alpha}-1\right)&\alpha\neq1
    \end{cases}
\end{gather*}

Per $\alpha=1$, la successione diverge, poiché il logaritmo è una funzione monotona crescente, mentre per $\alpha\neq1$:
\begin{gather*}
    \displaystyle\frac{1}{1-\alpha}\lim_{n\to\infty}\left(n^{1-\alpha}-1\right)=\begin{cases}
        +\infty&\alpha<1\\
        \displaystyle\frac{1}{1-\alpha}&\alpha>1
    \end{cases}
\end{gather*}
La serie quindi diverge per $\alpha<1$, mentre converge per $\alpha>1$

Il carattere della serie armonica generalizzata è quindi dato dal seguente:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k^\alpha}:\begin{cases}
        \text{diverge}&\alpha\le1\\
        \text{converge}&\alpha>1        
    \end{cases}
\end{equation}


Conviene applicare il criterio dell'integrale quando la funzione associata è facilmente integrabile. Considerata la seguente serie:
\begin{equation*}
    \displaystyle\sum_{k=1}^{\infty}\frac{\text{arctan}\, k}{1+k^2}
\end{equation*}

Per valutare il carattere di questa serie si potrebbe considerare il criterio del confronto, poiché l'arcotangente è una funzione superiormente limitata da $\pi/2$:
\begin{gather*}
    \displaystyle\frac{\text{arctan}\,k}{1+k^2}<\frac{\pi/2}{1+k^2}<\frac{\pi}{2k^2}
\end{gather*}

Considerando la serie maggiorante, questa è una serie armonica generalizzata con parametro $\alpha=2>1$, questa converge, quindi per il criterio del confronto converge anche la serie di partenza. 

In questo caso funziona anche il criterio dell'integrale. La sua funzione associata è:
\begin{gather*}
    f(x)=\displaystyle\frac{\text{arctan}\, x}{1+x^2}
\end{gather*}

Si può notare come la funzione associata è il prodotto dell'arcotangente per la sua derivata, quindi l'integrale è immediato. Per utilizzare il criterio dell'integrale bisogna determinare che la funzione è monotona decrescente, si analizza quindi la sua derivata:
\begin{gather*}
    \displaystyle\frac{\mathrm{d}f(x)}{\mathrm{d}x}=\displaystyle\frac{\cancelto{1}{\frac{1}{1+x^2}(1+x^2)}-2x\text{arctan}\,x}{(1+x^2)^2}\\
    1-2x\text{arctan}\,x <0
\end{gather*}
Il numeratore è sempre negativo per $x\in(1,\infty)$, per cui la funzione ausiliaria è monotona decrescente ed è possibile utilizzare il criterio dell'integrale:
\begin{gather*}
    t_k=\displaystyle\int_{1}^kf(x)\mathrm{d}x=\int_1^k\frac{\text{arctan}\,x}{1+x^2}\mathrm{d}x\\
    u=\text{arctan}\,x\rightarrow\int_1^{\text{arctan}\,k}u \mathrm{d}u=\bigg|\frac{u^2}{2}+c\bigg|_1^{\text{arctan}\,k}=\frac{\arctan^2k}{2}-\frac{\pi^2}{8} %% TODO finire
\end{gather*}

\subsubsection{Criterio di Condensazione}

Sia una serie di segno definitivamente positivo: $\sum_{k=1}^\infty a_k | a_k>0\,\forall k\geq k_0$. Si considera la serie monotona decrescente $a_k\downarrow$, allora la serie $\sum 2^ka_{2^k}$ ha lo stesso carattere della serie di partenza. Generalmente si applica solo nel caso dove in $a_k$ è presente un fattore logaritmo di $k$. 

Si considera la serie:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty\frac{\ln k}{k}
\end{equation*}

Si calcola la derivata della sua funzione ausiliaria:
\begin{gather*}
    \displaystyle f(x)=\frac{\ln x}{x}\\
    f'(x)=\displaystyle\frac{1-\ln x}{x^2}<0
\end{gather*}
Si è verificata l'ipotesi della monotonia della serie. 
Si applica quindi il criterio di condensazione:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty \cancel{2^k}\frac{\ln 2^k}{\cancel{2^k}}
\end{gather*}

Sfruttando le proprietà del logaritmo questo diventa:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty k\cdot{\ln 2}=\ln 2\displaystyle\sum_{k=1}^\infty k
\end{gather*}

Non verificando l'ipotesi di convergenza, non può convergere. 

Si considera ora la serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{\ln k}{k^2}\\
    \displaystyle f(x)=\frac{\ln x}{x^2}\\
    f'(x)=\displaystyle\frac{x-2x\ln x}{x^4}=\frac{\cancel{x}(1-2\ln x)}{x^{\cancelto{3}{4}}}<0
\end{gather*}

Si applica il criterio di condensazione:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty \cancel{2^k}\frac{\ln 2^k}{(2^k)^{\cancel{2}}}=\ln2\sum_{k=1}^\infty\frac{k}{2^k}
\end{gather*}
Si studia il criterio del rapporto per poter determinarne il carattere:
\begin{gather*}
    \displaystyle\frac{\frac{k+1}{2^{k+1}}}{\frac{k}{2^k}}=\frac{k+1}{k}\frac{\cancel{2^k}}{2^{\cancel{k+1}}}=\frac{1}{2}\frac{k+1}{k}\\
    \frac{1}{2}\lim_{k\to\infty}\frac{k+1}{k}=\frac{1}{2}<1
\end{gather*}
Poiché $a_{k+1}/a_{k}<1$ la serie converge, e quindi per il criterio di condensazione anche la serie di partenza converge.  

\subsubsection{Criterio del Confronto Asintotico}

In questo criterio si considerano due serie, entrambe a termini definitivamente positivi $\sum_{k=1}^\infty a_k \land \sum_{k=1}^\infty b_k | a_k>0,\,b>0\,\forall k\geq k_0$. Allora se il limite del rapporto all'infinito converge ad un numero reale non nullo, allora hanno lo stesso carattere
\begin{gather*}
    \lim_{k\to\infty}\frac{a_k}{b_k}=l\in\mathbb{R}\setminus\{0\}
\end{gather*}
Se $l=1$ allora le due successioni, analogamente per le funzioni, si dicono asintoticamente equivalenti per $k\to\infty$: $a_k$~$b_k$. %% TODO tilde c'è?
Spesso si userà questo simbolo generalizzandolo come due funzioni asintoticamente equivalenti a meno di una costante, poiché è di interessa solamente il carattere e non il valore effettivo esplicito di una serie. 
Se invece il rapporto converge a zero e la serie $\sum b_k$ converge, allora anche la serie $\sum a_k$ converge, ovvero $a_k$ è un infinitesimo di ordine superiore a $b_k$. 
Se invece il limite di questo rapporto tende ad infinito, e la serie $\sum b_k$ diverge, allora divergerà anche la serie $\sum a_k$, $b_k$ è un infinitesimo di ordine superiore di $a_k$. 

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\sin\left(\frac{1}{k}\right)
\end{gather*}
È soddisfatta la condizione necessaria per la convergenza, avendo:
\begin{gather*}
    \displaystyle\lim_{k\to\infty}\sin\left(\frac{1}{k}\right)=0
\end{gather*}

Bisogna ora trovare una serie $\sum b_k$, tale che:
\begin{gather*}
    \displaystyle\lim_{k\to\infty}\frac{\sin\left(\frac{1}{k}\right)}{b_k}=l\in\mathbb{R}\setminus\{0\}
\end{gather*}
Per il limite notevole $\sin x/x$, questa serie è $b_k=1/k$, per cui il limite converge ad uno:
\begin{gather*}
    \displaystyle\lim_{k\to\infty}\frac{\sin\left(\frac{1}{k}\right)}{\frac{1}{k}}=1
\end{gather*}

Queste due serie sono asintoticamente equivalenti tra di loro:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\sin\left(\frac{1}{k}\right)\sim\sum_{k=1}^\infty\frac{1}{k}
\end{gather*}
La serie di destra è una serie armonica e diverge, quindi diverge anche la serie di partenza. 5

Data ora la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\sin\left(\frac{1}{k^2}\right)
\end{gather*}

I termini sono sempre positivi, ed è soddisfatta la condizione necessaria, la serie asintoticamente equivalente è data da:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\sin\left(\frac{1}{k^2}\right)\sim\displaystyle\sum_{k=1}^\infty\frac{1}{k^2}
\end{gather*}

Questa è una serie armonia generalizzata per $\alpha=2>1$, quindi converge. Allora anche la serie di partenza converge.  


Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\ln\left(\frac{k+1}{k}\right)
\end{gather*}

La serie ha termini di segno definitivamente positivo, poiché l'argomento è certamente maggiore di uno: $k+1>k$. Si scrive in forma equivalente l'argomento per evidenziare il limite notevole:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\ln\left(\frac{k+1}{k}\right)=
    \displaystyle\sum_{k=1}^\infty\ln\left(1+\frac{1}{k}\right)\sim\sum_{k=1}^\infty\frac{1}{k}
\end{gather*}

Questa serie ha lo stesso carattere di una serie armonica divergente, quindi diverge. 

Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\left(e^{1/k}-1\right)\sim\sum_{k=1}^\infty\frac{1}{k}
\end{gather*}
Per il limite notevole è asintoticamente equivalente ad una serie armonica divergente, quindi diverge. 

Considerando ora la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\left(e^{1/\sqrt{k}}-1\right)\sim\sum_{k=1}^\infty\frac{1}{k^{1/2}}
\end{gather*}
Essendo asintoticamente equivalente ad una serie armonica generalizzata divergente, diverge. 
Per avere avere una serie convergente, deve avere come argomento almeno un $k^\alpha$, con $\alpha>1$.. 


Si considera la seguente serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\ln\left(\frac{k^2+5k-2}{k^2+3}\right)
\end{gather*}
Sicuramente è una serie a termini positivi, si vuole quindi riscrivere l'argomento del logaritmo nella forma $1+x$:
% !! 55555555555555555555
% ?? 55555555555555555555555555555555555555555555558555555555555555555555555555555555555555555555555555555555555
% todo 55555555555555555555255555555555555555525555555585555555555555555554555555555555555555555565565555565656565555555555555555555555555555
\begin{gather*}
    \displaystyle\frac{k^2+5k-2}{k^2+3}=1+\frac{5k-5}{k^2+3}
\end{gather*}
Questa serie si comporta in modo equivalente alla serie:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\ln\left(\frac{k^2+5k-2}{k^2+3}\right)=
    \displaystyle\sum_{k=1}^\infty\ln\left(1+\frac{5k-5}{k^2+3}\right)\sim\sum_{k=1}^\infty\frac{5k-5}{k^2+3}\sim\sum_{k=1}^\infty\frac{5k}{k^2}=5\sum_{k=1}^\infty\frac{\cancel{k}}{k^{\cancel{2}}}
\end{gather*}
Essendo asintoticamente equivalente ad una serie armonica divergente, anche essa diverge. 

\subsubsection{Criterio di Leibniz}

Una prima famiglia di serie a termini di segno alterni permette comunque di poter calcolare. Considerata una serie con $a_k>0\forall k>k_0$, si esprime il fattore che rende la serie alterna:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty(-1)^ka_k
\end{gather*}

Il criterio di Leibniz suppone di avere una serie del genere, siano i termini della serie decrescenti, tendenti a 0: $\{a_k\}\downarrow0$, allora la serie converge. 


Detta $S$ la somma della serie:
\begin{gather*}
    s=\displaystyle\sum_{k=0}^\infty(-1)^ka_k
\end{gather*}

All'aumentare di $n$, la somma $s_n$ dei primi $n$ elementi della serie, la serie oscilla sorpassando in positivo o in negativo la somma $s$, di valori sempre più piccoli, convergendo al valore $s$:

%% TODO asse reale con S1, S2, ... S oscillazione
\begin{gather*}
    |s-s_1| < |s_1-s_2|\\
    |s-s_n| \leq |s_n-s_{n-1}|=|a_n|
\end{gather*}

La somma $s_n$ si posizione al lato opposto di $s_{n-1}$ e si trova ad una posizione più vicina alla somma $s$ rispetto al precedente, quindi ha una distanza minore. 

\subsubsection{Criterio di Convergenza Assoluta}

Il criterio di Leibniz si può utilizzare solo quando le serie hanno segno alterno, mentre, per altri tipo di serie in cui il segno non è né definitivamente positivo, o negativo, e né alterno, è necessario un altro criterio per poter determinarne il carattere. 

Un criterio generale consiste nell'analizzare il carattere della serie $|a_k|$, questa serie risultante è a termini di segno costante positivo:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty|a_k|
\end{gather*}

Un teorema dimostrabile afferma che se una serie ha termini di segno non costante $\sum a_k$, se la serie formata mettendo in valore assoluto i termini della prima $\sum|a_k|$ converge, allora converge anche la serie iniziale. Si dice che converge in modo assoluto, o assolutamente. 

Se la serie $\sum a_k$ converge assolutamente, allora la serie converge semplicemente, la convergenza studiata con i criteri precedenti. 

\subsection{Serie di Potenze}

In generale una serie di potenza viene espressa, partendo da 0 o 1, come:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty a_k(x-x_0)^k
\end{gather*}
Con $x_0\in\mathbb{R}$, si dice serie di potenze con centro in $x_0$. Le serie di potenze sono molto importanti e di facile analisi, anche se il calcolo del loro limite non è triviale. 

Quando si analizzano serie di potenze si parla di intervallo di convergenza, poiché si analizza per quali valori del parametro $x$ la serie converge. Una serie geometrica è una particolare serie di potenze centrata in $x_0=0$, con $a_k=1$ per ogni valore di $k$, di cui si conosce anche la somma, per valori del parametro $x\in(-1,1)$:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty x^k=\frac{1}{1-x}
\end{gather*}

Tutte le volte che si ha una serie di potenze, la prima cosa che bisogna calcolare è il cosiddetto raggio di convergenza. La sua definizione è molto più ampia, ma studiando casi particolari non sarà necessario approfondirlo. Per calcolarlo si introduce una successione ausiliaria:
\begin{gather*}
    \left\{\displaystyle\left|\frac{a_k}{a_{k+1}}\right|\right\}
\end{gather*}
Questa serie si riferisce al criterio del rapporto, alternativamente si può usare la serie ausiliaria: %% TODO quale criterio
\begin{gather*}
    \left\{\displaystyle\frac{1}{\sqrt[k]{a_k}}\right\}
\end{gather*}
Bisogna dare per ipotesi che queste successioni siano regolari, per $k\to\infty$. Questo valore $R$ si trova calcolando il limite per $k\to\infty$ di una di queste due successioni:
\begin{equation}
    R=\lim_{k\to\infty}\displaystyle\left|\frac{a_k}{a_{k+1}}\right|=\lim_{k\to\infty}\frac{1}{\sqrt[k]{a_k}}=\begin{cases}
        +\infty\\
        0\\
        \in\mathbb{R}^+
    \end{cases}
\end{equation}

Se il limite esiste assume uno di questi tre possibili valori. Una volta determinato il raggio di convergenza, esiste un teorema che stabilisce dove questa serie risulta sicuramente convergente. 

Sia $R$ il raggio di convergenza della serie di potenze $a_k$ con centro in $x_0$: $\sum a_k(x-x_0)^k$. Allora si può affermare:
\begin{enumerate}
    \item Se $R=0$, la serie converge solo nel centro $x_0$. 
    \item Se $R=+\infty$, la serie converge in $\mathbb{R}$, ovvero qualunque sia il valore reale del parametro $x$. 
    \item Se $R\in\mathbb{R}^+$, finito positivo e diverso da zero, la serie converge assolutamente, e quindi semplicemente, in $(x_0-R, x_0+R)$. Inoltre la serie non converge nell'intervallo $(-\infty,x_0-R)$ e $(x_0+R, +\infty)$. 
\end{enumerate}

Nell'ultimo caso $R$ rappresenta il centro dell'intervallo di convergenza, se il raggio è zero, contiene solo il centro, se è infinito, contiene tutti i numeri reali. 
Per determinare il valore al limite dell'intervallo $x=x_0\pm R$, bisogna sostituire questo valore ad $x$ e studiare per via diretta il carattere della serie risultante. Per questo si distingue tra intervallo di convergenza ed insieme di convergenza, poiché potrebbero non coincidere, potrebbero comprendere gli estremi. Coincidono solo se ai valori estremi la serie non converge. 

\subsubsection{Teorema della Serie Derivata e Integrale}

Sia una serie di potenze con centro $x_0$:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty a_k(x-x_0)^k
\end{gather*}
Tale che il raggio di convergenza è un numero reale positivo, oppure diverge ad infinito: $R\in\mathbb{R}^+$ o $R=+\infty$. 
Allora per ogni valore nell'intervallo di insieme di convergenza centrato in $x_0$: 
$\forall x\in I_R(x_0)$, la funzione somma è di classe $S(x)\in C^{\infty}(I_R(x_0))$, quindi è derivabile infinite volte, e tutte le sue derivate sono funzioni continue. La derivata rispetto alla variabile $x$ della somma è:
\begin{gather*}
    \forall x \in I_R(x_0)\implies\displaystyle\frac{\mathrm{d}}{\mathrm{d}x}S(x)=
    \frac{\mathrm{d}}{\mathrm{d}x}\sum_{k=0}^\infty a_k(x-x_0)^k=
    \sum_{k=0}^\infty a_k\frac{\mathrm{d}}{\mathrm{d}x}(x-x_0)^k=
    \sum_{k=1}^\infty a_kk(x-x_0)^{k-1}
\end{gather*}
Il termine con $k=0$ è costante per cui la serie parte da $k=1$.
Oltre a poter derivare termine a termine è possibile integrare termine a termine della funzione somma:
\begin{gather*}
    \forall x\in I_R(x_0)\implies\displaystyle\int_{x_0}^xS(t)\mathrm{d}t=\int_{x_0}^x\sum_{k=0}^\infty a_k(t-x_0)^k\mathrm{d}t=\sum_{k=0}^\infty a_k\int_{t_0}^x(t-x_0)^k\mathrm{d}t\\
    \displaystyle\int_{x_0}^xS(t)\mathrm{d}t=
    \sum_{k=0}^\infty a_k\frac{t-x_0}{k+1}^{k+1}
\end{gather*}
L'integrale della somma è uguale alla serie degli integrali, analogamente alla derivata. 

\subsubsection{Espansione in Serie}

Per ogni $x$ nell'intervallo $(-1,1)$ si è dimostrato per via diretta che la funzione definita in $\mathbb{R}\setminus\{1\}$: $(1-x)^{-1}$ si può esprimere come una serie di potenze con raggio di convergenza uno e centro nell'origine:
\begin{gather}
    \forall x\in(-1,1)\implies\displaystyle\frac{1}{1-x}=\sum_{k=0}^\infty x^k
\end{gather}
Si considera nell'intervallo $I_1(0)$ l'integrale di questa funzione, per il teorema appena enunciato si può esprimere come la somma di integrali, effettuando il passaggio sotto il segno dell'integrale alla sommatoria: %% TODO fix wording
\begin{gather*}
    \forall x \in I_1(0)\implies\displaystyle\int_{0}^x\frac{1}{1-t}\mathrm{d}t=
    \sum_{k=0}^\infty\int_{0}^x t^k\mathrm{d}t=
    \sum_{k=0}^\infty\frac{t^{k+}1}{k+1}\bigg|_{0}^x=
    \sum_{k=0}^\infty\frac{x^{k+1}}{k+1}=\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather*}
Calcolando l'integrale direttamente si ottiene che vale:
\begin{gather*}
    \forall x\in(-1,1)\implies\displaystyle\int_0^x\frac{1}{1-t}\mathrm{d}t=-\ln(1-x)
\end{gather*}
Si è scoperto che se la $x$ è contenuta in questo intervallo dato lo sviluppo in serie di una funzione si ottiene anche lo sviluppo in serie della funzione:
\begin{gather*}
    \forall x\in I_1(0)\implies -\ln(1-x)=\displaystyle\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather*}
L'uguaglianza si può estendere all'estremo $-1$ per il criterio di Leibniz, ma non per $x=1$:
\begin{gather}
    \forall x\in [-1,1)\implies -\ln(1-x)=\displaystyle\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather}

Effettuando il cambio di variabile $-x=u$, l'intervallo di convergenza diventa $u\in(-1, 1]$:
\begin{gather*}
    -\ln(1+u)=\displaystyle\sum_{k=1}^\infty\frac{(-u)^k}{k}=
    \displaystyle\sum_{k=1}^\infty(-1)^k\frac{u^k}{k}\\
    \ln(1+u)=-\displaystyle\sum_{k=1}^\infty(-1)^k\frac{u^k}{k}=
    \displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{u^k}{k}\\
    \forall x\in(-1,1]\implies\displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{x^k}{k}\tageq
\end{gather*}


%% TODO \ref alla prima eq
Considerando la prima espansione, si effettua la sostituzione $x=-u^2$: 
\begin{gather*}
    -1<x<1\\
    -1<-u^2<1\\
    -u^2<1\,\forall n\in\mathbb{R}\implies u^2<1:\,-1<n<1\\
    u\in(-1,1)
\end{gather*}

La funzione e corrispondente serie diventa quindi:
\begin{gather*}
    \forall u\in(-1,1)\,\displaystyle\frac{1}{1+n^2}=\sum_{k=0}^\infty(-n^2)^k=
    \sum_{k=0}^\infty(-1)^kn^{2k}
\end{gather*}
A questo punto si integra membro a membro e si scambia l'integrale sotto il segno della sommatoria:
\begin{gather*}
    \displaystyle\int_0^u\frac{1}{1+u^t}\mathrm{d}t=
    \int_0^u\sum_{k=0}^\infty(-1)^kt^{2k}\mathrm{d}t=
    \sum_{k=0}^\infty(-1)^k\int_0^ut^{2k}\mathrm{d}t=
    \sum_{k=0}^\infty(-1)^k\frac{u^{2k+1}}{2k+1}\\
    \arctan u=\sum_{k=0}^\infty(-1)^k\frac{u^{2k+1}}{2k+1}
\end{gather*}

Quindi l'arcotangente di $x$ nell'intervallo $(-1,1)$ si può esprimere come la seguente serie:
\begin{equation*}
    \forall x\in(-1,1)\,\arctan x=\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{2k+1}
\end{equation*}
Bisogna comunque controllare se questa serie converge anche agli estremi dell'intervallo di convergenza. Per $x=1$ si ha:
\begin{gather*}
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^k}{2k+1}
\end{gather*}
Questa serie converge per il criterio di Leibniz poiché la serie ha termini strettamente decrescenti convergenti a zero; mentre per $x=-1$ si ha:
\begin{gather*}
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^k(-1)^{2k+1}}{2k+1}=
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^{k+1}}{2k+1}
\end{gather*}
Analogamente alla precedente vale il criterio di Leibniz quindi converge. L'identità diventa quindi:
\begin{equation}
    \forall x\in[-1,1]\,\arctan x=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{2k+1}
\end{equation}
Questa serie venne utilizzata per calcolare il valore di pi greco, considerando la serie per il valore $x=1$:
\begin{gather*}
    \arctan(1)=\displaystyle\frac{\pi}{4}=\displaystyle\sum_{k=0}^\infty\frac{(-1)^k}{2k+1}\\
    \pi=4\displaystyle\sum_{k=0}^\infty\frac{(-1)^k}{2k+1}
\end{gather*}
Con un indice molto elevato si può ottenere un'approssimazione molto accurata del pi greco. 

\subsubsection{Serie di Taylor Swift}

Questa serie di potenze si può chiamare serie di Taylor. Data una funzione derivabile con continuità infinite volte $f\in C^\infty(I_R(x_0)) $, la sua serie di Taylor si definisce come la seguente:
\begin{equation}
    \displaystyle\sum_{k=0}^\infty\frac{f^{(k)}(x_0)}{k!}(x-x_0)
\end{equation}

Per certe funzioni, e certi intervalli, si può estendere il grado del polinomio di Taylor fino all'infinito. 

Il polinomio di Maclaurin della serie esponenziale è la seguente:
\begin{gather*}
    e^x=\displaystyle\sum_{k=0}^n\frac{x^k}{k!}+o[x^n]
\end{gather*}
Si può dimostrare che tendendo $n\to\infty$ la serie di Maclaurin ottenuta continua a coincidere alla serie esponenziale; si vuole ottenere lo sviluppo in serie dell'esponenziale. 
Partendo dalla serie di potenze si cattura il suo raggio di convergenza:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}\\
    R=\lim_{k\to\infty}\displaystyle\left|\frac{a_k}{a_{k+1}}\right|=
    \lim_{k\to\infty}\frac{1}{\cancel{k!}}(k+1)\cancel{!}=\lim_{k\to\infty}{k+1}=+\infty
\end{gather*}
Essendo il raggio di convergenza infinito, la serie converge in $\mathbb{R}$:
\begin{gather*}
    \forall x\in\mathbb{R}\, S(x)=\displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}
\end{gather*}
Si vuole dimostrare che la somma di questa serie $S(x)$ coincide all'esponenziale $e^x$. Si applica il teorema del passaggio della derivata sotto il segno della sommatoria:
\begin{gather*}
    \displaystyle\frac{\mathrm{d}}{\mathrm{d}x}S(x)=\frac{\mathrm{d}}{\mathrm{d}x}\sum_{k=0}^\infty\frac{x^k}{k!}=
    \displaystyle\sum_{k=0}^\infty\frac{1}{k!}\frac{\mathrm{d}}{\mathrm{d}x}x^k=
    \sum_{k=1}^\infty x^{k-1}\frac{\cancel{k}}{\cancel{k}(k-1)!}=
    \displaystyle\sum_{k=1}^\infty\frac{x^{k-1}}{(k-1)!}\\
\end{gather*}
La serie della derivata parte da $k=1$, poiché il primo addendo $a_0$ è costante e nel passaggio della derivata si annulla. 
\begin{gather*}
    S'(x)=\displaystyle\sum_{k=1}^\infty\frac{x^{k-1}}{(k-1)!}=
    \displaystyle\sum_{k=0}^\infty\frac{x^{k}}{k!}=S(x)
\end{gather*}

La derivata prima di questa funzione coincide con la funzione di partenza, a meno di una costante, per ogni $x\in\mathbb{R}$. Inoltre si ha che $S(0)=1$, questo rappresenta un problema di Cauchy:
\begin{gather*}
    \begin{cases}
        S'(x)=S(x)&\forall x\in\mathbb{R}\\
        S(0)=1
    \end{cases}\\
    \displaystyle\frac{S'(x)}{S(x)}=1\implies\int_0^x\frac{S'(t)}{S(t)}\mathrm{d}t=x\\
    \ln|S(t)|\bigg|_0^x=x\implies \ln|S(x)|-\cancelto{0}{\ln|S(0)|}=x\\
    S(x)=e^x
\end{gather*}
Per cui si è dimostrato che la funzione somma $S(x)$ è la funzione esponenziale, e si è definita la sua espansione:
\begin{equation}
    \forall x\in\mathbb{R}\implies\,e^x=\displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}
\end{equation}

Si considera l'approssimazione di Maclurin della funzione coseno:
\begin{gather*}
    \cos x=\displaystyle\sum_{k=1}^n(-1)^k\frac{x^{2k}}{(2k)!}+o[x^{2n}]
\end{gather*}
Si effettua un procedimento analogo, partendo dalla serie, tendendola all'infinito, e ci si aspetta che $o[x^{2n}]$ tende a zero. Si dimostra che la somma di questa serie $S(x)$ non può essere altro che la funzione coseno. 
Si determina il raggio di convergenza della serie:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k}}{(2k)!}=S(x)\\
    %% TODO calcolo del raggio
    R=+\infty
\end{gather*}

Analogamente all'esponenziale la serie converge per ogni $x$ reale $x\in\mathbb{R}$. Si deriva membro a membro l'equazione:
\begin{gather*}
    S'(x)=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{\mathrm{d}}{\mathrm{d}x}\frac{x^{2k}}{(2k)!}=
    \sum_{k=1}^\infty(-1)^k\frac{\cancel{2k}}{\cancel{2k}}\frac{x^{2k-1}}{(2k-1)!}
\end{gather*}
ANalogamente all'esponenziale il termine $a_0$ è una costante, quindi si annulla e la serie parte da $k=1$. Questa serie rappresenta, a meno del segno, lo sviluppo in serie del seno. Si deriva nuovamente membro a membro e si ottiene la seguente:
\begin{gather*}
    S''(x)=\displaystyle\sum_{k=1}^\infty(-1)^k\frac{\cancel{2k-1}}{\cancel{2k-1}}\frac{x^{2k-2}}{(2k-2)!}
\end{gather*}
Si effettua una traslazione, per impostare il valore iniziale a $k=0$:
\begin{gather*}
    S''(x)=\displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{x^{2k-2}}{(2k-2)!}=
    -\sum_{k=0}^\infty(-1)^{k+1}\frac{x^{2k}}{(2k)!}=-S(x)
\end{gather*}
La seconda derivata della funzione iniziale coincide alla funzione stessa, quindi la funzione è o un coseno o un seno, le uniche due funzioni che rispettano questa condizione. Inoltre deve soddisfare $S(0)=1$, e solo la funzione coseno rispetta questo problema di Cauchy:
\begin{gather*}
    \begin{cases}
        S''(x)=-S(x)&\forall x\in\mathbb{R}\\
        S(0)=1
    \end{cases}
\end{gather*}

Quindi la funzione coseno si può esprimere nell'intero asse reale con la seguente espansione:
\begin{equation}
    \forall x\in\mathbb{R}\cos x=\displaystyle\sum_{k=0}^\infty (-1)^k\frac{x^{2k}}{(2k)!}
\end{equation}

%% TODO seno dimostrare

Si può dimostrare allo stesso modo l'espansione seno sull'intero asse dei reali:
\begin{gather*}
    \forall x\in\mathbb{R} \sin x=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{(2k+1)!}
\end{gather*}

\clearpage

\section{Serie di Fourier}

Prima di trattare la serie di Fourier, un altro metodo per esprimere funzioni tramite serie, oltre la serie di Taylor, necessita di conoscere gli integrali impropri. 

\subsection{Integrali Impropri}

L'unica ipotesi per cui si definisce un integrale proprio su intervallo $[a,b]$ di una funzione $f$ è che sia continua nell'intervallo. Si dimostra che l'integrale:
\begin{gather*}
    \displaystyle\int_a^b f(x)\mathrm{d}x
\end{gather*}
È definito. 

Si vuole allentare l'ipotesi per considerare intervalli con una o più discontinuità. Sia una funzione $f$ continua e limitata in $[a,b)$, 
Per definire in termini più generali il concetto di integrale, con un punto di non continuità, si considera un intorno infinitesimo di $b$, ed agli estremi di questo interno $b-\varepsilon$, la funzione è continua: $[a,b-\varepsilon]$. In questo modo si rimuove la singolarità e si può definire l'integrale come:
\begin{gather*}
    \displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x
\end{gather*}
Ottenuta una funzione in termini di $\varepsilon$, si calcola il valore del limite per $\varepsilon\to0^+$, sotto queste ipotesi si dimostra che questo limite esiste ed è finito:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x=\int_a^bf(x)\mathrm{d}x
\end{gather*}
Si poteva scegliere come punto di discontinuità $a$ oppure un punto intermedio, si può sempre utilizzare la proprietà di additività degli integrali. 
Si allenta ulteriormente l'ipotesi, si suppone che la funzione $f$ sia continua ed illimitata nell'intervallo $[a,b)$.  

Analogamente si toglie l'intorno sinistro di $b$, e si forma un'intervallo dove la funzione è continua $[a, b-\varepsilon]$, si calcola in seguito l'integrale in funzione di $\varepsilon$ in questo intervallo. Per ottenere il valore dell'integrale sull'intervallo $[a,b]$ si calcola il valore del limite per $\varepsilon\to0$. 
Rinunciando all'ipotesi di limitatezza, non è più garantito che l'integrale sia definito, potrebbe esistere finito, infinito o irregolare:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x=
    \begin{cases}
        l\in\mathbb{R} &l=\displaystyle\int_a^bf(x)\mathrm{d}x\\
        \pm\infty&\\
        \nexists&
    \end{cases}
\end{gather*}
Nel primo caso l'integrale è convergente al valore $l$, la funzione $f$ si dice integrabile in senso improprio nell'intervallo $[a,b]$ oppure in senso equivalente l'integrale improprio della funzione $f$ è convergente. Questo integrale si dice integrale improprio della seconda specie. Nel secondo caso è divertente ad infinito, la funzione non è integrabile nel senso improprio, l'integrale improprio di seconda specie diverge. Nell'ultimo caso l'integrale oscilla ed il limite non esiste, l'integrale improprio di seconda specie è irregolare. 

%% ESEMPIO

Calcolare questo integrale:
\begin{gather*}
    \displaystyle\int_0^1\frac{1}{\sqrt{1-x^2}}\mathrm{d}x
\end{gather*}
Per prima cosa bisogna categorizzare l'integrale, presenta una singolarità di seconda specie nel punto $x=1$. La funzione integranda è una funzione continua ed illimitata nell'intervallo $[0,1)$. 
Si rimuove la singolarità e si calcola il suo limite:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{1-\varepsilon}\frac{1}{\sqrt{1-x^2}}\mathrm{d}x=\lim_{\varepsilon\to0^+}\left\{\arcsin x\bigg|_0^{1-\varepsilon}\right\}=\lim_{\varepsilon\to0^+}\arcsin(1-\varepsilon)=\frac{\pi}{2}
\end{gather*}

Si considera il seguente integrale:
\begin{gather*}
    \displaystyle\int_1^e\frac{\mathrm{d}x}{x\sqrt[3]{\ln x}}
\end{gather*}
La funzione integranda è illimitata nel punto $x=1$, si rimuove il suo intorno destro per rimuovere la singolarità e si calcola il limite:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\displaystyle\int_{1+\varepsilon}^e\frac{\mathrm{d}x}{x\sqrt[3]{\ln x}}=\lim_{\varepsilon\to0^+}\int_{1+\varepsilon}^e(\ln x)^{-1/3}\mathrm{d}\left(\ln x\right)=\lim_{\varepsilon\to0^+}\left\{\frac{3}{2}\left(\ln x\right)^{2/3}\bigg|_{1+\varepsilon}^e\right\}\\
    \displaystyle\int_1^e\frac{\mathrm{d}x}{x\sqrt[3]{\ln x}}=
    \frac{3}{2}\lim_{\varepsilon\to0^+}\left\{1-\left(\ln 1-\varepsilon\right)^{2/3}\right\}=\frac{3}{2}
\end{gather*}
In questo caso converge, quindi la funzione è integrabile. 


Calcolare al variare del parametro reale $\alpha\in\mathbb{R}$ la convergenza del seguente integrale:
\begin{gather*}
\displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}    
\end{gather*}
Se $\alpha<0$ l'integrale converge, poiché diventa un integrale classico, se $\alpha=0$, l'integrale converge. Diventa un'integrale improprio di seconda specie per $\alpha>0$, poiché $b$ diventa un punto singolare. In un caso si applica l'a regola delle potenze, nell'altro si %% TODO add qualcosa logaritmo

Per $\alpha=1$:
\begin{gather*}
    \displaystyle\int_a^b\frac{\mathrm{d}x}{b-x}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}\frac{\mathrm{d}x}{b-x}=
    \lim_{\varepsilon\to0^+}\left\{-\ln(b-x)\bigg|_a^{b-\varepsilon}\right\}=
    -\lim_{\varepsilon\to0^+}\left\{\ln(\varepsilon)-\ln(b-a)\right\}=+\infty
\end{gather*}
Quindi l'integrale diverge per $\alpha=1$, la funzione non è integrabile in questo intervallo per questo valore del parametro reale $\alpha$.

Per $\alpha\neq1$:
\begin{gather*}
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}\frac{\mathrm{d}x}{(b-x)^{\alpha}}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}(b-x)^{-\alpha}\mathrm{d}x=
    -\lim_{\varepsilon\to0^+}\int_a^{b-\varepsilon}(b-x)^{-\alpha}\mathrm{d}(b-x)\\
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=
    -\lim_{\varepsilon\to0^+}\left\{\frac{(b-x)^{1-\alpha}}{1-\alpha}\bigg|_a^{b-\varepsilon}\right\}=
    \frac{\lim_{\varepsilon\to0^+}\left\{\varepsilon^{1-\alpha}-(b-a)^{1-\varepsilon}\right\}}{\alpha-1}\\
    \lim_{\varepsilon\to0^+}\varepsilon^{1-\alpha}=\begin{cases}
        0&1-\alpha>0\\
        +\infty&1-\alpha<0
    \end{cases}\\
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=\begin{cases}
        \displaystyle\frac{(b-a)^{1-\alpha}}{1-\alpha}&1-\alpha>0\\
        -\infty&1-\alpha<0
    \end{cases}
\end{gather*}
L'integrale improprio di seconda specie converge se $\alpha<1$, e diverge ad infinito se $\alpha\geq1$. 

%% TODO caso analogo: 
Calcolare al variare del parametro reale $\alpha\in\mathbb{R}$ la convergenza del seguente integrale:
\begin{gather*}
\displaystyle\int_a^b\frac{\mathrm{d}x}{(x-a)^\alpha}    
\end{gather*}
%% fine caso analogo


\subsubsection{Teormea ??} %% TODO add nome

Sia $f$ una funzione continua ed illimitata in $[a,b)$, inoltre sia $f(x)\geq0$, o $\leq0$, nell'intorno sinistro del punto singolare $(b-\varepsilon, b)$. Allora l'integrale improprio di seconda specie su $f(x)$ in questo intervallo è regolare. 

\subsubsection{Teoream del Criterio del Confronto}

Siano $f$ e $g$ continue e illimitate in $[a, b)$, e sia $\forall x\in(b-\varepsilon, b)$ la funzione $f$ maggiorata dalla funzione $g$: $0\leq f(x)\leq g(x)$. 
Allora se l'integrale improprio della funzione maggiorante converge, allora converge anche l'integrale improprio della funzione minorante converge:
\begin{gather*}
    \displaystyle\int_a^b g(x)\mathrm{d}x:\mbox{converge}\implies
    \displaystyle\int_a^b f(x)\mathrm{d}x:\mbox{converge}
\end{gather*}
Inoltre se l'integrale improprio della funzione minorante diverge, allora pure l'integrale improprio della funzione maggiorante diverge. 
\begin{gather*}
    \displaystyle\int_a^b f(x)\mathrm{d}x=\pm\infty\implies
    \displaystyle\int_a^b g(x)\mathrm{d}x=\pm\infty
\end{gather*}


%% ESEMPIO

Studiare la convergenza di questo integrale improprio:
\begin{gather*}
    \displaystyle\int_0^1\frac{3-\sin x}{\sqrt{x}}\mathrm{d}X
\end{gather*}
È un integrale improprio di seconda specie, poiché in $x=0$ è presente una singolarità, ed è sempre positivo per $x\geq0$, essendo $\sin x<3$. 
Si può maggiorare e minorare il numeratore:
\begin{gather*}
    2\leq3-\sin x\leq4
\end{gather*}
Poiché il valore massimo e minimo del seno sono $\pm1$. La funzione integranda è sicuramente maggiorabile con la funzione:
\begin{gather*}
    \displaystyle\frac{3-\sin x}{\sqrt{x}}\leq\frac{4}{\sqrt{x}}
\end{gather*}
Sicuramente questa condizione vale nell'intervallo $[0,1]$. Si calcola l'integrale improprio di seconda specie della funzione maggiorante:
\begin{gather*}
    \displaystyle\int_0^1\frac{\mathrm{d}x}{\sqrt{x}}:\mbox{converge}
\end{gather*}
Converge poiché è un integrale immediato già trattato. 


%% ALTRO CRITERIO/TEOREMA

Siano $f$ e $g$ continue e illimitate in $[a, b)$, e sia $\forall x\in(b-\varepsilon, b)$ che entrambi le funzioni $f(x)$ e $g(x)$ nell'intervallo $(b-\varepsilon, b)$ mantengano lo stesso segno: $0\leq f(x)\land0\leq g(x)$. %% TODO fix wording

Allora se:
\begin{gather*}
    \lim_{x\to b^-}\frac{f(x)}{g(x)}=l\in\mathbb{R}^+\implies \int_a^b f(x)\mathrm{d}x\land\int_a^b f(x)\mathrm{d}x:\mbox{hanno lo stesso carattere}
\end{gather*}
Un caso particolare è che $f(x)\sim g(x)$, se questo è verificato allora gli integrali impropri di queste due funzioni hanno lo stesso carattere. Questa è una condizione parallela ed indipendente. 
Se invece il limite del rapporto per $x\to b^-$ è nullo ed inoltre, l'integrale sull'intervallo $[a,b)$ di $g(x)$ converge, allora converge anche l'integrale di $f(x)$:
\begin{gather*}
    \displaystyle\lim_{x\to b^-}\frac{f(x)}{g(x)}=0\land\int_a^bg(x)\mathrm{d}x\in\mathbb{R}\implies\int_a^bf(x)\mathrm{d}x\in\mathbb{R}
\end{gather*}
Invece se questo limite diverge ad infinito, e la funzione $g(x)$ non è integrabile in senso improprio, allora diverge anche l'integrale improprio della funzione $f(x)$:
\begin{gather*}
    \displaystyle\lim_{x\to b^-}\frac{f(x)}{g(x)}=\pm\infty\land\displaystyle\int_a^bg(x)\mathrm{d}x=\pm\infty\implies\int_a^bf(x)\mathrm{d}x=\pm\infty
\end{gather*}


%% ALTRO CRITERIO/TEOREMA ?? Convergenza Assoluta?

Siano $f$ continue e illimitate in $[a, b)$.  Se il modulo della funzione $|f(x)|$ è integrabile in senso improprio in $[a,b]$, allora converge anche l'integrale in senso improprio della funzione $f(x)$ in $[a,b]$. Si dice che la funzione $f(x)$ è assolutamente integrabile, se l'integrale converge in modo assoluto allora converge anche in modo semplice. 



%% ESEMPIO

Studiare la convergenza di questo integrale:
\begin{gather*}
    \displaystyle\int_0^1\frac{\sin\left(\frac{1}{x}\right)}{\sqrt[3]{x}}\mathrm{d}x
\end{gather*}
La funzione è continua ed illimitata in questo intervallo $(0,1]$. Questa funzione assume valori di segno diverso, e l'ampiezza dell'oscillazione aumenta per $x\to0^+$. Si valuta la convergenza della funzione di modulo per valutare eventuale convergenza assoluta:
\begin{gather*}
    \displaystyle\int_0^1\frac{\left|\sin\left(\frac{1}{x}\right)\right|}{\sqrt[3]{x}}\mathrm{d}x
\end{gather*}
Si utilizza il metodo del confronto:
\begin{gather*}
    \displaystyle\frac{\left|\sin\left(\frac{1}{x}\right)\right|}{\sqrt[3]{x}}\leq\frac{1}{\sqrt[3]{x}}
\end{gather*}
L'integrale improprio della funzione maggiorante converge, quindi anche l'integrale della funzione minorante converge. 
%% TODO motivo: poiché $\alpha<1$. 


%% ESERCIZIO

Si considera il carattere del seguente integrale:
\begin{gather*}
    \displaystyle\int_0^1\frac{x^2}{\sqrt{1-x}}\mathrm{d}x
\end{gather*}
La funzione integranda è continua ed illimitata in $[0,1)$ ha un punto critico in $x=1$, ha segno definitivamente positivo nell'intervallo $(1-\varepsilon, 1)$. 

\begin{gather*}
    \mbox{per}x\to1^-\displaystyle\frac{x^2}{\sqrt{1-x}}\sim\frac{1}{(1-x)^{1/2}}
\end{gather*}
È asintoticamente equivalente ad una funzione campione $(1-x)^{-\alpha}$, essendo $\alpha<1$ la funzione converge. 

\subsection{Integrali Impropri di Prima Specie}

Sia la funzione $f$ continua in $[a,+\infty)$, allora ha senso parlare dell'integrale:
\begin{gather*}
    \displaystyle\int_a^hf(x)\mathrm{d}x
\end{gather*}
Per $h>a$, una volta calcolato questo integrale, per ottenere il valore dell'integrale improprio sull'intero intervallo $[a,+\infty)$ si calcola il limite:
\begin{gather*}
    \lim_{h\to+\infty}\displaystyle\int_a^hf(x)\mathrm{d}x=\begin{cases}
        \exists\displaystyle\int_a^{+\infty}f(x)\mathrm{d}x\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{gather*}
Se il limite esiste, la funzione è integrabile in modo improprio nell'intervallo $[a,+\infty)$, analogamente l'integrale improprio di prima specie della funzione $f$ converge. Altrimenti il limite può non converge, oppure può essere irregolare e non esistere. 

Si determini il valore del seguente integrale improprio:
\begin{gather*}
    \displaystyle\int_{-\infty}^{+\infty}\frac{\df x}{1+x^2}
    =\lim_{h\to+\infty}\int_{-h}^h\frac{1}{1+x^2}\df x
\end{gather*}
Essendo una funzione pari si può esprimere come:
\begin{gather*}
    \displaystyle\int_{-\infty}^{+\infty}\frac{\df x}{1+x^2}=
    2\lim_{h\to+\infty}\int_0^h\frac{1}{1+x^2}\df x=
    2\lim_{h\to+\infty}\arctan x\bigg|_0^h=\pi\in\mathbb{R}
\end{gather*}


Studiare la convergenza del seguente integrale:
\begin{gather*}
    \displaybreak\intpinf{xe^{-x}}{x}=\lim_{h\to+\infty}\int_0^hxe^{-x}\df x=-\lim_{h\to+\infty}\int_0^he\df(e^{-x})=
    -\lim_{h\to+\infty}\left\{xe^{-x}\bigg|_0^h-\int_0^he^{-x}\df x\right\}\\
    -\lim_{h\to+\infty}\left\{he^{-h}+e^{-x}\bigg|_0^h\right\}=
    -\lim_{h\to+\infty}\left\{\overbrace{he^{-h}}^{\to0}+\underbrace{e^{-h}}{\to0}-1\right\}=-1
\end{gather*}


Studiare il seguente integrale:
\begin{gather*}
    \displaystyle\intab{e^2}{+\infty}{\frac{1}{x\ln^3 x}}{x}=\lim_{h\to+\infty}\int_{e^2}^{h}\frac{\df (\ln x)}{(\ln x)^3}=
    \lim_{h\to+\infty}\int_{e^2}^h(\ln x)^{-3}\df(\ln x)=\lim_{h\to+\infty}\frac{(\ln x)^{-2}}{2}\bigg|_{e^2}^h\\
    -\frac{1}{2}\lim_{h\to+\infty}\left\{\overbrace{\frac{1}{\ln^2 h}}^0-\frac{1}{\ln^2e^2}\right\}=\frac{1}{2}\frac{1}{4}=\frac{1}{8}
\end{gather*}


Studiare la convergenza del seguente integrale, al variare del parametro reale $\alpha\in\mathbb{R}$, con $a>0$:
\begin{gather*}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}
\end{gather*}
Si considera il primo caso per $\alpha=1$:
\begin{gather*}
    \displaystyle\int_a^{+\infty}\frac{1}{x}\df x=\lim_{h\to\infty}\ln x\bigg|_a^h=\lim_{h\to\infty}(\ln h-\ln 0)=+\infty
\end{gather*}
Per $\alpha\neq1$:
\begin{gather*}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}=\lim_{h\to\infty}\int_a^{+\infty}x^{-\alpha}\df x=\lim_{h\to\infty}\frac{x^{-\alpha+1}}{-\alpha+1}\bigg|_a^h=
    \frac{1}{1-\alpha}\lim_{h\to\infty}\left\{h^{1-\alpha}-a^{1-\alpha}\right\}
\end{gather*}
Si considera per quali esponenti si ha $h$ divergente o convergente a zero:
\begin{gather*}
    h^{1-\alpha}=\begin{cases}
        +\infty & \alpha<1\\
        0^+ & \alpha>1
    \end{cases}
\end{gather*}
Quindi l'integrale di partenza:
\begin{gather*}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}=
    \begin{cases}
        +\infty& \alpha\leq1\\
        l\in\mathbb{R}&\alpha>1
    \end{cases}
\end{gather*}

\subsubsection{Teorema Condizione Necessaria di Convergenza}

Sia $f$ continua nell'intervallo $[a,+\infty)$ e sia l'integrale $\int_a^{+\infty}f(x)\df x$ convergente, allora:
\begin{gather*}
    \lim_{x\to+\infty}f(x)=0
\end{gather*}

\subsubsection{Teorema ??}

Sia $f$ continua nell'intervallo $[a,+\infty)$ e sia $f$ definitivamente non negativa $f(x)\geq0$ in $(\delta, +\infty)$.
Allora l'integrale improprio della funzione $f(x)$ sull'intervallo $[a,+\infty)$ è regolare. 

\subsubsection{Criterio del Confronto}

Il criterio del confronto afferma le stesse nozioni enunciate nel criterio del confronto per integrali impropri di seconda specie. 
Siano $f$ e $g$ due funzioni continue nello stesso intervallo illimitato superiormente $[a,+\infty)$. E sia $0\leq f(x)\leq g(x)$ definitamente. 
%% TODO riscrivere in modo migliore
Allora se l'integrale di $g(x)$ converge, allora converge anche l'integrale di $f(x)$, invece se l'integrale sulla funzione $f(x)$ diverge, anche l'integrale di $g(x)$ diverge. 



Studiare il carattere del seguente integrale:
\begin{gather*}
    \displaystyle\int_1^{+\infty}\frac{2+\cos x}{x^2}\df x
\end{gather*}
Si può maggiorare e minorare:
\begin{gather*}
    \displaystyle\frac{1}{x^2}\leq\frac{2+\cos x}{x^2}\leq\frac{3}{x^2}\\
    \displaystyle\int_1^{+\infty}\frac{3}{x^2}\df x\in\mathbb{R}
\end{gather*}
Quindi converge anche l'integrale di partenza. 


Studiare il carattere del seguente integrale:
\begin{gather*}
    \displaystyle\int_0^{+\infty}\frac{2+\cos x}{x^2}\df x
\end{gather*}
Questo integrale è sia di prima che seconda specie. Si divide in due integrali per studiarne il carattere separatamente:
\begin{gather*}
    \displaystyle\int_0^{+\infty}\frac{2+\cos x}{x^2}\df x=
    \int_0^{1}\frac{2+\cos x}{x^2}\df x+
    \underbrace{\int_1^{+\infty}\frac{2+\cos x}{x^2}\df x}_{\mbox{converge}}
\end{gather*}

Per il teorema del confronto si ha:
\begin{gather*}
    \displaystyle\frac{1}{x^2}\leq\frac{2+\cos x}{x^2}\leq\frac{3}{x^2}\implies
    \displaystyle\int_0^{1}\frac{3}{x^2}\df x=\infty
\end{gather*}
Poiché $\alpha<1$, quindi l'integrale di partenza non converge. 

\subsubsection{Teorema del Confronto Asintotico}

Siano $f$ e $g$ due funzioni continue nello stesso intervallo illimitato superiormente $[a,+\infty)$. E sia $f(x),\,g(x)\geq0$ definitamente.

Allora se il limite:
\begin{gather*}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=l\in\mathbb{R}^+
\end{gather*}
Allora gli integrali impropri di $f(x)$ e $g(x)$ hanno lo stesso carattere, in particolare $f(x)\sim g(x)$ per $x\to\infty$. 

Invece se:
\begin{gather*}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=0
\end{gather*}
E l'integrale impropri della funzione $g(x)$ converge, allora anche l'integrale improprio di $f(x)$ converge. 


Se:
\begin{gather*}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=+\infty
\end{gather*}
E l'integrale improprio della funzione $g(x)$ diverge, allora anche l'integrale improprio sulla funzione $f(x)$ diverge. 

\subsubsection{Teorema Convergenza Assoluta}

Sia $f$ continua in $[a,+\infty)$, allora se l'integrale improprio:
\begin{gather*}
    \displaystyle\int_a^{+\infty}|f(x)|\df x
\end{gather*}
Converge, anche l'integrale improprio senza valore assoluto converge. Questo si dice criterio di convergenza assoluta ed implica la convergenza semplice. La funzione $f$ si dice assolutamente integrabile. 

%% TODO sin x/x^2 [1, inf) |sin x|/x^2
%% TODO sin x/x [1, inf) |sin x|/x => conv smp, div abs

\begin{gather*}
    \displaystyle\int_{1}^{+\infty}\frac{\sin x}x\df x
\end{gather*}
Non potendo utilizzare i teoremi, si calcola direttamente:
\begin{gather*}
    \displaystyle\int_{1}^{+\infty}\frac{\sin x}x\df x=
    \lim_{h\to\infty}\int_{1}^{h}\frac{-\df(\cos x)}x=
    -\lim_{h\to\infty}\left\{\frac{\cos x}{x}\bigg|_1^h+\intab{1}{h}{\frac{\cos x}{x^2}}{x}\right\}\\
    -\lim_{h\to\infty}\left\{\cancelto{0}{\frac{\cos h}{h}}-\cos1+\intab{1}{h}{\frac{\cos x}{x^2}}{x}\right\}=
    \lim_{h\to\infty}\left\{\cos1-\intab{1}{h}{\frac{\cos x}{x^2}}{x}\right\}\\
    \displaystyle\int_{1}^{+\infty}\frac{\sin x}x\df x=\cos1-\int_1^{+\infty}\frac{\cos x}{x^2}\df x
\end{gather*}
Si è trasformato l'integrale di partenza in un integrabile dove è applicabile il teorema del confronto, e si dimostra che converge. %% TODO

%% TODO Dimostrare convergenza di cos x/x sullo stesso intervallo 

Dimostrare che:
\begin{gather*}
    \displaystyle\int_1^{+\infty}\frac{|\sin x|}{x}\df x=+\infty
\end{gather*}
Si suppone per assurdo che questo integrale converga, la funzione è sicuramente maggiorabile da:
\begin{gather*}
    \sin^2x\leq|\sin x|\leq1
\end{gather*}
Ma per il teorema del confronto converge anche l'integrale della funzione minorante:
\begin{gather*}
    \displaystyle\int_{1}^{+\infty}\frac{\sin^2 x}x\df x
\end{gather*}
sfruttando la formula di duplicazione del coseno:
\begin{gather*}
    \displaystyle\int_{1}^{+\infty}\frac{\sin^2 x}x\df x=
    \int_1^{+\infty}\frac{1-\cos2x}{2x}\df x=
    \frac{1}{2}\int_1^{+\infty}\frac{\df x}{x}-\int_1^{+\infty}\frac{\cos(2x)}{2x}\df (2x)
\end{gather*}
Il secondo integrale corrisponde a quello dimostrato precedentemente, il primo è un integrale notevole che diverge, ma per ipotesi converge, quindi l'ipotesi iniziale è errata e quindi l'integrale non converge. 

\subsection{Funzioni} %% TODO fix section name
%% DEF 1
Le serie di Fourier sono serie di funzioni utilizzate per approssimare funzioni periodiche. Una funzione $f$ definita su $D_f$ illimitato, si dice periodica di periodo $T$ se $\forall x\in D_f$ si ha:
\begin{enumerate}
    \item $x+kT\in D_f\,\,\forall k\in\mathbb{Z}$
    \item $f(x+kT)=f(x)$
\end{enumerate}
%% DEF 2
Una funzione $f$ si dice continua a tratti in un intervallo limitato $I$, se $f$ è continua in $I$, tranne che in una quantità finita di punti di discontinuità di prima o terza specie. 

È integrabile in $I$ ed il suo integrale esiste, è utile poiché per determinare la serie di Fourier bisognerà risolvere integrali. 

%% DEF 3
Una funzione $f$ si dice regolare a tratti in un intervallo limitato $I$, se è continua a tratti in $I$, e se ha derivata continua in $I$ tranne che nel punto di discontinuità più altri punti dove $f$ non è derivabile, in quantità finita. In tali punti esistono finiti i limiti $\lim_{x\to x_0^-}f'(x)\neq\lim_{x\to x_0^+}f'(x)$. 

% punto angoloso , discontinuità a tratti
Una funzione si dire continua o regolare a tratti in $\mathbb{R}$, se in lo è in ogni arbitrario intervallo limitato. 


%% IMG serie di triangoli /\/\/\/\/\

Sia $f$ una funzione continua a tratti in $\mathbb{R}$ è periodica di periodo $T$, l'integrale su un periodo $T$, $\forall a\in\mathbb{R}$, si può esprimere in maniera equivalente come:
\begin{gather*}
    \displaystyle\intab{a}{a+T}{f(x)}{x}=
    \displaystyle\intab{0}{T}{f(x)}{x}=
    \displaystyle\intab{-T/2}{T/2}{f(x)}{x}
\end{gather*}
Per semplicità si vuole considerare un intervallo simmetrico, per facilitare il calcolo, sfruttando eventuali simmetrie della funzione. 


La serie di Fourier di $f$ viene definita come:
\begin{gather}
    \displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)+b_k\sin\left(\frac{2k\pi}{T}x\right)
\end{gather}
Dove i coefficienti $a_k$ e $b_k$ sono dati da:
\begin{gather}
    a_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x\\
    b_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x
\end{gather}

Può succedere che la funzione $f$ rispetta la simmetria, e quindi si possono semplificare queste formule. Se $f$ è pari:
\begin{gather*}
    a_k=\displaystyle\frac{4}{T}\int_{0}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x\\
    b_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x=0\\
    \displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)
\end{gather*}
Mentre se $f$ è dispari si ha:

\begin{gather*}
    a_k=\displaystyle\frac{4}{T}\int_{-T/2}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x=0\\
    b_k=\displaystyle\frac{4}{T}\int_{0}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x\\
    \displaystyle\sum_{k=1}^\infty b_k\sin\left(\frac{2k\pi}{T}x\right)
\end{gather*}

\subsubsection{Teorema}
Sia $f$ regolare a tratti in $\mathbb{R}$ ed inoltre sia periodica di periodo $T$. Allora se $f$ è continua in $x_0$:
\begin{gather*}
    \displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)+b_k\sin\left(\frac{2k\pi}{T}x\right)=f(x_0)
\end{gather*}
Se $f(x)$ non è continua in $x_0$ allora:
\begin{gather*}
    \displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)+b_k\sin\left(\frac{2k\pi}{T}x\right)=\frac{f(x_0^-)+f(x_0^+)}{2}\,\mbox{dove}\\
    f(x_0^-)=\lim_{x\to x_0^-}f(x)\\
    f(x_0^+)=\lim_{x\to x_0^+}f(x)
\end{gather*}

\clearpage

\section{Equazioni Differenziali} 
%% 3/4/25

Le equazioni differenziali sono un modello matematico di tipo algebrico, sono un modo di studiare un fenomeno, in genere fisico. Prima di studiare il fenomeno bisogna studiare le grandezze di questo fenomeno, ed in seguito bisogna individuare un legame per definire o possibilmente determinare l'evoluzione del fenomeno stesso. 

Un'equazione differenziale è un'equazione dove l'incognita è una funzione $y=f(x)$, continua nell'intervallo su cui è definita l'equazione, e sono presenti dei termini differenziali di $n$-esimo ordine della funzione $y$:
\begin{equation}
    f(x, y, y', \cdots, y^{(n)})=0
\end{equation}
La funzione e tutte le sue derivate sono tutte definite su un insieme dell'asse reale $\mathbb{R}$. 

Considerando il valore generico della variabile indipendente $x$, l'equazione differenziale è una relazione tra i valori della $x$ ed i valori assunti dalla funzione incognita e le sue derivate. 
Per ordine dell'equazione si intende ordine massimo della derivata presente nell'equazione, $n-$esimo. Se è possibile esplicitare la derivata $n-$esima dell'equazione, allora l'equazione si dice espressa in forma normale:
\begin{equation}
    y^{(n)}=f(x, y, y', \cdots, y^{(n-1)})
\end{equation}

Un'equazione differenziale si dice lineare se sia la funzione che le sue derivate sono elevate ad una potenza massima pari ad uno, e non sono presenti termini misti. 


Si considera un'equazione differenziale ordinaria di primo ordine $y'=f(x,y)$, si possono rappresentare sul piano le coppie di questa funzione $(\bar{x},\bar{y})$, e la derivata ha un significato grafico ovvero la pendenza in questo punto. Questa funzione viene definita in un intervallo che individua un rettangolo, se per ogni punto di questo insieme si può disegnare 
un segmento che rappresenta la pendenza in questo punto, si genera una figura simile ad un campo vettoriale. La funzione $y'$ è l'inviluppo di tutti questi segmenti così individuati. 

%% TODO ??
% Sia un valore $x_0\in I$, dove $I$ è l'intervallo su cui è definita l'equazione differenziale, e la funzione $f(x)$ è continua. Se $y_0=y(x_0)\neq0$, nell'intorno di $x_0$, $I(x_0)$, la funzione $y(x)$ ha sempre lo stesso segno:
% \begin{gather*}
%     x\in I(x_0):y(x)\neq0\implies \displaystyle\frac{y(x)}{y_0}>0
% \end{gather*}


\subsection{Equazione a Variabili Separabili}

Un'equazione differenziale ordinaria a variabili separabili è un'equazione che può essere ricondotta ad una forma nota come la seguente:
\begin{equation}
    y'=g(x)\cdot h(y)
\end{equation}
Si considerano integrali singolari, che corrispondono alle soluzioni di $h(y)=0$, questi integrali singolari vengono esclusi dai procedimenti successivi, per $h(y)\neq0$, si può risolvere considerando:
\begin{gather*}
    \displaystyle\frac{\df y}{\df x}=g(x)\cdot h(y)\\
    \displaystyle\frac{1}{h(y)}\df y=g(x)\df x\\
    \displaystyle\int\frac{1}{h(y)}\df y=\int g(x)\df x
\end{gather*}
In seguito si prova ad esprimere esplicitamente l'incognita $y$ in funzione della variabile indipendente $x$. Questo primo modo di procedere è laborioso. 
Si può risolvere in modo più rigoroso considerando la primitiva del primo membro:
\begin{gather*}
    H(y)=\displaystyle\int\frac{1}{h(y)}\df y\implies H'(y)=\frac{1}{h(y)}
\end{gather*}
Sostituendola nell'equazione di partenza si ottiene:
\begin{gather*}
    H'(y)y'=g(x)
\end{gather*}
Il primo membro ora somiglia alla derivata di una funzione composta, quindi si può riscrivere come:
\begin{gather*}
    \displaystyle\frac{ \df H}{\df x}=g(x)\\
    \displaystyle H(y(x))=\int g(x)\df x+c
\end{gather*}
Quindi in teoria $H(y)$ è una funzione monotona, e quindi continua, poiché la sua derivata è il reciproco di $h(y)$ e non si annulla, quindi è invertibile. Si può quindi considerare la funzione inversa di $H(y)$: $H^{-1}(y)$. Applicandola membro a membro all'equazione ottenuta precedentemente si ottiene:
\begin{gather}
    H^{-1}\left[H(y(x))\right]=y(x)=H^{-1}\left[\displaystyle\int g(x)\df x+c\right]
\end{gather}
Anche se la funzione è invertibile non è detto che si riesca ad individuare la sua inversa, per cui a volte bisogna accontentarsi dell'espressione implicita: 
\begin{gather*}
    \displaystyle H(y(x))=\int g(x)\df x+c
\end{gather*}


%% ESEMPIO

Si considera la seguente equazione differenziale:
\begin{gather*}
    y'=y(1-y)
\end{gather*}
Si individuano gli integrali singolari in $y_0=0$ e $y_1=1$, si separano ora le variabili e si ottiene la seguente:
\begin{gather*}
    \displaystyle\frac{\df y}{y(1-y)}=\df x\\
    \displaystyle\int \frac{\df y}{y(1-y)}=\int \df x=x+c_0
\end{gather*}
Si separa la funzione integranda del primo membro in fratti semplici:
\begin{gather*}
    \displaystyle\int\frac{\df y}{y(1-y)}=\int\frac{\df y}{y}-\int\frac{\df y}{y-1}=x+c_0\\
    \ln|y|-\ln|y-1|+c_1=x+c_0\,\land c_2=c_0-c_1\\
    \ln|y|-\ln|y-1|=x+c_2\\
    \ln\left|\displaystyle\frac{y}{y-1}\right|=x+c_2
\end{gather*}

Per eliminare il logaritmo si considera entrambi i membri come l'argomento dell'esponenziale:
\begin{gather*}
    \displaystyle\frac{y}{y-1}=e^{c_2}e^x=c_3e^x\\
    y=c_3e^x(y-1)=c_3ye^x-c_3e^x\\
    y(1-c_3e^x)=-c_3e^x\implies y=-\frac{c_3e^x}{1-c_3e^x}=\frac{c_3e^x}{c_3e^x-1}
\end{gather*}


Si considera la seguente equazione differenziale:
\begin{gather*}
    y'=\displaystyle\frac{e^x+1}{e^y+1}
\end{gather*}
Integrali singolari corrispondono a $e^y+1=0$, ma non esistono valori reali di $y$ tali da annullare il denominatore: $\nexists y\in\mathbb{R}$. 
Si separano le variabili:
\begin{gather*}
    \displaystyle\int(e^y+1)\df y=\int (e^x+1)\df x\\
    e^y+y+c_0=e^x+x+c_1\implies e^y+y=e^x+x+c_2
\end{gather*} 

\subsection{Problema di Cauchy}

Il problema di Cauchy consiste nell'assegnare una condizione iniziale ad un'equazione differenziale:
\begin{gather*}
    \begin{cases}
        y'=f(x,y)\\
        y(x_0)y_0
    \end{cases}
\end{gather*}


%% TODO esercizi y'=(1+y^2)?? y'=cos^2y->y=arctan(x+c)

\subsection{Equazioni Differenziali Lineari del Primo Ordine}

Sono equazioni del tipo:
\begin{gather*}
    y'+p(x)y=f(x)
\end{gather*}
Dove le funzioni $p$ ed $f$ sono definite su un intervallo dove è definita anche la funzione incognita $y(x)$. La funzione $p$ viene chiamata funzione coefficiente e la funzione $f$ funzione forzante. Per risolvere questo tipo di equazioni è fondamentale la determinazione del fattore integrante.
% cia u sei kattivaciaOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO

Si considera la seguente equazione differenziale:
\begin{gather*}
    y'+\displaystyle\frac{2}{x}y=\frac{2}{x^3}\\
    x^2y'+2xy=\displaystyle\frac{\df (x^2y)}{\df x}=\frac{2}{x}\\
    \displaystyle x^2y=\int \frac{2}{x}\df x=2\ln x + c
\end{gather*}

Si vuole lavorare in modo che un membro diventi una derivata, considerando l'equazione generale si moltiplicano ambo i lati per la funzione $\mu$:
\begin{gather*}
    \mu y'+\mu p(x)y=\mu f(x)
\end{gather*}% !! <3 ily 2
Si vuole avere la derivata del prodotto al primo membro:
\begin{gather*}
    (\mu y)'=\mu'x+\mu y'\\
    \cancel{\mu y'}+\mu p(x)y=\mu'x+\cancel{\mu y'}\\
    \mu p(x)=\mu'\implies\displaystyle\int\frac{y'}{y}=p(x)\\
    \ln\mu=\displaystyle\int p(x)\df x\\
    \mu=e^{\int p(x)\df x}
\end{gather*}

%% TODO si può riportare in equazione a variabili separabili

%% ESEMPIO

Si considera il seguente problema di Cauchy:
\begin{gather*}
    \begin{cases}
        y'+5y=0\\
        y(1)=-2
    \end{cases}
\end{gather*}
Si determina il fattore integrante:
\begin{gather*}
    A(x)=\displaystyle\int p(x)\df x=\int5\df x=5x\\
    e^{A(x)}=e^{5x}
\end{gather*}
Si moltiplica l'equazione differenziale per il fattore integrante appena trovato e si determina la derivata di partenza:
\begin{gather*}
    e^{5x}(y'+5y)=D[y\cdot e^{5x}]=0
\end{gather*}
Poiché la derivata è nulla, la funzione è costante quindi si ha:
\begin{gather*}
    y\cdot e^{5x}=c\implies y=ce^{-5x}
\end{gather*}
Per determinare il valore della costante $c$ si inserisce il vincolo:
\begin{gather*}
    y(1)=ce^{-5(1)}=-2\implies c=-2e^5\\
    y=-2e^5e^{-5x}=-2e^{5(1-x)}
\end{gather*}


Considerare il seguente problema di Cauchy :
\begin{gather*}
    \begin{cases}
        \displaystyle x'(t)-\frac{1}{t+1}x(t)=3\\
        x(0)=1 & t\in(-1,+\infty)
    \end{cases}\\
    A(t)=\displaystyle-\int\frac{1}{t+1}\df t=-\ln(t+1)+c_0\implies e^{A(t)}=\frac{e^{c_0}}{t+1}\\
    \displaystyle\frac{e^{c_0}}{t+1}\left[ x'(t)-\frac{1}{t+1}x(t)\right]=\frac{3}{t+1}=D\left[\frac{x}{t+1}\right]\\
    \displaystyle\cancel{\int}\cancel{\df}\left(\frac{x}{t+1}\right)=e^{-c_0}\int \frac{3}{t+1}=3e^{-c_0}\ln(t+1)+c_1e^{-c_0}\\
    x=(t+1)e^{-c_0}\ln(t+1)^3+c_1e^{-c_0}(t+1)
\end{gather*}

\subsection{Operatore Differenziale}

Sia $p(x)$ continua in $I$, l'operatore differenziale $L$ assegna ad ogni funzione $y$:
\begin{gather*}
    L[y]=y'+p(x)y
\end{gather*}
Questo operatore è molto comodo per rappresentare equazioni differenziali lineare di primo ordine. 
L'operatore differenziale è lineare, per cui data una funzione $y_1$, tale che $L[y_1]=0$ e $y_2$ tale che $L[y_2]=0$, allora si ha:
\begin{gather*}
    L[c_1y_1+c_2y_2]=c_1y'_1+p(x)c_1y_1+c_2y'_2+p(x)c_2y_2=c_1L[y_1]+c_2L[y_2]=0
\end{gather*}
La combinazione lineare di due soluzioni è soluzione dell'equazione lineare omogenea. 

Data una soluzione $\omega_1$ ed $\omega_2$ ad un'equazione differenziale lineare di primo ordine non omogenea: $L[\omega_1]=f(x)$, $L[\omega_2]=f(x)$, allora si ha che:
\begin{gather*}
    L[\omega_1-\omega_2]=L[\omega_1]-L[\omega_2]=f(x)-f(x)=0
\end{gather*}
Quindi la differenza tra queste due soluzioni, rappresenta una soluzione per l'equazione omogenea $\omega_1-\omega_2=y$. Ogni soluzione della omogenea si può esprimere come:
\begin{gather*}
    y=c\cdot y e^{-A(t)}\mbox{ dove } A(t)=\displaystyle\int p(x)\df x
\end{gather*}
Per cui fissando $\omega_2$, la soluzione generale ad un'equazione non omogenea si ottiene fissando una particolare soluzione ed aggiungendo l'integrale generale per la sua soluzione omogenea:
\begin{gather}
    \omega_1-\omega_2=y=c\cdot e^{-A(t)}\implies\omega_1=\overbrace{\omega_2}^{\text{non omogenea}}+\underbrace{c\cdot e^{-A(t)}}_{\text{omogenea}}
\end{gather}
Questo permette di semplificare l'integrazione in un caso abbastanza particolare. 
Supponendo che $p(x)$ sia una costante $k$, allora la soluzione particolare $\bar{y}$ è dello stesso tipo della forzante $f(x)$, per il criterio della similarità. La funzione $f(x)$ può essere una costante, un polinomio, una funzione sinusoidale o esponenziale. Questo rappresenta un modo euristico per risolvere il problema, considerando una soluzione dello stesso tipo, a differenza di una costante, da individuare. 


Sia questa equazione differenziale:
\begin{gather*}
    y'-\displaystyle\frac{1}{2}y=x^2-1\\
    \bar{y}=ax^2+bx+c\\
    2ax+b-\displaystyle\frac{1}{2}\left(ax^2+bx+c\right)=x^2-1
\end{gather*}
Per la proprietà di identità dei polinomi si ha:
\begin{gather*}
    \begin{cases}
        \displaystyle-\frac{\strut 1}{\strut 2}a=1\\
        2a-\displaystyle\frac{\strut1}{\strut2}b=0\\
        b-\displaystyle\frac{\strut1}{\strut2}c=-1
    \end{cases}\implies\begin{cases}
        a=-2\\
        -4-\displaystyle\frac{\strut1}{\strut2}b=0\implies b=-8\\
        -8-\displaystyle\frac{\strut1}{\strut2}c=-1\implies c=-14
    \end{cases}\\
    \bar{y}=-2x^2-8x-14
\end{gather*}
La soluzione di questa equazione differenziale è quindi:
\begin{gather*}
    y=c\cdot e^{-\int\frac{1}{2}\df x}-2x^2-8x-14
\end{gather*}



Considerare quest'equazione differenziale:
\begin{gather*}
    L[y]=y'+5y=\sin2x
\end{gather*}
La soluzione particolare è quindi del tipo:
\begin{gather*}
    \bar{y}=A\sin2x+B\cos2x\\
    \bar{y}'=2A\cos2x-2B\sin2x\\
    \bar{y}'+5\bar{y}=2A\cos2x-2B\sin2x+5(A\sin2x+B\cos2x)=\sin2x\\
    \begin{cases}
        2A+5B=0\\
        -2B+5A=1
    \end{cases}\implies\begin{cases}
        A=\displaystyle-\frac{\strut5}{\strut2}B\\
        -2B-\displaystyle\frac{\strut25}{\strut2}B=1\implies B=\displaystyle-\frac{1}{29}
    \end{cases}\implies\begin{cases}
        A=\displaystyle\frac{\strut5}{29}\\
        B=\displaystyle-\frac{\strut2}{\strut29}
    \end{cases}\\
    \bar{y}=\displaystyle\frac{5}{29}\sin2x-\frac{2}{29}\cos2x
\end{gather*}
La soluzione dell'equazione differenziale è quindi:
\begin{gather*}
    y=c\cdot e^{-\int 5\df  x}\displaystyle\frac{5}{29}\sin2x-\frac{2}{29}\cos2x
\end{gather*}


Se si ha un esponenziale nella soluzione particolare che coincide all'integrale omogeneo:
\begin{gather*}
    L[y]=y'+\alpha y=\beta e^{-\alpha x}
\end{gather*}
La soluzione particolare non è del tipo $ke^{-\alpha x}$ come la forzante $\beta e^{-\alpha x}$, non segue completamente la regola della similarità:
\begin{gather*}
    \bar{y}=kxe^{-\alpha x}\\
    \bar{y}'=ke^{-\alpha x}-\alpha kxe^{-\alpha x}
\end{gather*}
La costante $k$ è quindi:
\begin{gather*}
    ke^{-\alpha x}-\cancel{\alpha kxe^{-\alpha x}}+\bcancel{\alpha kxe^{-\alpha x}}=\beta\cdot e^{-\alpha x}\\
    k=\beta
\end{gather*}
La soluzione generale dell'equazione differenziale è quindi:
\begin{gather*}
    y=ce^{-\int\alpha\df x}+\bar{y}=ce^{-\int\alpha\df x}+\beta xe^{-\alpha x}
\end{gather*}


Sia $L[y]=y'p(x)y=0$, e siano due soluzioni particolari $\bar{y}_1$ e $\bar{y}_2$ rispettivamente $L[\bar{y}_1]=f(x)$ e $L[\bar{y}_2]=g(x)$, allora l'equazione differenziale $L[y]=f(x)+g(x)$ ha soluzione particolare in $\bar{y}_1+\bar{y}_2$. 
Analogamente la loro combinazione lineare rappresenta integrale particolare dell'equazione differenziale: $c_1\bar{y}_1+c_2\bar{y}_2$. 

\subsection{Riduzione dell'Ordine}

Data un'equazione differenziale $y'=f(x,y)$, può essere che al secondo membro non sia presente la variabile $y$, e quindi assume la forma $y'=f(x)$. Questa equazione differenziale si può risolvere quindi per integrazione diretta:
\begin{gather*}
    y=\displaystyle\int f(x)\df x
\end{gather*}

Analogamente per un'equazione differenziale del tipo $y''=f(x,y,y')$, se la costante per $y$ è nulla diventa: $y"=f(x,y')$. Si può effettuare una sostituzione con $z=y'$, per ridurre l'ordine dell'equazione differenziale:
\begin{gather*}
    z'=f(x,z)
\end{gather*}
Risolvendo per $z$, si può ottenere la soluzione $y$, effettuando un'integrazione diretta:
\begin{gather*}
    y=\displaystyle\int z\df z
\end{gather*}

\subsection{Equazione Differenziale di Bernoulli}

Un'equazione di Bernoulli è un'equazione del tipo:
\begin{gather*}
    y'+p(x)y+q(x)y^m=0
\end{gather*}
Per risolvere l'equazione si dividono ambo i membri per $y^{m}$:
\begin{gather*}
    y^{-m}y'+p(x)y^{1-m}+q(x)=0
\end{gather*}
A questo punto si introduce un'altra variabile. Si pone $u=y^{1-m}$:
\begin{gather*}
    u'=(1-m)y^{-m}y'\\
    \displaystyle\frac{1}{1-m}u'+p(x)u+q(x)=0
\end{gather*}
In questo modo è diventata un'equazione differenziale lineare del primo ordine, risolubile con i metodi precedenti. 


Risolvere la seguente equazione differenziale:
\begin{gather*}
    y'-2y=-e^xy^2
\end{gather*}
Per il metodo di Bernoulli diventa:
\begin{gather*}
    y^{-2}y'-2y^{-1}=-e^{x}\\
    u=y^{-1}\implies u'=-y^{-2}y'\\
    -u'-2u'=-e^{-x}\to u'+2u'=e^{x}
\end{gather*}
L'equazione omogenea ha per soluzione:
\begin{gather*}
    u_0=c\cdot e^{-\int 2\df x}
\end{gather*}
La soluzione particolare è della forma:
\begin{gather*}
    \bar{u}=ke^{x}\to\bar{u}'=kxe^x\\
    kxe^x+2ke^{x}=e^x\\
    k=\displaystyle\frac{1}{3}\\
    \bar{u}=\displaystyle\frac{1}{3}e^{x}
\end{gather*}
La soluzione dell'equazione differenziale è quindi data dalla somma tra la soluzione particolare ed omogenea:
\begin{gather*}
    u=c\cdot e^{-\int 2\df x}+\bar{u}=c\cdot e^{-\int 2\df x}+\displaystyle\frac{1}{3}e^{x}
\end{gather*}
Per ottenere la soluzione in termini di $y$ si considera $u=y^{-1}$:
\begin{gather*}
    y=u^{-1}=\displaystyle\frac{1}{c\cdot e^{-\int 2\df x}+\frac{1}{3}e^{x}}
\end{gather*}


Risolvere la seguente equazione differenziale:
\begin{gather*}
    y'-\displaystyle\frac{y}{x}=-\frac{1}{y}
\end{gather*}
Questa rappresenta un'equazione di Bernoulli con $m=-1$, si pone $u=y^2$:
\begin{gather*}
    \frac{1}{2}u'-\frac{u}{x}=-1\\
    u'-\frac{2u}{x}=-2
\end{gather*}
Si risolve rispetto ad $u$:
\begin{gather*}
    A(x)=-\displaystyle\int\frac{2}{x}\df x=-2\ln x=\ln\frac{1}{x^2}\\
    e^{-A(x)}=x^2
\end{gather*}

%% TODO fix
% u=2x+cx^2
%% TODO solve: y'-2y/x=2x\sqrt{y}

Un'esercizio abbastanza frequente è l'esercizio inverso, dove viene data una soluzione ad un'equazione differenziale $y(x)$ e si chide di ottenere un'equazione differenziale. 
% y=cx+sinx
Il primo metodo consiste nel derivare la soluzione per trovare il valore della costante, e poi sostituirlo nell'equazione originaria. 
%% TODO risolvere con questo metodo
Un altro metodo consiste nel prendere la porzione della soluzione corrispondente alla soluzione omogenea, tale che $L[y_0]=0$, ed eguagliarla a $cx^{-A(x)}$, per determinare $p(x)$, derivando $A(x)$. 
%% TODO risolvere con questo metodo
Quindi si può esprimere come:
\begin{gather*}
    L[y]=f(x)\equiv y'+A'(x)y=f(x)
\end{gather*}
%% TODO finish 
% y'-y/x=cosx-sinx/x
%% TODO foto esercizi lavagna 10/4/25

\subsection{?}

Equazione di Manfredi:
\begin{gather*}
    y'=f\left(\displaystyle\frac{ax+by}{cd+dy}\right)    
\end{gather*}
Si considera funzioni omogenee di grado zero:
\begin{gather*}
    y'=f(x,y)=f(tx,ty)
\end{gather*}
Se si considera $t=x^{-1}$ si ottiene:
\begin{gather*}
    y'=f\left(1,\displaystyle\frac{y}{x}\right)
\end{gather*}
Per trovare una soluzione si effettua un'ulteriore sostituzione $z=yx^{-1}$:
\begin{gather*}
    y=xz,\,y'=z+xz'\\
    z+xz'=f(1,z)=F(z)
\end{gather*}
Quest'ultima diventa un'equazione a variabili separabili del tipo:
\begin{gather*}
    xz'=F(z)-z\\
    \displaystyle\frac{\df z}{F(z)-z}=\frac{\df x}{x}
\end{gather*}


Un esempio classico di questo tipo di funzione è:
\begin{gather*}
    y'=\displaystyle\frac{x-y}{x+y}
\end{gather*}
Applicando la sostituzione $z=y/x$, si divide tutto per $x$:
\begin{gather*}
    z+xz'=f(x,y)=F(z)=\displaystyle\frac{1-z}{1+z}
\end{gather*}
Allora si può scrivere come:
\begin{gather*}
    \displaystyle\frac{\df z}{\frac{1-z}{1+z}-z}=\frac{\df x}{x}\\
    \displaystyle\frac{1+z}{1-z-z-z^2}\df z=\frac{\df x}{x}\\
    \displaystyle\frac{1}{2}\frac{2z+2}{x^2+2z-1}\df z=\frac{1}{2}\frac{\df(z^2+2z-1)}{z^2+2z-1}=-\frac{\df x}{x}\\
    \displaystyle\frac{1}{2}\ln|z^2+2z-1|=-\ln x+c\\
    \displaystyle\ln|z^2+2z-1|=-\ln x^2+c
\end{gather*}
Elevando a potenza entrambi i membri si ottiene la seguente:
\begin{gather*}
    z^2+2z-1=\frac{c}{x^2}
\end{gather*}
Considerando la sostituzione $z=y/x$, si sostituisce e si ottiene:
\begin{gather*}
    \displaystyle\frac{y^2}{x^2}+2\frac{y}{x}-1=\frac{c}{x^2}
\end{gather*}

%% TODO ex a casa:
Risolvere la seguente equazione differenziale;
\begin{gather*}
    y'=\displaystyle\frac{x^3+y^3}{xy^2}
\end{gather*}

\subsection{Equazione di Riccati}

La conoscenza di una radice permette di semplificare l'esercizio di determinare ulteriori radici di un polinomio. Analogamente conoscendo una soluzione di un'equazione differenziale, è possibile individuare più facilmente altre soluzioni. 
L'equazione di Riccati del primo ordine è del tipo:
\begin{gather*}
    y'=p(t)y^2+q(t)y+r(t)
\end{gather*}
Sembra, anche se non lo è, un'equazione di Bernoulli. Si suppone si conosca una soluzione $u(t)$ di questa equazione, a questo punto si sostituisce $y=u(t)+1/z$:
\begin{gather*}
    u'(t)-\displaystyle\frac{z'}{z}=p(t)\left(u(t)+\frac{1}{z}\right)^2+q(t)\left(u(t)+\frac{1}{z}\right)+r(t)\\
    u'(t)-\displaystyle\frac{z'}{z}=p(t)\left(u(t)^2+2\frac{u(t)}{z}+\frac{1}{z^2}\right)+q(t)\left(u(t)+\frac{1}{z}\right)+r(t)\\
    \displaystyle-\frac{z'}{z^2}=-u'(t)+p(t)u^2+p(t)\frac{1}{z^2}+2\frac{p(t)u(t)}{z}+q(t)\left(u(t)+\frac{1}{z}\right)+r(t)
\end{gather*}
Sapendo che $u(t)$ è una soluzione, si può sostituire: %% TODO ??
\begin{gather*}
    -z'=\left(-u'(t)+p(t)u^2+p(t)\frac{1}{z^2}+2\frac{p(t)u(t)}{z}+q(t)\left(u(t)+\frac{1}{z}\right)+r(t)\right)z^2\\
    -z'=(2u(t)p(t)+q(t))z-p(t)
\end{gather*}

%% TODO ??
Esempio perché non gli andava di continuare la cosa di prima:
\begin{gather*}
    \begin{cases}
        y'+y^2-1=0\\
        y(0)=-\displaystyle\frac{\strut 1}{\strut3}
    \end{cases}\\
    y=k=1
\end{gather*}
Si sostituisce $y=1+1/z$, supponendo che $1$ sia una soluzione:
\begin{gather*}
    \displaystyle-\frac{1}{z^2}z'+1+\frac{1}{z^2}+\frac{2}{z}-1=0\\
    -z'+\cancel{z^2}+1+2z-\bcancel{z^2}=0\\
    -z'+2z+1=0\to z'-2z=1
\end{gather*}
Si risolve ora quest'equazione semplificata:
\begin{gather*}
    A(t)=\displaystyle\int-2\df v=-2t\\
    e^{A(t)}=e^{-2t}\implies e^{-2t}\left[z'-2z\right]=e^{-2t}
\end{gather*}
\begin{gather*}
    D[ze^{-2t}]=e^{-2t}\\
    ze^{-2t}=\displaystyle\int e^{-2t}\df t+c=-\frac{1}{2}\int e^{-2t}\df(-2t)+c\\
    z=e^{-2t}\left(-\frac{1}{2e^{-2t}}+c\right)=ce^{2t}-\frac{1}{2}
\end{gather*}
Considerando la sostituzione iniziale, si ha:
\begin{gather*}
    z=\displaystyle\frac{1}{y-1}=ce^{2t}-\frac{1}{2}
\end{gather*}

\subsection{Equazioni Esatte}

Le equazioni frate sono un tipo di equazioni nella forma:
\begin{gather*}
    X(x,y)\df x+Y(x,y)\df y=0
\end{gather*}
Si può portare nella forma di un'equazione differenziale come:
\begin{gather*}
    X(x,y)+Y(x,y)\displaystyle\frac{\df y}{\df x}=0\\
    y'=\displaystyle-\frac{X(x,y)}{Y(x,y)}
\end{gather*}

La soluzione è una funzione $\Phi$ che ammette derivate parziali, le quali sono uguali a $X$ e $Y$:
\begin{gather*}
    \displaystyle\frac{\partial\Phi}{\partial x}=X(x,y)\\
    \displaystyle\frac{\partial\Phi}{\partial y}=Y(x,y)
\end{gather*}
E derivata nulla rispetto ad $x$:
\begin{gather*}
    \displaystyle\frac{\df\Phi}{\df x}=0
\end{gather*}
Le sue derivate parziali sono i coefficienti della forma lineare differenziale dell'equazione esatta:
\begin{gather*}
    \displaystyle\frac{\df\Phi}{\df x}=\frac{\partial\Phi}{\partial x}+\frac{\partial\Phi}{\partial y}\frac{\df y}{\df x}=
    X(x,y)+Y(x,y)\frac{\df y}{\df x}
\end{gather*}
Se questo è verificato la soluzione è del tipo $\Phi(x,y)=c$, ma devono essere verificate le condizioni per l'esistenza della soluzione. 

La condizione da verificare è la condizione di chiusura, ovvero le derivate miste devono essere congruenti e deve quindi essere verificato il teorema di Schwarz:
\begin{gather*}
    \displaystyle\frac{\partial\Phi}{\partial x\partial y}=\frac{\partial\Phi}{\partial y\partial x}
\end{gather*}
In un dominio rettangolare del piano $(x,y)$:
%% TODO add img piano rettangolo

Le funzioni $X$ e $Y$ devono essere continue, quindi devono essere continue le derivate parziali di $\Phi$. 



Si considera un'equazione in forma esatta:
\begin{gather*}
    (4y^2+y-4x^2)\df x+(8xy+x)\df y=0
\end{gather*}
Si verifica la condizione di chiusura:
\begin{gather*}
    X_y=\frac{\partial}{\partial y}(4y^2+y-4x^2)=8y+1\\
    Y_x=\frac{\partial}{\partial x}(8xy+x)=8y+1
\end{gather*}
La condizione di chiusura è verificata, quindi si può proseguire alla risoluzione. Dato che $\Phi_x=X$ e $\Phi_y=Y$, si possono integrare le funzioni $X$ e $Y$ rispetto ad $x$ ed a $y$ per ottenere la funzione di partenza $\Phi$:
\begin{gather*}
    \Phi=\int X\df x=\int(4y^2+y-4x)\df x=4xy^2+xy-\frac{4}{3}x^3+h(y)
\end{gather*}
La costante è una funzione in termini di $y$, poiché nella derivata parziale di $\Phi$ rispetto ad $x$, tutti i termini che non contengono la variabile $x$ sono costanti rispetto ad $x$. Per determinare il valore di queste costanti $h(y)$ effettuare la derivata parziale della primitiva ottenuta rispetto ad $y$ e confrontarla con la funzione $Y$:
\begin{gather*}
    \Phi_y=\frac{\partial}{\partial y}\left(4xy^2+xy-\frac{4}{3}x^3\right)=\cancel{8xy}+\cancel{x}+h'(y)=\bcancel{8xy}+\bcancel{x}=Y\\
    h'(y)=0\implies h(y)=c\\
    4xy^2+xy-\frac{4}{3}x^3=c
\end{gather*}



Considerare la seguente equazione esatta:
\begin{gather*}
    2x\cos y\df x-x^2\sin y\df y=0
\end{gather*}
Si verifica la condizione di chiusura:
\begin{gather*}
    X_y=-2x\sin y=Y_x
\end{gather*}
Si considera $\Phi_x=X$ e si integra rispetto $X$ rispetto ad $x$:
\begin{gather*}
    \Phi_x=2x\cos y\\
    \Phi=\int 2x\cos y\df x=x^2\cos y+h(y)
\end{gather*}
Si deriva rispetto ad $y$ e si confronta con $Y$ per determinare la funzione $h(y)$:
\begin{gather*}
    \frac{\partial}{\partial y}(x^2\cos y+h(y))=-\cancel{x^2\sin y}+h'(y)=-\bcancel{x^2\sin y}=Y\\
    h'(y)=0\implies h(y)=c\\
    x^2\cos y=c
\end{gather*}


Considerare la seguente equazione esatta:
\begin{gather*}
    (3x+2y)\df x+x\df y=0
\end{gather*}
Le due derivate parziali sono diverse:
\begin{gather*}
    X_y=2x\neq1=Y_x
\end{gather*}
Si può trasformare in un'altra equazione differenziale, equivalente moltiplicando entrambi i membri per $x$. Questa equazione intuitivamente ha le stesse soluzioni della prima equazione, ma in questo caso la condizione di chiusura è verificata:
\begin{gather*}
    (3x^2+2xy)\df x+x^2\df y=0\\
    X_y=2x=Y_x
\end{gather*}
Si risolve questa nuova equazione che risulta esatta:
\begin{gather*}
    \Phi(x,y)=\int (3x^2+2xy)\df x=x^3+x^2y+h(y)\\
    \Phi_y=\cancel{x^2}+h'(y)=\bcancel{x^2}=Y\\
    h'(y)=0\implies h(y)=c\\
    \Phi(x,y)=x^3+x^2y=c
\end{gather*}

\subsubsection{Fattore Integrante}

Il problema nella risoluzione di equazioni esatte, è la ricerca del fattore integrante $\mu$ che moltiplicato ad entrambi i membri rende l'equazione esatta. Nella precedenza equazione questo fattore era $x$, questo può dipendere da entrambe le variabili indipendenti, ma generalmente conviene scegliere un fattore integrante che dipende o solo dalla $x$ o solo dalla $y$. 

Data un'equazione:
\begin{gather*}
    X(x,y)\df x+Y(x,y)\df y=0
\end{gather*}
Si considera un fattore integrante $\mu(x)$ e si moltiplicano ambo i membri:
\begin{gather*}
    \mu(x)X(x,y)\df x+\mu(x)Y(x,y)\df y=0
\end{gather*}
Si verifica la condizione di chiusura:
\begin{gather*}
    \frac{\partial}{\partial y}\left(\mu(x)X(x,y)\right)=\mu(x)X_y\\
    \frac{\partial}{\partial x}\left(\mu(x)Y(x,y)\right)=\mu'(x)Y+\mu(x)Y_x\\
    \mu(x)X_y=\mu'(x)Y+\mu(x)Y_x  
\end{gather*}
Si dividono entrambi i membri per $\mu(x)$:
\begin{gather*}
    \frac{\mu'}{\mu}Y+Y_x=X_y    
\end{gather*}
Questa è un'equazione differenziale a variabili separabili in termini di $\mu$:
\begin{gather*}
    Y\frac{\mu'}{\mu}=X_y-Y_x\\
    \frac{\df \mu}{\df x}\frac{1}{\mu}=\frac{X_y-Y_x}{Y}\\
    \frac{\df\mu}{\mu}=\frac{X_y-Y_x}{Y}\df x
\end{gather*}
Si ha che $X_y-Y_x$ non rispetta la condizione di chiusura, e quindi è diverso da zero. Bisogna determinare la funzione $K$ e bisogna verificare che si tratta di una funzione nella sola $x$:
\begin{gather*}
    \frac{X_y-Y_x}{Y}=K(x)
\end{gather*}
Allora il fattore integrante $\mu$ è dato da:
\begin{gather*}
    \int\frac{\df\mu}{\mu}=\int K(x)\df x\\
    \ln\mu=\int K(x)\df x\\
    \mu(x)=e^{\int K(x)\df x}
\end{gather*}
Analogamente se $\mu$ dipende interamente dalla $y$, si ha:
\begin{gather*}
    \mu(y)X(x,y)\df x+\mu(y)Y(x,y)\df y=0    
\end{gather*}
Le derivate parziali sono quindi:
\begin{gather*}
    \mu'X+\mu X_y=\mu Y_x
\end{gather*}
Si ottiene la seguente equazione a variabili separabili:
\begin{gather*}
    \frac{\df\mu}{\mu}=\frac{X_y-Y_x}{-X}\df y
\end{gather*}
Si considera $-X$ al denominatore per mantenere il numeratore equivalente al precedente caso con $\mu(x)$, si verifica ora che il secondo membro sia un'equazione interamente in $y$, $K(y)$:
\begin{gather*}
    \frac{Y_x-X_y}{X}=K(y)
\end{gather*}
Allora si risolve l'equazione a variabili separabili:
\begin{gather*}
    \mu(y)=e^{\int K(y)\df y}
\end{gather*}


Si considera la seguente equazione:
\begin{gather*}
    y\df x+(y-x)\df y=0\\
    X_y=1\neq-1=Y_x
\end{gather*}
Si determina il fattore integrante rispetto ad $y$:
\begin{gather*}
    \mu(y)=e^{\int K(y)\df y}=e^{\int\frac{2}{-y}\df y}=e^{-2\ln y}=\frac{1}{y^2}
\end{gather*}
Quindi moltiplicando l'equazione di partenza per il fattore integrante $\mu$ si ha:
\begin{gather*}
    \frac{1}{y}\df x+\frac{y-x}{y^2}\df y=0
\end{gather*}
La condizione di chiusura è verificata poiché si è moltiplicati per il fattore integrante. A questo punto si determina $\Phi$, integrando $X$ rispetto alla $x$:
\begin{gather*}
    \Phi(x,y)=\int\frac{1}{y}\df x=\frac{x}{y}+h(y)
\end{gather*}
Si determina il valore della funzione $h(y)$:
\begin{gather*}
    Y=\frac{y-x}{y^2}=\frac{1}{y}-\cancel{\frac{x}{y^2}}=-\bcancel{\frac{x}{y^2}}+h'(y)=\Phi_y
\end{gather*}
La funzione $h'(y)$ non è nulla quindi si ha:
\begin{gather*}
    h'(y)=\frac{1}{y}\implies h(y)=\ln y
\end{gather*}
La soluzione è quindi:
\begin{gather*}
    \Phi(x,y)=\frac{x}{y}+\ln y=c
\end{gather*}


\subsection{Esistenza ed Unicità di una Soluzione}

% Le equazioni differenziali del primo ordine trattate,
Data un'equazione differenziale in forma normale, supponendo siano stat assegnate 
\begin{gather*}
    y'=f(x,y)\\
    y_0=y(x_0)
\end{gather*}

Il teorema di Picard afferma che se la funzione $f$ è continua e se la derivata parziale rispetto ad $y$ è anch'essa una funzione continua in un rettangolo $x,y$, allora l'equazione differenziale assegnata ha sempre una ed una sola soluzione. 
Ed esiste un numero reale $h$, tale che nell'intorno di $x_0$: $|x-x_0|<h$, ammette una ed una sola funzione. 

\subsection{Equazioni Differenziali del Secondo Ordine}

Un'equazione differenziale del secondo ordine è un'equazione che presente un termine $y$ derivato secondo. Molte equazioni di secondo grado non hanno una soluzione calcolabile in modo esplicito, ma sono presenti molte equazioni particolari di cui si può calcolare la soluzione. 
Considerando un'equazione:
\begin{gather*}
    y''-xy=0
\end{gather*}
Questo tipo di equazioni si chiama equazioni di Airy. Si tratteranno solamente equazioni lineari del secondo ordine:
\begin{gather*}
    y''+P(x)y'+Q(x)y=R(x)
\end{gather*}
Il teorema dell'esistenza ed unicità delle soluzioni afferma che se queste funzioni $P(x),\,Q(x),\,R(x)$ sono continue su un'intervallo $[a,b]$ allora la soluzione esiste ed è unica, dati i vincoli $y_0=y(x_0)$ e $y_0'=y'(x_0)$. 


Si considera un caso particolare:
\begin{gather*}
    y''=f(x)
\end{gather*}
La sua soluzione è immediata, è sufficiente integrare ambo le parti:
\begin{gather*}
    y'=\displaystyle\int f(t)\df t+c_1\\
    y=\displaystyle\int\left(\int f(t)\df t+c_1\right) \df v+c_2
\end{gather*}



%% SKIP

Si considerano prima equazioni di secondo grado lineari con il termine noto nullo:
\begin{gather*}
    y''+a(x)y'+b(x)y=0
\end{gather*}
Si considera l'operatore differenziale $L[y]=0$. Questo problema di integrazione si risolve in modo semplice quando i coefficienti sono delle costanti:
\begin{gather*}
    y''+ay'+by=0
\end{gather*}
Per individuare una soluzione si considerano funzioni del tipo $e^{\lambda t}$:
\begin{gather*}
    y=e^{\lambda t}\\
    y'=\lambda e^{\lambda t}\\
    y''=\lambda^2e^{\lambda t}
\end{gather*}
Sostituendo nell'equazione di partenza si ottiene:
\begin{gather*}
    \lambda^2e^{\lambda t}+a\lambda e^{\lambda t}+be^{\lambda t}=0\\
    e^{\lambda t}\left[\lambda^2+a\lambda+b\right]=0
\end{gather*}

L'esponenziale non può essere mai nullo, quindi solo se il polinomio in termini di $\lambda$ è nullo esiste una soluzione, con $\lambda$:
\begin{gather*}
    \lambda=\displaystyle\frac{-a\pm\sqrt{a^2-4b}}{2}
\end{gather*}
Quest'equazione da risolvere si chiama equazione caratteristica, e la soluzione dipende dal discriminante $\Delta$:
%% TODO vari casi per Delta >=< 0
% \begin{gather*}
%   \Delta:\begin{cases}
%     >0\\
%     =0\\
%     <0
% \end{cases}    
% \end{gather*}

Si considera un'equazione lineare omogenea:
\begin{gather*}
    y''+y=0\to\,y''=-y\\
    y(0)=3\\
    y'(0)=0
\end{gather*}
Una possibile soluzione è una funzione sinusoidale:
\begin{gather*}
    y=k\cos x\\
    y'=-k\sin x\\
    y''=-k\cos x
\end{gather*}
Per individuare la soluzione bisogna utilizzare le condizioni al contorno fornite:
\begin{gather*}
    y(0)=k\cos(0)=k=3\\
    y'(0)=3\sin(0)=0
\end{gather*}
La soluzione individuata $y=3\cos x$ è unica. 


Se i coefficienti dell'equazione differenziale ordinaria di secondo ordine non sono costanti si ha:
\begin{gather*}
    y''+P(x)y'+Q(x)y=0
\end{gather*}
Si utilizza allora l'operatore differenziale:
\begin{gather*}
    L[y]=y''+P(x)y'+Q(x)y
\end{gather*}
Questo operatore è lineare, quindi siano $y_1$ e $y_2$ soluzioni dell'equazione non omogenea, allora una loro combinazione lineare è anch'essa una soluzione:
\begin{gather*}
    L[c_1y_2+c_2y_2]=c_1y_1''+c_1P(x)y_1'+c_1Q(x)y_1+c_2y_2''+c_2P(x)y_2'+c_2Q(x)y_2=c_1L[y_1]+c_2L[y_2]
\end{gather*}

Considerando ora l'equazione non omogenea, data $\bar{y}$ la soluzione dell'equazione non omogenea, e $y_1$ una soluzione dell'equazione omogenea, allora l'operatore applicato alla loro combinazione lineare diventa:
\begin{gather*}
    L[y_1+\bar{y}]=L[y_1]+L[\bar{y}]
\end{gather*}
Il primo addendo è nullo poiché è soluzione dell'equazione omogenea quindi si ha:
\begin{gather*}
    L[y_1+\bar{y}]=\cancelto{0}{L[y_1]}+L[\bar{y}]=R(x)
\end{gather*}
Quindi la combinazione lineare tra una soluzione dell'equazione omogenea e di quella non omogenea, è una soluzione per l'equazione non omogenea.
Mentre date due soluzioni per l'equazione non omogenea $\bar{y}_1$ e $\bar{y}_2$, l'operatore differenziale applicato alla loro differenza sarà nullo:
\begin{gather*}
    L[\bar{y}_1-\bar{y_2}]=L[\bar{y}_1]-L[\bar{y}_2]=R(x)-R(x)=0
\end{gather*}
La differenza di due soluzioni dell'equazione non otogena è una soluzione all'equazione omogenea. Quindi fissando una delle due soluzioni si può attuare lo stesso procedimento per le equazioni lineari di primo ordine, dove 
la soluzione generale per un'equazione di primo ordine è data dall'integrale particolare per l'omogenea più una soluzione generale per la non omogenea. %% TODO fix per secondo ordine scrivere soluzione tipo y+\bar{y}
\begin{gather*}
    L[y+\bar{y}]
\end{gather*}


Esempio a caso:
\begin{gather*}
    y''+2y'+y=0
\end{gather*}
Si considera la sua equazione caratteristica:
\begin{gather*}
    e^{\lambda t}(\lambda^2+2\lambda+1)=0
\end{gather*}
Il determinante è nullo $\Delta=0$, quindi si ha $\lambda=-1$, quindi le due soluzioni dell'equazione sono:
\begin{gather*}
    y_1=e^{-x}\\
    y_2=xe^{-x}
\end{gather*}
La soluzione generale di quest'equazione è quindi del tipo:
\begin{gather*}
    y=c_1e^{-x}+c_2xe^{-x}
\end{gather*}

%% ??
%% TODO fix wording and shi
Date due equazioni $y_1(x)$ e $y_2(x)$, se esse sono linearmente indipendenti se non esistono costanti $c_i\neq0$ tali che $c_1y_1(x)+c_2y_2(x)$. Se invece esistono queste costanti, sempre diverse da zero, le funzioni si dicono linearmente dipendenti. 


Date $y_1(x)$ e $y_2(x)$ soluzioni linearmente indipendenti, di un'equazione lineare di secondo ordine omogenea $y''+P(x)y'+Q(x)y=0$, allora ogni soluzione combinazione lineare di queste due soluzioni allora: $y=c_1y_1+c_2y_2$. 
Date le condizioni al contorno $y_0$ e $y_0'$, si possono individuare le costanti $c_1$ e $c_2$:
\begin{gather*}
    c_1y_1(x_0)+c_2y_2(x_0)=y_0\\
    c_1y_1'(x_0)+c_2y_2'(x_0)=y_0'
\end{gather*}
Queste costanti esistono quando il determinante dei coefficienti è diverso da zero:
\begin{gather*}
    \begin{pmatrix}
        y_1(x_0) & y_2(x_0)\\
        y_1'(x_0) & y_2'(x_0)
    \end{pmatrix}\neq0
\end{gather*}
Questo si chiama il Wronskiano relativo a $y_1$ e $y_2$. 
Si vuole trovare due soluzioni linearmente indipendenti, quindi considerando il Wronskiano se è nullo allora le soluzioni non solo linearmente indipendenti e quindi non può essere utilizzato per individuare la soluzione. 

\clearpage

\section{Trasformata di Laplace}

La trasformata di Laplace essenzialmente è un'integrale improprio di seconda specie. 
%% TODO ??

% funzione discontinua a tratti e etc

La discontinuità in questi punti deve essere di prima o terza specie%% TODO ??

Se una funzione rinuncia alla limitatezza della funzione, allora è discontinua in un numero finito di punti, dove può presentare discontinuità di seconda specie, questa è una funzione a tratti. 


La trasformata di Laplace è una funzione di questo tipo. Data una funzione $f(t)$ definita per $t\geq0$, allora la funzione di Laplace $\mathscr{L}$ di questa funzione è definita come:
\begin{gather*}
    F(s)=\mathscr{L}[f(t)]=\intpinf{f(t)e^{-st}}{t}
\end{gather*}
Quest'integrale deve essere finito per certi valori $s>a$. La trasformata di Laplace è una funzione in $s$ $F(s)$, più propriamente la trasformata è un limite:
\begin{gather*}
    \mathscr{L}[f(t)]=\lim_{w\to\infty}\int_0^\omega f(t)e^{-st}\df t
\end{gather*}

\subsection{Trasformate di Funzioni Elementari}

Si determina la trasformata di una costante $f(t)=k$, utilizzando la funzione come limite:
\begin{gather*}
    \mathscr{L}[f(t)]=\lim_{w\to\infty}\int_0^\omega ke^{-st}\df t
\end{gather*}
Quest'integrale è immediato:
\begin{gather*}
    F(s)=\lim_{\omega\to\infty}\left\{-\frac{1}{s}ke^{-st}\bigg|_0^\omega\right\}
\end{gather*}
Si possono invertire i limite di integrazione:
\begin{gather*}
    F(s)=\lim_{\omega\to\infty}\left\{\frac{1}{s}ke^{-st}\bigg|_\omega^0\right\}=
    \frac{k}{s}-\cancelto{0}{\lim_{\omega\to\infty}\frac{k}{s}e^{-s\omega}}
\end{gather*}
La trasformata di una costante è quindi:
\begin{gather*}
    \mathscr{L}[k]=\frac{k}{s}
\end{gather*}


Si considera la trasformata di una funzione lineare:
\begin{gather*}
    \mathscr{L}[t]=\lim_{\omega\to\infty}\int_0^\omega te^{-st}\df t
\end{gather*}
Si integra per parti:
\begin{gather*}
    \mathscr{L}[t]=\lim_{\omega\to\infty}-\frac{1}{s}\left\{te^{-st}+\frac{1}{s}e^{-st}\bigg|_0^\omega\right\}=
    \lim_{\omega\to\infty}\left\{\cancelto{0}{-\frac{\omega}{s} e^{-s\omega}}+\cancelto{0}{-\frac{1}{s^2}e^{-s\omega}}+\frac{1}{s^2}\right\}=\frac{1}{s^2}
\end{gather*}


In generale una funzione del tipo $f(t)=t^n$ ha una trasformata di Laplace:
\begin{gather*}
    \mathscr{L}\left[t^n\right]=\frac{n!}{s^{n+1}}
\end{gather*}
Si dimostra per induzione, per $n=0$ si ha:
\begin{gather*}
    \mathscr{L}[1]=\frac{1}{s}
\end{gather*}
Questo si è già calcolato precedentemente. 
Si suppone che sia vero per $n=k$, quindi si ha:
\begin{gather*}
    \mathscr{L}\left[t^{k}\right]=\frac{k!}{s^{k+1}}
\end{gather*}
Si determina allora per $n=k+1$:
\begin{gather*}
    \mathscr{L}\left[t^{k+1}\right]=\int_0^{+\infty} t^{k+1}e^{-st}\df t
\end{gather*}
Integrando per parti si ha:
\begin{gather*}
    \mathscr{L}\left[t^{k+1}\right]=\overbrace{\left[-\frac{t^{k+1}e^{-st}}{s}\right]_0^{+\infty}}^0+\frac{k+1}{s}\int_0^{+\infty}t^ke^{-st}\df t=\frac{k+1}{s}\mathscr{L}\left[t^k\right]=\frac{k+1}{s}\frac{k!}{s^{k+1}}=\frac{(k+1)!}{s^{k+2}}
\end{gather*}


Si determina la trasformata di Laplace del seno:
\begin{gather*}
    \mathscr{L}\left[\sin(at)\right]=\int_0^{+\infty}\sin(at)e^{-st}\df t
\end{gather*}
Integrando per parti si ha:
\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline
        &D&I\\\hline
        +&$e^{-st}$&$\sin(at)$\\\hline
        -&$-se^{-st}$&$-\cos(at)/a$\\\hline
        +&$s^2e^{-st}$&$-\sin(at)/a^2$\\\hline
    \end{tabular}
\end{center}
\begin{gather*}
    \mathscr{L}[\sin at]=-e^{-st}\frac{\cos(at)}{a}-se^{-st}\frac{\sin(at)}{a^2}-\frac{s^2}{a^2}\int_0^{+\infty}e^{-st}\sin(at)\df t\\
    \left(1+\frac{s^2}{a^2}\right)\mathscr{L}[\sin(at)]=\left[-e^{-st}\frac{\cos(at)}{a}-se^{-st}\frac{\sin(at)}{a^2}\right]_0^{+\infty}=\frac{1}{a}\\
    \mathscr{L}[\sin(at)]=\frac{1}{a}\frac{a^2}{a^2+s^2}=\frac{a}{a^2+s^2}
\end{gather*}


Si determina la trasformata dell'esponenziale:
\begin{gather*}
    \mathscr{L}\left[e^{bt}\right]=\intpinf{e^{-st}e^{bt}}{t}=\intpinf{e^{-(s-b)t}}{t}=-\frac{1}{s-b}e^{-(s-b)}\bigg|_0^{+\infty}=\frac{1}{s-b}
\end{gather*}
Questa si può interpretare anche come il prodotto di una costante per questo esponenziale:
\begin{gather*}
    \mathscr{L}\left[e^{bt}\cdot 1\right]=\frac{1}{s-b}
\end{gather*}
Considerando ora invece della costante, una funzione generica $f(t)$:
\begin{gather*}
    \mathscr{L}\left[e^{bt}\cdot f(t)\right]=\intpinf{f(t)e^{-(s-b)t}}{t}=F(s-b)
\end{gather*}
Dato che la trasformata di Laplace della funzione $f(t)$ è:
\begin{gather*}
    \mathscr{L}[f(t)]=\intpinf{f(t)e^{-st}}{t}=F(s)
\end{gather*}
Quindi effettuando la trasformata di una funzione, moltiplicata per un esponenziale $e^{-bt}$, la funzione risultante è la trasformata della funzione traslata dal fattore costante all'esponente dell'esponenziale, nel dominio $s$. 

\subsection{Trasformata della Derivata e dell'Integrale}

Si vuole calcolare la trasformata della derivata di una funzione generica $f(t)$, sapendo il valore $f(0)$:
\begin{gather*}
    \mathscr{L}[f'(t)]=\intpinf{\frac{\df f(t)}{\df t}e^{-st}}{t}
\end{gather*}
Applicando l'integrazione per parti si ottiene:
\begin{gather*}
    \intpinf{\frac{\df f(t)}{\df t}e^{-st}}{t}=e^{-st}f(t)\bigg|_0^{+\infty}+s\intpinf{f(t)e^{-st}}{t}=-f(0)+sF(s)
\end{gather*}


Analogamente si determina la trasformata dell'integrale di una funzione generica $f(t)$:
\begin{gather*}
    \mathscr{L}\left[\int_0^t f(\varphi)\df \varphi\right]=\intpinf{e^{-st}\int_0^t f(\varphi)\df\varphi}{t}
\end{gather*}
Si considera questa funzione integrale $g(t)$, e la trasformata della sua derivata:
\begin{gather*}
    g(t)=\int_0^t f(\varphi)\df\varphi\\
    g'(t)=f(t)\\
    \mathscr{L}[g'(t)]=sG(s)-\cancelto{0}{g(0)}=F(s)=\mathscr{L}[f(t)]\\
    \mathscr{L}\left[\int_0^tf(\varphi)\df\varphi\right]=G(s)=\frac{F(s)}{s}
\end{gather*}

\subsection{Derivate nel Dominio di Laplace}

Si considera il seguente problema di Cauchy:
\begin{gather*}
    \begin{cases}
        y'-y=0\\
        y(0)=1
    \end{cases}
\end{gather*}
La trasformata è un'operazione lineare, essendo l'integrale un operatore lineare, quindi è possibile scomporre la trasformata di una equazione differenziale come la combinazione lineare di trasformate:
\begin{gather*}
    \mathscr{L}[y'-y]=\mathscr{L}[0]\\
    \mathscr{L}[y']-\mathscr{L}[y]=0\\
    sY(s)-\cancelto{1}{y(0)}-Y(s)=0\\
    Y(s)(s-1)=1\implies Y(s)=\frac{1}{s-1}
\end{gather*}
Considerando che $\mathscr{L}[1]=1/s$ e considerando la proprietà della traslazione nel piano di Laplace:
\begin{gather*}
    \frac{1}{s-1}=G(s-1)\\
    G(s)=\frac{1}{s}=\implies g(t)=1\\
    Y(s)=G(s-1)=\mathscr{L}[g(t)e^{bt}]=\mathscr{L}[e^t]\\
    y(t)=e^{t}
\end{gather*}


Considerare ora il seguente problema di Cauchy:
\begin{gather*}
    \begin{cases}
        y'+2y=e^t\\
        y(0)=1
    \end{cases}
\end{gather*}
Procedendo analogamente all'esercizio precedente si ottiene:
\begin{gather*}
    y'+2y=e^t\to sY(s)-\cancelto{1}{y(0)}+2Y(s)=\frac{1}{s-1}\\
    Y(s)(s+2)=\frac{s-\cancel{1}+\bcancel{1}}{s-1}\\
    Y(s)=\frac{s}{(s-1)(s+2)}
\end{gather*}
Tra le funzioni e le rispettive trasformate è presente una corrispondenza biunivoca, come per la trasformata esiste una trasformata inversa che le riporta in $t$. Il problema per risolvere le equazioni differenziali diventa la ricerca dell'antitrasformata corrispondente di $Y(s)$. Poiché la trasformata è un'operazione lineare, se si scompone in fratti semplici e si cercano le funzioni che trasformate le generano, la loro combinazione lineare sarà la funzione la cui trasformata corrisponde alla soluzione $y(t)$:
\begin{gather*}
    \frac{s}{(s-1)(s-2)}=\frac{A}{s-1}+\frac{B}{s-2}\\
    A(s+2)+B(s-1)=s\\
    \begin{cases}
        A+B=s\\
        2A-B=0
    \end{cases}\implies\begin{cases}
        A=\frac{1}{3}\\
        B=\frac{2}{3}
    \end{cases}\\
    Y(s)=\frac{1}{3}\frac{1}{s-1}+\frac{2}{3}\frac{1}{s+2}\\
    \mathscr{L}^{-1}[Y(s)]=\frac{1}{3}e^{t}+\frac{2}{3}e^{-2t}=y(t)
\end{gather*}

\subsection*{Esercizi 15/5/25}

Risolvere la seguente trasformata di Laplace:
\begin{gather*}
    \mathscr{L}[2e^{3t}\sin(4t)]=\frac{2\cdot4}{(s-3)^2+16}
\end{gather*}


Risolvere le seguenti trasformate:
\begin{gather*}
    \mathscr{L}[(t+4)^2e^{-5t}]=\frac{e^{-4s}}{(s+5)^2}\\
    \mathscr{L}\left[3\sin\left(t+\frac{\pi}{6}\right)e^{-t}\right]=\frac{3e^{\pi/6}}{1+(s+1)^2}\\
    \mathscr{L}\left[2\sin(3t)+4e^{2t}\cos t\right]=\frac{6}{9+s^2}+\frac{4}{1+(s-2)^2}
\end{gather*}


Calcolare la seguente trasformata di Laplace:
\begin{gather*}
    \mathscr{L}[\cos^2(\alpha t)]
\end{gather*}
Si considera la derivata della funzione:
\begin{gather*}
    f(t)=\cos^2\alpha t\\
    f'(t)=-2\alpha\cos(\alpha t)\sin(\alpha t)=-\alpha\sin(2\alpha t)\\
    f(0)=1\\
    \mathscr{L}[f'(t)]=s\mathscr{L}[f(t)]-1\\
    \mathscr{L}[-\alpha\sin(2\alpha t)]=s\mathscr{L}[\cos^2\alpha t]-1\\
    \frac{-2\alpha^2}{4\alpha^2+s^2}=s\mathscr{L}[\cos^2\alpha t]-1\\
    \mathscr{L}[\cos^2\alpha t]=\left(1-\frac{-2\alpha^2}{4\alpha^2+s^2}\right)\frac{1}{s}
\end{gather*}

\subsection{?}

Data una funzione generica $f(t)$ e la sua trasformata $F(s)$, con $s>a$, si considera la trasformata di $f(bt)$:
\begin{gather*}
    \mathscr{L}[f(bt)]=\frac{1}{b}F\left(\frac{s}{b}\right)
\end{gather*}
Con $s/b>a$, allora si effettua un cambio di variabile, con $u=t/b$:
\begin{gather*}
    \frac{1}{b}F\left(\frac{s}{b}\right)=\frac{1}{b}\intpinf{e^{-s/bt}f(t)}{t}\\
    \frac{1}{\cancel{b}}\intpinf{e^{-su}f(ub)\bcancel{b}}{u}=\intpinf{e^{-su}f(ub)}{u}=\mathscr{L}[f(ub)]
\end{gather*}
Per cui si è verificata la proprietà. 


\subsection{??}

Si considera un numero $M$ positivo, ed una funzione $f$ continua a tratti, per $t>a$, presenta un numero finito di punti di discontinuità di prima o terza specie. Inoltre si ha $|f(t)|\leq g(t)$, per $t>M$, allora anche l'integrale improprio della funzione da $M$ ad $+\infty$ converge:
\begin{gather*}
    \int_M^{+\infty}g(t)\df t:\mbox{ converge}
\end{gather*}

Se $f(t)\geq g(t)\geq0$ per $t\geq M$, se l'integrale di $g(t)$ converge, allora anche $f(t)$ converge. 


Una funzione $f(t)$ si dice di ordine esponenziale $e^{\alpha t}$ per $\alpha>0$, se esistono due costanti $\exists\,N,k>0$ tali che il modulo $f(t)\leq Ne^{\alpha t}$, per $t\geq k$. 
Se una funzione è di ordine esponenziale, allora la funzione ammette trasformata. 

\subsection{Traslazione sull'asse Temporale}

Data una funzione $f(t)$ e la sua trasformata $F(s)$, si considera una traslazione nell'asse $t$ di una quantità $\tau>0$:
\begin{gather*}
    \mathscr{L}[f(t-\tau)]=\intpinf{f(t-\tau)e^{-st}}{t}
\end{gather*}
Applicando una sostituzione $u=t-\tau$ si ottiene:
\begin{gather*}
    \int_{-\tau}^{+\infty}{ f(u)e^{-(u+\tau)s}}{\df u}=e^{-s\tau}\intpinf{f(u)e^{-su}}{u}+e^{-s\tau}\int_{-\tau}^0f(u)e^{-su}\df u\\
    \mathscr{L}[f(t-\tau)]=e^{-s\tau}F(s)+e^{-s\tau}\int_{-\tau}^0f(u)e^{-su}\df u
\end{gather*}
Se $f(t)=0$, per $\tau<0$, allora diventa:
\begin{gather*}
    \mathscr{L}[f(t-\tau)]=e^{-s\tau}F(s)
\end{gather*}

\clearpage

\section{Funzioni Multi-Variabili}


Una funzione è definita come $f:D_f\subseteq\mathbb{R}\to C_f\subseteq\mathbb{R}$, si può estendere questa definizione, aumentando la dimensione del dominio:
\begin{gather*}
    f:D_f\subseteq\mathbb{R}^2\to C_f\subseteq\mathbb{R}\\
    P=(x,y)\rightarrow z=f(x,y)
\end{gather*}
Il suo grafico $\mathscr{G}_f$ si può definire come l'insieme dei punti tridimensionali tali che:
\begin{gather*}
    \mathscr{G}_f=\left\{(x,y,z)\in\mathbb{R}^3\big|(x,y)\in D_f,\,z=f(x,y)\right\}
\end{gather*}
Si considera la seguente funzione bidimensionale:
\begin{gather*}
    z=f(x,y)=x^2+y^2
\end{gather*}
Questo paraboloide ha la seguente forma nello spazio tridimensionale: 
%% TODO add img paraboloide da IA-ML
\begin{figure}[H]
    \centering%
    \includegraphics[scale=0.5]{example-image.png}%    
\end{figure}
Tenendo fissa una variabile, e considerando un taglio di questa figura, si ottiene una parabola. 

Aumentando la dimensione del dominio della funzione ulteriormente, impedisce a questa di essere rappresentata:
\begin{gather*}
    f: D_f\subseteq\mathbb{R}^3\to C_f\subseteq\mathbb{R}\\
    P=(x,y,z)\to w=(x,y,z)
\end{gather*}
Aumentando ulteriormente rende ancora più difficile la sua rappresentazione. 


Analogamente è possibile aumentare la dimensione del codominio, in questo modo si crea una funzione vettoriale:
\begin{gather*}
    f:D_f\subseteq\mathbb{R}\to C_f\subseteq\mathbb{R}^2\\
    t\to f(t)=\begin{pmatrix}
        x(t)\\y(t)
    \end{pmatrix}
\end{gather*}
Questa è un'equazione parametrica per rappresentare una curva nel piano. Funzioni vettoriali a due dimensioni, di una variabile reale servono per descrivere pariteticamente una curva nel piano bidimensionale. 

Si può aumentare arbitrariamente l'ordine del codominio, in modo che l'immagine della variabile sia un vettore nello spazio $n$-dimensionale. Le componenti di questo vettore vengono chiamate equazioni parametri di una curva nello spazio. 
% \begin{gather*}
%     f:D_f\subseteq\mathbb{R}\to C_f\subseteq\mathbb{R}^n\\
%     t\to f(t)=\begin{pmatrix}
%         x_1(t)\\\vdots\\x_n(t)
%     \end{pmatrix}
% \end{gather*}
Generalizzando ancora il concetto si può avere un ordine superiore al primo sia per il dominio che pe ril codominio della funzione:.
\begin{gather*}
    f: D_f\subseteq\mathbb{R}^2\to C_f\subseteq\mathbb{R}^3\\
    (u,v)\to f(u,v)=\begin{pmatrix}
        x(u,v)\\y(u,v)\\z(u,v)
    \end{pmatrix}
\end{gather*}
Avendo due variabili indipendenti si definisce un'equazione parametrica per una superficie. Questo tipo di funzioni sono molto usate in fisica per definire spazi campi vettoriali, se le dimensioni di dominio e codominio sono uguali, e altre funzioni per definire campi di forze. 

\subsection{Funzioni Reali a Più variabili Reali}

Dopo aver generalizzato la nozione di funzione, si considerano funzioni reali a più variabili reali: $\mathbb{R}\to\mathbb{R}^n$. 


Si considera la seguente funzione:
\begin{gather*}
    z=f(x,y)=2x^2+2xy-y-5
\end{gather*}
Non sono presenti vincoli sul dominio della funzione, essendo composta solamente da potenze: $D_f\subseteq\mathbb{R}^2$. Altre funzioni invece presentano dei vincoli per definire il loro dominio:
\begin{gather*}
    z=f(x,y)=\sqrt{2x+y-5}
\end{gather*}

Bisogna impostare un vincolo per determinare la scelta appropriata della $x$ e della $y$, il dominio deve considerare nel piano euclideo tutti i numeri reali che soddisfano la condizione:
\begin{gather*}
    2x+y-5\geq0
\end{gather*}
Dal punto di vista teorico non sono presenti problemi, i problemi sono dal punto di vista pratico, bisogna risolvere una disequazione di più incognite. 
Si parte dall'equazione per poi risolvere la disequazione, si considera quindi la retta:
\begin{gather*}
    2x+y-5=0\\
    y=-2x+5
\end{gather*}
Tutti i punti che soddisfano quest'equazione sono punti accettabili. 
%% TODO add img retta 
Dopo aver rappresentato questa retta, si divide il piano in una porzione sopra e sotto alla retta, bisogna determinare la porzione che soddisfa la disequazione $y>-2x+5$, quindi bisogna scegliere tutti i punti superiori alla retta. Il dominio della funzione è individuato dal semipiano superiore alla retta, compresa:
\begin{gather*}
    D_f=\left\{(x,y)\in\mathbb{R}^2\big| 2x+y-5\geq0\right\}
\end{gather*}

%% TODO ex analogo
Data la funzione:
\begin{gather*}
    z=f(x,y)=\displaystyle\frac{2x+y}{x^2+y^2}
\end{gather*}
Questa funzione presente una singolarità, nel punto dove si annulla il denominatore, ovvero dove $x^2+y^2=0$, quindi nell'origine: $D_f=\mathbb{R}^2\setminus\{(0,0)\}$



Considerare la seguente funzione:
\begin{gather*}
    z=f(x,y)=\displaystyle\frac{\sqrt[4]{x^2+y^2-2x-4y-11}}{\ln(2x+y)}
\end{gather*}
Per definire il suo dominio, bisogna utilizzare tre vincoli, uno per la radice, uno per il denominatore, ed uno per il logaritmo:
\begin{gather*}
    \begin{cases}
        x^2+y^2-2x-4y-11\geq0\\
        \ln(2x+y)\neq0\\
        2x+y>0
    \end{cases}
\end{gather*}
Partendo dall'ultima disequazione si considera la retta $2x+y=0\to y=-2x$, poiché è una relazione stretta, i punti che appartengono a questa equazione vanno scartati. 
% x   | y
% -------
% 0   | 0
% 1/2 | 1
%% TODO add img retta e piano 
Essendo $y>-2x$ si considerano tutti i punti sopra a questa retta. Passando alla seconda disequazione, affinché il logaritmo non sia nullo bisogna imporre:
\begin{gather*}
    2x+y\neq1\\
    y\neq-2x+1
\end{gather*}
Rappresentando questa retta, bisogna escludere solamente i punti di questa retta $y=-2x+1$. 
%% TODO add img retta sovrapposta al semipiano precedente
La prima disequazione rappresenta un'equazione di un cerchio, centrato in punto da determinare:
\begin{gather*}
    x^2+y^2-2x-4y-11\geq0\\
    (x^2-2x+1)+(y^2-4y+4)-16\geq0\\
    (x-1)^2+(y-4)^2\geq4^2
\end{gather*}
Si è ottenuta l'equazione di una circonferenza, di raggio 4 e centro in $(2,4)$:
\begin{gather*}
    (x-1)^2+(y-4)^2=4^2
\end{gather*}
%% TODO add img circonferenza al semipiano precedente
Questo vincolo esclude tutti i punti interni, circonferenza esclusa. Il dominio della funzione è quindi data da:
\begin{gather*}
    D_f=\left\{(x,y)\in\mathbb{R}^2\big|(x-1)^2+(y-4)^2\geq4^2\land y\neq-2x+1\land y>-2x\right\}
\end{gather*}

\subsubsection{Limite Multi-Variabile}

Considerare la seguente funzione:
\begin{gather*}
    z=f(x,y)=\displaystyle\frac{\arcsin(2x+y)}{\sqrt{5-2x-3y}}
\end{gather*}
Per determinare il dominio della funzione, bisogna analizzare il comportamento della funzione in punti di accumulazione ed analizzare il loro comportamento, generalizzando il concetto di limite. La distanza euclidea in due dimensioni, dati due punti $P=(x_p,y_p)$ e $Q=(x_q,y_q)$, è data da:
\begin{gather*}
    \df(PA)=\sqrt{(x_p-x_q)^2+(y_p-y_q)^2}
\end{gather*}
Si deve definire l'intorno di un punto in due dimensioni $P_0(x_0,y_0)$, di raggio $\delta>0$:
\begin{equation}
    I_\delta(P_0)=\left\{P\in\mathbb{R}^2\big| \df (P_0P)<\delta\right\}
\end{equation}
%% TODO add img intorno aperto, senza circonferenza
Dato l'intorno sferico di un punto, bisogna definire il punto di accumulazione, e studiare il comportamento della funzione in questo punto. 
$P_0\in\mathbb{R}^2$ è punto di accumulazione di $D_f$ se $\forall\delta>0$ si ha che l'intorno sferico di raggio $\delta$ bucato $I_\delta(P_0)\setminus\{P_0\}$ deve contenere almeno un punto del dominio:
\begin{equation}
    \left(I_\delta(P_0)\setminus\{P_0\}\right)\cap D_f\neq0
\end{equation}
Ci si può avvicinare arbitrariamente al punto $P_0$, senza mai lasciare il dominio $D_f$. 

Si suppone di avere una funzione $f$ definita su un piano euclideo ed ha valori reali:
\begin{gather*}
    f: D_f\subseteq\mathbb{R}^2\to C_f\subseteq\mathbb{R}
    (x,y)\to x=f(x,y)% funzione analitica
\end{gather*}
Si considera un punto di accumulazione $P_0\in\mathbb{R}^2$ del dominio $D_f$. 

Il limite della funzione, avvicinandosi al punto $P_0$ può essere:
\begin{gather*}
    \lim_{P\to P_0}f(x,y)=\lim_{(x,y)\to (x_0,y_0)}f(x,y)=\begin{cases}
        l\in\mathbb{R}\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{gather*}
Nei primi due casi la funzione è regolare, mentre nel terzo caso la funzione è irregolare. 

Si estende il concetto di continuità, se il limite di $P\to P_0$ di $f$ esiste ed ha un valore $l$, allora se $\forall\varepsilon>0\,\exists\delta_\varepsilon>0$ talle che $\forall P\in D_f$ per cui $\df(P_0P)<\delta_\varepsilon$ allora $|f(x,y)<l+\varepsilon$. 
\begin{equation}
    \forall\varepsilon>0\,\exists\delta_\varepsilon>0\big|\forall P\in D_f\mbox{ per cui }\df(P_0P)<\delta_\varepsilon\implies l-\varepsilon<f(x,y)<l+\varepsilon
\end{equation}
Allora la funzione è continua in $P_0$ se:
\begin{equation}
    \lim_{P\to P_0}f(x,y)=f(x_0,y_0)
\end{equation}
Dal punto di vista applicativo su una sola dimensione è sufficiente controllare due limiti, da destra e da sinatra, poiché sono gli unici due modi in cui si può tendere al punto di accumulazione $x_0$. Ma in più di una dimensione sono presenti infiniti modi di tendere ad un punto di accumulazione $P_0$. 
Il problema è individuare le traiettorie che portano al punto di accumulazione, se esistono due traiettorie per cui il limite non esiste, allora il limite non esiste. 
Si considera il seguente limite:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{xy}{x^2+y^2}
\end{gather*}
Si fissa $x=0$ e si considera di arrivare a $P_0$ per $y\to 0^+$, quindi il punto $P$ di partenza appartiene all'asse $y$:
\begin{gather*}
    \lim_{y\to0}\displaystyle\frac{0}{0+y^2}=0
\end{gather*}
Analogamente se ci si muove sull'asse delle $x$:
\begin{gather*}
    \lim_{x\to0}\displaystyle\frac{0}{x^2+0}=0
\end{gather*}
Si ci si muove sulla bisettrice del primo quadrante, definita da $y=x$, si ha invece:
\begin{gather*}
    \lim_{x=y\to0}\displaystyle\frac{x^2}{2x^2}=\frac{1}{2}
\end{gather*}
Secondo la bisettrice quindi il limite è diverso, ma poiché un limite non può avere valori diversi per traiettorie diverse, è irregolare. Quindi non è possibile estendere la funzione al punto $P_0=(0,0)$. 

Invece considerando il seguente limite:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^3}{x^2+y^2}
\end{gather*}
Se ci si muove sull'asse $x$ o $y$, si ha lo stesso limite pari a zero, così per la bisettrice. L'unico strumento, in questo corso, per calcolare questi limiti è il passaggio alle coordinate polari: $(x,y)\to(\rho,\theta)$:
\begin{gather*}
    \begin{cases}
        x=x_0+\rho\cos\theta\\
        y=y_0+\rho\sin\theta\\
    \end{cases}
\end{gather*}
In questo caso il punto di accumulazione $P_0$ si trova nell'origine, quindi:
\begin{gather*}
    \begin{cases}
        x=\rho\cos\theta\\
        y=\rho\sin\theta\\
    \end{cases}    
\end{gather*}
Applicando questa sostituzione il limite diventa:
\begin{gather*}
    \lim_{\rho\to0}\displaystyle\frac{\rho^3\cos^3\theta}{\rho^2(\cancelto{1}{\cos^2\theta+\sin^2\theta})}=\lim_{\rho\to0}\rho\cos^3\theta
\end{gather*}
Se si può eliminare la presenza del parametro $\theta$, si può ragionare solamente con il parametro $\rho$ e risolvere direttamente questo limite. Si applica quindi il teorema del confronto:
\begin{gather*}
    -\rho\leq\rho\cos^3\theta\leq\rho
\end{gather*}
Studiare questo limite è come studiare il limite degli estremi, e se questi coincidono allora il valore del limite coincide a questo valore, per il teorema del confronto:
\begin{gather*}
    \lim_{\rho\to0}-\rho=\lim_{\rho\to0}\rho=0\\
    \lim_{\rho\to0}\rho\cos^3\theta=0
\end{gather*}
Quindi il limite originale esiste e tende a zero:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^3}{x^2+y^2}=0
\end{gather*}
Tendenzialmente si svincolano le dipendenze a $\theta$ tramite il confronto $|\cos\theta|\leq1$ e $|\sin\theta|\leq1$. 


Si considera il seguente limite:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^3y}{x^2+y^2}\\
    \lim_{\rho\to0}\displaystyle\frac{\rho^3\cos^3\theta\cdot\rho\sin\theta}{\rho^2}\\
    \lim_{\rho\to0}\rho^2\cos^3\theta\sin\theta    
\end{gather*}
Per il teorema del confronto si ha:
\begin{gather*}
    -\rho\leq\rho\cos^3\theta\sin\theta\leq\rho\\
    \lim_{\rho\to0}-\rho=\lim_{\rho\to0}\rho=0\\
    \lim_{\rho\to0}\rho\cos^3\theta\sin\theta=0
\end{gather*}
Il limite quindi è definito ed ha valore:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^3y}{x^2+y^2}=0
\end{gather*}

% recap su vari limiti xy/x^2+y^2: \nexists
%% RECAP

Si considera una funzione il cui limite non esiste nell'origine:
\begin{gather*}
    f(x,y)=\begin{cases}
        \displaystyle\frac{\strut xy}{\strut x^2+y^2}&(x,y)\neq(0,0)\\
        0&(x,y)=(0,0)
    \end{cases}
\end{gather*}
In questo modo è definita nell'origine, ma affinché sia continua anche nell'origine, il valore del limite, deve coincidere al valore della funzione nell'origine:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}f(x,y)\neq f(0,0)=0
\end{gather*}
Dato che il limite non esiste, allora non può essere uguale a zero, e non è continua nell'origine, ma è definita su tutto il dominio $D_f=\mathbb{R}^2$. 

Il passaggio a coordinate polari, con centro in $(x_0,y_0)$ permette di risolvere questi limiti. Dopo aver cambiato le coordinate, si prova svincolare il calcolo dall'angolo $\theta$, in modo da renderlo indipendente dalla traiettoria. 



%% TODO add to esercizi
Determinare se esiste un valore $\alpha\in\mathbb{R}$ tale che la seguente funzione è continua:
\begin{gather*}
    f(x,y)=
    \begin{cases}
        \displaystyle\frac{\strut x^4+y^2e^x}{\strut\sqrt{x^2+y^2}}&(x,y)\neq(0,0)\\
        \alpha&(x,y)=(0,0)    
    \end{cases}
\end{gather*}

Non si riesce ad individuare due traiettorie per cui il limite diverge, quindi si calcola direttamente, effettuando un cambiamento di coordinate:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^4+y^2e^x}{\sqrt{x^2+y^2}}=
    \lim_{\rho\to0}\frac{\rho^4\cos^4\theta+\rho^2\sin^2\theta e^{\rho\cos\theta}}{\rho}=
    \lim_{\rho\to0}\rho^3\cos^4\theta+\rho\sin^2\theta (1+\cos\theta+o[\rho])
\end{gather*}
Si usa una formula di Maclaurin dell'esponenziale per riscrivere l'esponenziale come:
\begin{gather*}
    e^t=1+t+o[t]\mbox{ per }t\to0
\end{gather*}
Il limite diventa:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\rho^3\cos^4\theta+\rho\sin^2+\rho^2\cos^2\theta\sin\theta+o[\rho^2]
\end{gather*}
Tutti i termini in questo limite tendono a zero, quindi il limite tende a zero. 
La funzione originale quindi è continua se $\alpha=0$:
\begin{gather*}
    f(x,y)=
    \begin{cases}
        \displaystyle\frac{\strut x^4+y^2e^x}{\strut\sqrt{x^2+y^2}}&(x,y)\neq(0,0)\\
        0&(x,y)=(0,0)    
    \end{cases}
\end{gather*}


Determinare il valore $\alpha\in\mathbb{R}$ per cui la funzione data risulti continua anche nell'origine:
\begin{gather*}
    f(x,y)=
    \begin{cases}
        \displaystyle\frac{\strut x^2y^2}{\strut3x^2+y^2}&(x,y)\neq(0,0)\\
        \alpha&(x,y)=(0,0)    
    \end{cases}
\end{gather*}
Si effettua un cambio di coordinate nel limite per coordinate polari centrate nell'origine:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{\strut x^2y^2}{\strut3x^2+y^2}=
    \lim_{\rho\to0}\frac{\rho^4\cos^2\theta\sin^2\theta}{\rho^2\left(3\cos^2\theta+\sin^2\right)}=
    \lim_{\rho\to0}\frac{\rho^2\cos^2\theta\sin^2\theta}{2\cos^2\theta+1}
\end{gather*}
Il denominatore è sempre maggiore o uguale a zero, quindi per il teorema del confronto si ha:
\begin{gather*}
    0\leq\frac{\rho^2\cos^2\theta\sin^2\theta}{2\cos^2\theta+1}\leq\rho^2\sin^2\theta\cos^2\theta\leq\rho^2\to0
\end{gather*}
Essendo sia il limite maggiorante che minorante tendente a zero, allora il limite converge a zero, ed il valore $\alpha=0$:
\begin{gather*}
    f(x,y)=
    \begin{cases}
        \displaystyle\frac{\strut x^2y^2}{\strut3x^2+y^2}&(x,y)\neq(0,0)\\
        0&(x,y)=(0,0)    
    \end{cases}
\end{gather*}

\subsection{Derivate Parziali}

Si suppone di avere una funzione $z=f(x,y)$, definita nel dominio $D_f$. Si suppone esista un punto $P_0=(x_0,y_0)\in D_f\cap\mathscr{D}D_f$, punto di accumulazione, derivabile di $f$. %% TODO simbolo per insieme derivabile

%% TODO add img grafico

Si considera un incremento solamente sull'asse $x$, dal punto $P_0$, per quantificare questo incremento si considera la differenza del valore di $z$: $\Delta z$, in seguito a questo incremento, ovvero il rapporto incrementale:
\begin{gather*}
    \displaystyle\frac{f(x_0+h,y)-f(x_0,y_0)}{h}
\end{gather*}
Si considera il limite di questo rapporto incrementale:
\begin{gather*}
    \lim_{h\to0}\displaystyle\frac{f(x_0+h,y)-f(x_0,y_0)}{h}=l\in\mathbb{R}
\end{gather*}
Se questo limite del rapporto incrementale ottenuto aumentando solamente la variabile indipendente $x$, esiste ed è finito, allora la funzione $f$ si dice parzialmente derivabile rispetto ad $x$ nel punto $x_0$. Se esiste ed è finito, si indica come:
\begin{gather*}
    f_x(P_0)=f_x(x_0,y_0)=\displaystyle\frac{\partial f}{\partial x}(x_0,y_0)
\end{gather*}
Questa viene chiamata derivata parziale di $f$ rispetto ad $x$ nel punto $P_0$. 

Analogamente si considera un incremento solamente sulla variabile indipendente $y$ di $k$. A seguito di questo spostamento fino al punto $P(x_0,y_0+k)$ del dominio, anche la funzione subisce un incremento. Si considera ora il rapporto incrementale dovuto a questo incremento:
\begin{gather*}
    \lim_{k\to0}\displaystyle\frac{f(x_0,y_0+k)-f(x_0,y_0)}{k}=l\in\mathbb{R}
\end{gather*}
Se esiste ed è definito il limite del rapporto incrementale, allora la funzione si dice parzialmente derivabile rispetto a $y$ nel punto $y_0$. Si rappresenta analogamente come:
\begin{gather*}
    f_y(P_0)=f_y(x_0,y_0)=\displaystyle\frac{\partial f}{\partial y}(x_0,y_0)
\end{gather*}
% È il concetto di differnziabilità che estende il concetto di derivabilità. 
%% TODO add affinché esiste il piano derivata allora la funzione deve essere differenziabile

Si considera una funzione polinomiale $f$, definita e continua su $D_f\in\mathbb{R}^2$:
\begin{gather*}
    f(x,y)=2x^3+5x^2y+3xy^4-2y^3
\end{gather*}
La funzione è parzialmente derivabile rispetto a $x$ ed $y$ in tutti i punti di $\mathbb{R}^2$. Per calcolare la derivata si utilizza il calcolo dei limiti delle derivate:
\begin{gather*}
    f_x(x,y)=6x^2+10xy+3y^4=\displaystyle\frac{\partial f}{\partial x}\\
    f_y(x,y)=5x^2+12xy^3-6y^2=\displaystyle\frac{\partial f}{\partial y}
\end{gather*}
%% TODO cambiare con de/de
Si possono derivare nuovamente rispetto $x$ ed $y$, formando derivate parziali miste:
\begin{gather*}
    f_{xx}(x,y)=12x+10y=\displaystyle\frac{\partial^2 f}{\partial x^2}\\
    f_{xy}=10x+12y^3=\displaystyle\frac{\partial^2 f}{\partial y\partial x}\\
    f_{yx}=10x+12y^3=\displaystyle\frac{\partial^2 f}{\partial x\partial y}\\
    f_{yy}=36xy^2-12y=\displaystyle\frac{\partial^2f}{\partial y^2}
\end{gather*}
L'ordine delle variabili è rilevante, dato che due derivate parziali miste non sono necessariamente equivalenti $f_{xy}\neq f_{yx}$, ma se la funzione è continua allora per il teorema di Schwarz le derivate parziali miste sono uguali. 

Date queste derivate parziali seconde si possono ottenere le derivate terze, derivando parzialmente queste altre funzioni. 

%% TODO determinare dov'è derivabile la funzione f = 2x\ln(x+2y^2+1)+3y^2
% parabola x > -2y^2-1: punti a destra e non della parabola sono validi per la continuità


%% TODO add 2/5/25


In una dimensione, se una funzione è derivabile in un punto, allora è anche continua in quel punto, mentre questo concetto non si estende in due dimensioni, quindi se una funzione bidimensionale è derivabile in un punto $P_0$ sia rispetto ad $x$ che ad $y$, questo non implica che sia continua nello stesso punto $P_0$. 
Un esempio di una funzione del genere è la seguente:
\begin{gather*}
    f(x,y)=\begin{cases}
        \displaystyle\frac{\strut xy}{\strut x^2+y^2}&(x,y)\neq(0,0)\\
        0&(x,y)=(0,0)
    \end{cases}
\end{gather*}


Affinché sia continua il limite della funzione tendente all'origine deve essere uguale a zero:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}f(x,y)=\nexists
\end{gather*}
Questo limite è già stato dimostrato che non converge, per una traiettoria bisettrice infatti converge a $1/2$, metre su una traiettoria che si muove solamente lungo uno dei due assi, converge a $0$. La funzione non ammette limite, quindi non è continua nel punto $(0,0)$. Per essere continua deve essere regolare e valere $0$. 


Dal punto di vista grafico per studiare la derivabilità bisogna considerare un incremento $h$ sull'asse $x$ ed $y$, e si studia il limite di questa funzione, rispetto all'origine:
\begin{gather*}
    \lim_{h\to0}\displaystyle\frac{f(h,0)-f(0,0)}{h}=\lim_{h\to0}\frac{0-0}{h}=0
\end{gather*}
Questo diventa un limite di una funzione ad una variabile. La derivata parziale rispetto ad $x$ nell'origine esiste e vale $0$, analogamente per simmetria si ha che esiste anche la derivata parziale rispetto ad $y$ e vale anch'essa zero:
\begin{gather*}
    \displaystyle\frac{\partial f}{\partial x}(0,0)=0\\
    \displaystyle\frac{\partial f}{\partial y}(0,0)=0
\end{gather*}

\subsection{Integrai Doppi}

Un'integrale doppio è definito su un dominio di integrazione $D\in\mathbb{R}^2$, e si indica come:
\begin{gather*}
    \iint_Df(x,y)\df x\df y
\end{gather*}
Si semplifica l'analisi di questi integrali imponendo che questo dominio $D$ sia un dominio normale rispetto all'asse $x$, è l'insieme dei punti del piano tali che la variabile indipendente $x$ si deve muovere esclusivamente tra due costanti:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\bigg|a\leq x\leq b,\alpha(x)\leq y\leq\beta(x)\right\}
\end{gather*}
Dove $\alpha$ e $\beta$ sono continue in $[a,b]$. 

%% TODO img esempio dominio normale di integrazione rispetto all'asse x

Il caso più semplice è che il dominio normale di integrazione è un rettangolo. Si utilizza questa definizione di domino poiché esiste una formula che semplifica il calcolo di integrali doppi, a cui verrà attribuito anche un significato geometrico. 
Un'integrale doppio si può calcolare come il prodotto tra due integrali:
\begin{gather*}
    \displaystyle\iint_D f(x,y)\df x \df y=\int_a^b\df x\int_{\alpha(x)}^{\beta(x)}f(x,y)\df y
\end{gather*}
Questo integrale rappresenta il volume del sotto-grafico, è un'estensione della relazione tra area sottesa da un grafico ed integrale monodimensionale. 

C'è anche la possibilità di definire un domino normale rispetto all'asse $y$, ed in questo caso si inverte il ruolo delle due variabili. 

%% TODO img esempio dominio normale di integrazione rispetto all'asse y
Per questi integrali vale la proprietà additiva $D=D_1\cup D_2$, quindi l'integrale su $D$ è uguale alla somma tra gli integrali su $D_1$ e $D_2$. 

Si considera un triangolo $T$ nel piano definito da tre vertici $A=(0,0)$, $B=(2,0)$ e $C=(1,1)$, si vuole calcolare l'integrale su questo triangolo della funzione $f=xy+y^2$:
\begin{gather*}
    \iint_T(xy+y^2)\df x\df y
\end{gather*}

%% TODO img triangolo
Si utilizza la formula:
\begin{gather*}
    a=0\land b=2\\
    \alpha(x)=0\land
    \beta(x)=\begin{cases}
        x&0\leq x\leq 1\\
        2-x &1\leq x\leq 2
    \end{cases}\\
\end{gather*}
Si divide l'intervallo di integrazione in $T_1$ e $T_2$ e si ottiene quindi:
\begin{gather*}
    \iint_T(xy+y^2)\df x\df y=
    \int_0^1\df x\int_{0}^{x}(xy+y^2)\df y+
    \int_1^2\df x\int_{0}^{2-x}(xy+y^2)\df y\\
    \int_0^1\df x\left(\frac{1}{2}x^3+\frac{1}{3}x^3\right)+
    \int_1^2\df x\left(\frac{1}{2}x(2-x)^2+\frac{1}{3}(2-x)^3\right)\\
    \displaystyle\frac{5}{6}\int_0^1x^3\df x+\int_1^2\frac{1}{2}\left(x^3-4x^2+4x\right)+\frac{1}{3}\left(-x^3+6x^2-12x+8\right)\df x\\
    \frac{5}{24}+\int_1^2\frac{1}{6}x^3-2x+\frac{8}{3}\df x=\frac{5}{24}+\left[\frac{1}{24}x^4-x^2+\frac{8}{3}x\right]_1^2\\
    \frac{5}{25}+\left(\frac{16}{24}-4+\frac{16}{3}\right)-\left(\frac{1}{24}-1+\frac{8}{3}\right)=\frac{20}{24}-3+\frac{8}{3}=\frac{20-3\cdot24+8\cdot8}{24}=\frac{84-72}{24}=\frac{1}{2}
\end{gather*}


Si considera il seguente integrale doppio:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y
\end{gather*}
Dove $D=[1,2]\times[0,1]$.
%% TODO img dominio di integrazione sull'asse xy
Si risolve mediante la formula:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y=\int_1^2\df x\int_0^1(x^2+y^2)\df y=\int_1^2\left[x^2y+\frac{1}{3}y^3\right]_0^1\df x\\
    \int_1^2\left(x^2+\frac{1}{3}\right)\df x=\frac{1}{3}\left[x^3+x\right]_1^2=\frac{1}{3}(8+2-1-1)=\frac{8}{3}
\end{gather*}
Si considera ora il dominio normale rispetto all'asse $y$:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y=\int_0^1\df y\int_1^2(x^2+y^2)\df x=
    \int_0^1\left[y^2x+\frac{1}{3}x^3\right]_1^2\df y\\
    \int_0^1\left(y^2+\frac{7}{3}\right)\df y=\frac{1}{3}\left[y^3+7y\right]_0^1=\frac{1}{3}(1+7-0)=\frac{8}{3}
\end{gather*}


Si considera il seguente integrale:
\begin{gather*}
    \iint_D xy\df x \df y
\end{gather*}
Dove $D$ è il dominio delimitato nel primo quadrante costituito ad un quarto di cerchio, centrato nell'origine e di raggio 1. Questo dominio è normale sia rispetto all'asse $x$ che rispetto all'asse $y$. Si considera il dominio di integrazione normale rispetto all'asse $x$ e si applica la formula di riduzione:
\begin{gather*}
    x\in[0,1]
    y\in\left[\alpha(x)=0,\beta(b)=\sqrt{1-x^2}\right]\\
    \iint_D xy\df x \df y=\int_0^1\df x\int_0^{\sqrt{1-x^2}}xy\df y=\int_0^1 x\df x\int_0^{\sqrt{1-x^2}}y\df y=
    \frac{1}{2}\int_0^1 x\left(\sqrt{1-x^2}\right)^2\df x\\
    \frac{1}{2}\int_0^1 (x-x^3)\df x=\frac{1}{2}\left[\frac{1}{2}x^2-\frac{1}{4}x^4\right]_0^1=\frac{1}{2}\left(\frac{1}{2}-\frac{1}{4}\right)=\frac{1}{8}
\end{gather*}

Applicando la formula poiché $x$ è indipendente da $y$ si può spostare direttamente all'integrale esterno, ma i due integrali non si possono separare come il prodotto di due integrali, poiché la variabile $y$ dipende ancora da $x$ quindi devono essere calcolati insieme. 

Si considera lo stesso integrale, dove il dominio di integrazione è dato da $D=[0,1]\times[0,1]$:
\begin{gather*}
    \iint_D xy\df x\df y=\int_0^1\df x\int_0^1 xy\df y
\end{gather*}
Poiché le due variabili sono indipendenti, e l'intervallo di integrazione di $y$ è indipendente dalla variabile $x$, si possono trattare i due integrali come indipendenti e quindi si può trattare come fosse un prodotto di integrali:
\begin{gather*}
    \int_0^1\df x\int_0^1 xy\df y=\int_0^1 x\df x\cdot\int_0^1 y\df y
\end{gather*}


Si considera l'integrale:
\begin{gather*}
    \iint_D(x+y)\df x \df y
\end{gather*}
Dove il dominio $D$ è definito sul primo quadrante tale che:
\begin{gather*}
    x^2+y^2\leq1\\
    y\leq2x
\end{gather*}
Per definire il dominio si considerano le due equazioni $x^2+y^2=1$ e $y=2x$. I punti della prima equazione sono tutti i punti che si trovano sulla circonferenza di raggio 1 e centrata nell'origine, quindi si considerano tutti i punti dell'arco di circonferenza nel primo quadrante. Poiché la relazione è $x^2+y^2<1$, si considerano tutti i punti interni alla circonferenza, quindi tutti i punti nel primo quadrante appartenente a questo spicchio di circonferenza. 
Considerando ora la seconda equazione, la retta $y=2x$, i punti del piano che la soddisfano sono tutti i punti del piano al di sotto di questa retta, $y<2x$. 
%% TODO img dominio di integrazione intersezione tra primo quadrante, retta y=2x e cerchio (0,0) 1

La funzione $\beta(x)$ è composta da due funzioni la prima è un tratto di retta, la seconda è un arco di circonferenza, quindi conviene utilizzare la proprietà additiva per dividere in due il domino $D$ nel punto di intersezione sull'asse $x$ di queste due funzioni:
\begin{gather*}
    \beta_1(x)=2x\\
    \beta_2(x)=\sqrt{1-x^2}\\
    2x=\sqrt{1-x^2}\\
    4x^2=1-x^2\\
    5x^2=1\implies x=\pm\frac{1}{\sqrt{5}}=\pm\frac{\sqrt{5}}{5}
\end{gather*}
Si considerano solo i punti nel primo quadrante si considerano solo i valori positivi. I due domini di integrazione $D_1$ e $D_2$ sono quindi:
\begin{gather*}
    D_1=\left\{(x,y)\in\mathbb{R}^2\bigg|0\leq x\leq \frac{\sqrt{5}}{5}\land 0\leq y\leq 2x\right\}\\
    D_2=\left\{(x,y)\in\mathbb{R}^2\bigg|\frac{\sqrt{5}}{5}\leq x\leq 1\land 0\leq y\leq \sqrt{1-x^2}\right\}\\
    \iint_D(x+y)\df x \df y=\overbrace{\iint_{D_1}(x+y)\df x \df y}^{I_1}+\underbrace{\iint_{D_2}(x+y)\df x \df y}_{I_2}
\end{gather*}
A questo punto si analizzano individualmente i due integrali $I_1$ e $I_2$. Si utilizza la formula di risoluzione:
\begin{gather*}
    I_1=\iint_{D_1}(x+y)\df x \df y=\int_0^{1/\sqrt{5}}\df x\int_0^{2x}(x+y)\df y=\int_0^{1/\sqrt{5}}\left[xy+\frac{1}{2}y^2\right]_0^{2x}\df x\\
    \int_0^{1/\sqrt{5}}2x^2+2x^2\df x=4\int_0^{{1}/{\sqrt{5}}}x^2\df x=\left[\frac{4}{3}x^3\right]_0^{1/\sqrt{5}}=\frac{4}{3\sqrt{125}}
\end{gather*}
Si considera il secondo integrale:
\begin{gather*}
    I_2=\iint_{D_1}(x+y)\df x \df y=\int_{1/\sqrt{5}}^1\df x\int_0^{\sqrt{1-x^2}}(x+y)\df y=
    \int_{1/\sqrt{5}}^1\left[xy+\frac{1}{2}y^2\right]_0^{\sqrt{1-x^2}}\df x\\
    \int_{1/\sqrt{5}}^1x\sqrt{1-x^2}+\frac{1}{2}\left(\sqrt{1-x^2}\right)^2\df x=
    \overbrace{\int_{1/\sqrt{5}}^1x\sqrt{1-x^2}\df x}_{I_3}+\underbrace{\frac{1}{2}\int_0^{1/\sqrt{5}}(1-x^2)\df x}_{I_4}\\
    % I_4=\int_0^{1/\sqrt{5}}1-x^2\df x=\frac{1}{2}\left[\right]
\end{gather*}
%% TODO finire calcolo integrale



Calcolare l'integrale doppio della funzione $x^2+y^2$ per un dominio che giace sul primo e secondo quadrante, sotteso dalle curve $y=0$ e $1-x^2$:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y=\int_{-1}^1\df x\int_0^{1-x^2}(x^2+y^2)\df y=\int_{-1}^1\left[x^2y+\frac{1}{3}y^3\right]_0^{1-x^2}\df x\\
    \int_{-1}^1x^2(1-x^2)+\frac{1}{3}(1-x^2)^3\df x=
    \int_{-1}^1\cancel{x^2}\cancel{-x^4}+\frac{1}{3}\bcancel{-x^2}\bcancel{+x^4}-\frac{1}{3}x^6\df x\\
    \frac{1}{3}\int_{-1}^11-x^6\df x=\frac{1}{3}\left[x-\frac{1}{7}x^7\right]_{-1}^1=\frac{2}{3}\left[x-\frac{1}{7}x^7\right]_0^1=\frac{2}{\cancel{3}}\cdot\frac{\cancelto{2}{6}}{7}=\frac{4}{7}
\end{gather*}


Calcolare l'area della regione giacente nel primo quadrante delimitata dalle curve di equazione $y=x$ e $y^2=2x$. Se la funzione integranda è costante ed uguale ad uno, allora l'integrale doppio rappresenta l'area del dominio di integrazione:
\begin{gather*}
    \iint_D\df x\df y=\int_0^{x_0}\df x\int_x^{\sqrt{2x}}\df y
\end{gather*}
Il problema è quindi determinare il dominio di integrazione. Dal punto di vista geometrico bisogna individuare l'ascissa $x_0$ dell'intersezione delle due curve:
\begin{gather*}
    y=\frac{y^2}{2}\implies y=2
\end{gather*}
Si risolve quindi l'integrale:
\begin{gather*}
    \iint_D\df x\df y=\int_0^2\df x\int_x^{\sqrt{2x}}\df y=\int_0^2(\sqrt{2x}-x)\df x=
    \left[\frac{4\sqrt{2}}{3}x^{3/2}-\frac{1}{2}x^2\right]_0^2=\frac{4\sqrt{2}}{3}2\sqrt{2}-2=\frac{10}{3}
\end{gather*}

\subsubsection*{Esercizi 16/5/25}

Calcolare il seguente integrale doppio:
\begin{gather*}
    \iint_D\frac{x}{x+y+1}\df x\df y
\end{gather*}
Dove il dominio $D$ è dato da:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\land x\leq y\land x+y\leq 2\right\}
\end{gather*}
Per la prima disequazione il dominio di integrazione si trova nel primo e quarto quadrante. La seconda disequazione divide il piano in due porzioni, essendo una bisettrice del primo quadrante, poiché contiene tutti i punti $(x,y)$ dove si ha $y\geq x$, allora si considera la porzione superiore di piano divisa da questa bisettrice, semiretta compresa, nel primo quadrante. 
Si considera ora l'ultima disequazione:
\begin{gather*}
    x+y\leq2\\
    y=2-x
\end{gather*}
Questa individua una retta che nel primo quadrante è individuata dai punti $(2,0)$ e $(0,2)$, questa interseca la seconda disequazione nel punto $(1,1)$. Si considerano tutti i punti nella parte inferiore individuati da questa retta, retta compresa. 
Considerando l'intersezione con le altre disequazioni individuate, allora il dominio di integrazione $D$ è un triangolo individuato dai punti $(0,0)$, $(2,0)$ e $(1,1)$. Si può esprimere come:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\leq1\land x\leq y\leq2-x\right\}
\end{gather*}
Questo dominio è normale rispetto all'asse $x$, quindi si considera la formula:
\begin{gather*}
    \iint_D\frac{x}{x+y+1}\df x\df y=\int_0^1\df x\int_{x}^{2-x}\frac{x}{x+y+1}\df y
\end{gather*}
Non essendo indipendenti non si possono separare. Si calcola quindi il primo integrale facilmente essendo immediato:
\begin{gather*}
    \int_0^1\df x\int_{x}^{2-x}\frac{x}{x+y+1}\df y=
    \int_0^1x\left[\ln|x+y+1|\right]_x^{2-x}\df x=
    \int_0^1x\ln3 - x\ln|2x+1|\df x\\
    \ln3\left[\frac{x^2}{2}\right]_0^1-\int_0^1x\ln|2x+1|\df x    
\end{gather*}
Si risolve questo secondo integrale tramite integrazione per parti:
\begin{gather*}
    \ln\sqrt{3}-\left(\ln|2x+1|\cdot\frac{x^2}{2}\bigg|_0^1-\frac{2}{2}\int_0^1\frac{x^2}{2x+1}\df x\right)=
    \cancel{\ln\sqrt{3}}-\bcancel{\ln\sqrt{3}}+\int_0^1\frac{x^2}{2x+1}\df x\\
    \iint_D\frac{x}{x+y+1}\df x\df y=\int_0^1\frac{x^2}{2x+1}\df x=\frac{\ln3}{8}
\end{gather*}
% Si effettua la divisione tra polinomi: 
% \begin{gather*}
%     \frac{x^2}{2x+1}=Ax+\frac{Bx+C}{2x+1}\\
%     Ax(2x+1)+Bx+C=x^2\\
%     2Ax^2+Ax+Bx+C=x^2\\
%     A=\frac{1}{2},B=-\frac{1}{2}
% \end{gather*}
%  x^2 0 0 | 2x 1
%% TODO risolvere integrale


Si considera lo stesso esercizio, dove il dominio di integrazione consiste nel trapezoide definito dai punti $(0,0)$, $(1,0)$, $(1,1)$ e $(2,0)$. Quindi è sufficiente aggiungere al valore ottenuto dal precedente esercizio all'integrale doppio sul dominio di integrazione individuato dai punti $(0,0)$, $(1,1)$, $(1,0)$:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big| 0\leq x\leq1\land 0\leq y\leq x\right\}
\end{gather*}
%% TODO risolvere esercizio


Calcolare il volume del sotto-grafico della funzione $f(x,y)=e^x\cos(y-x)$, con un dominio di integrazione $D$ è dato da:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\leq\frac{\pi}{2}\land x\leq y\leq\pi\right\}
\end{gather*}
% Bisogna determinare il segno della funzione per %% TODO ??
Il dominio di integrazione risulta essere un trapezio individuato dai punti $(0,0)$, $(\pi/2, \pi/2)$, $(\pi/2,\pi)$ e $(0,\pi)$. Su questo insieme deve essere valutato il segno della funzione. Un esponenziale è un fattore sempre positivo, quindi il segno della funzione dipende dalla funzione sinusoidale. Bisogna che la funzione sia positiva sull'intero intervallo, altrimenti il calcolo del volume deve essere determinato differentemente, sui domini dov'è positivo e negativo ed in seguito effettuare la differenza. Si determina dov'è che la funzione è positiva:
\begin{gather*}
    f(x,y)\geq0\implies \cos(y-x)\geq0\\
    -\frac{\pi}{2}+2k\pi\leq y-x\leq\frac{\pi}{2}+2k\pi\,\,\forall k\in\mathbb{Z}\\
    x-\frac{\pi}{2}+2k\pi\leq y\leq x+\frac{\pi}{2}+2k\pi\,\,\forall k\in\mathbb{Z}
\end{gather*}
Per rimanere nel dominio di integrazione l'unico valore di $k$ accettato è $k=0$, quindi si ha:
\begin{gather*}
    x-\frac{\pi}{2}\leq y\leq x+\frac{\pi}{2}
\end{gather*}
Considerando l'intervallo di $x$ ammissibili $x\in[0,\pi/2]$, allora l'insieme dei punti dove la funzione è positiva è delimitata dai punti $(0,-\pi/2)$, $(\pi/2,0)$, $(\pi/2,\pi)$ e $(0,\pi/2)$. Considerando l'intersezione con il dominio di integrazione $D$, la funzione positiva nel dominio $D_1$ definito da $(0,0)$, $(\pi/2,\pi/2)$, $(\pi/2,\pi)$ e $(0,\pi/2)$, mentre è negativa nel dominio $D_2$ definito dai punti $(0,\pi/2)$, $(\pi/2,\pi)$ e $(\pi,0)$. Il volume è quindi dato da:
\begin{gather*}
    V=\iint_{D_+}e^x\cos(y-x)\df x\df y-\iint_{D_-}e^x\cos(y-x)\df x\df y
\end{gather*}
I domini di integrazione $D_1$ e $D_2$ sono definiti come:
\begin{gather*}
    D_+=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\leq\frac{\pi}{2}\land x\leq y\leq x+\frac{\pi}{2}\right\}\\
    D_-=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\leq\frac{\pi}{2}\land x+\frac{\pi}{2}\leq y\leq {\pi}\right\}
\end{gather*}
Sono entrambi normali rispetto alla $x$, quindi si applica la formula:
\begin{gather*}
    I_+=\iint_{D_+}e^x\cos(y-x)\df x\df y=\int_0^{\pi/2}\df x\int_x^{x+\pi/2}e^x\cos(y-x)\df y\\
    I_-=\iint_{D_-}e^x\cos(y-x)\df x\df y=\int_0^{\pi/2}\df x\int_{x+\pi/2}^\pi e^x\cos(y-x)\df y
\end{gather*}
Il fattore $e^x$ è costante rispetto alla $y$ per entrambi gli integrali quindi si può portare fuori dal primo integrale:
\begin{gather*}
    I_+=\int_0^{\pi/2}e^x\df x\int_x^{x+\pi/2}\cos(y-x)\df y=
    \int_0^{\pi/2}e^x\left[\sin(y-x)\right]_x^{x+\pi/2}\df x\\
    I_-=\int_0^{\pi/2}e^x\df x\int_{x+\pi/2}^\pi\cos(y-x)\df y=
    \int_0^{\pi/2}e^x\left[\sin(y-x)\right]_{x+\pi/2}^\pi\df x
\end{gather*}
%% TODO risolvere
\begin{gather*}
    V=\frac{3}{2}e^{\pi/2}-\frac{5}{2}
\end{gather*}


\subsubsection{Trasformazione Regolare di Coordinate}

Questo metodo è analogo al calcolo di un limite a multi-variabile, questo processo permette di semplificare il calcolo dell'integrale, e del dominio di integrazione. 
Si suppone di avere un integrale doppio di una funzione continua $f(x,y)$ in un dominio di integrazione $D$:
\begin{gather*}
    \iint_Df(x,y)\df x\df y
\end{gather*}
Si suppone di avere un dominio di integrazione $D$ ed una funzione $f(x,y)$ eccessivamente complessi. 
Si considera un trasferimento di coordinate, rispetto ad una nuova coppia di coordinate $(u,v)$:
\begin{gather*}
    \begin{cases}
        x=x(u,v)\\
        y=y(u,v)
    \end{cases}
\end{gather*}
Per trasferire il dominio e la funzione si considera la seguente formula: 
\begin{gather*}
    \iint_Df(x,y)\df x\df y\to
    \iint_{D'}f[x(u,v),y(u,v)]|\det J|\df u\df v
\end{gather*}
Dove $J$ è la matrice jacobiana, di cui bisogna calcolare il determinante, questa matrice è del tipo $2\times 2$, ed è definita come: %% TODO cambiare J in math-qualcosa
\begin{gather*}
    J(u,v)=\begin{pmatrix}
        \displaystyle\frac{\partial\strut x}{\partial\strut u}&\displaystyle\frac{\partial\strut x}{\partial\strut v}\\
        \displaystyle\frac{\partial\strut y}{\partial\strut u}&\displaystyle\frac{\partial\strut y}{\partial\strut v}
    \end{pmatrix}
\end{gather*}


Si parla di trasformazione regolare di coordinate se sono soddisfatte tre ipotesi. Se le funzioni $x(u,v)$ e $y(u,v)$ sono funzioni di classe $C$ derivabili sia rispetto ad $x$ che ad $y$ con continuità; se queste funzioni sono invertibili; infine il determinante della matrice jacobiana deve essere diverso da zero. 


Considerando una trasformazione in coordinate polari si ha:
\begin{gather*}
    \begin{cases}
        x=x_0+\rho\cos\theta\\
        y=y_0+\rho\sin\theta
    \end{cases}
\end{gather*}
Dove $x_0$ e $y_0$ sono le coordinate del centro. Quando si considera la trasformazione in coordinate polari, il determinante della matrice jacobiana $\det J$ è sempre uguale a $\rho$. 

\subsubsection*{Esercizi 16/5/25}

Calcolare il seguente integrale doppio:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y
\end{gather*}
Dove il dominio di integrazione $D$ è dato da:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|x\geq0\land y\geq0\land x^2+y^2\leq 1\right\}
\end{gather*}
Questo esercizio si risolve prima in coordinate cartesiane e poi polari. Il dominio è un quarto di cerchio nel primo quadrante centrato nell'origine e di raggio unitario:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y=\int_0^1\df x\int_0^{\sqrt{1-x^2}}(x^2+y^2)\df y
    % =\int_0^1\left[x^2y+\frac{y^3}{3}\right]_0^{\sqrt{1-x^2}}\df x\\
    % \int_0^1x^2\sqrt{1-x^2}+\frac{1}{3}\sqrt{1-x^2}-\frac{1}{3}\sqrt{1-x^2}\df x
\end{gather*}

Si effettua una trasformazione regolare in coordinate polari:
\begin{gather*}
    \begin{cases}
        x=\rho\cos\theta\\
        y=\rho\sin\theta
    \end{cases}
\end{gather*}
Per rimanere nel quarto di circonferenza la variabile $\rho$ deve essere compresa in $[0,1]$, mentre la variabile $\theta$ effettua un quarto di rotazione, quindi deve essere contenuto in $[0,\pi/2]$ 
L'integrale diventa quindi:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y\to
    \iint_{D'}\rho^2(\cancelto{1}{\cos^2\theta+\sin^2\theta})|\det J|\df\theta\df\rho
\end{gather*}
Dove il nuovo dominio di integrazione è $D'=[0,1]\times[0,\pi/2]$: %% TODO img del rettangolo corrispondente in coordinate polari, trasformazione dal quarto di cerchio
\begin{gather*}
    \iint_{D'}\rho^2\cdot\rho\df\theta\df\rho=\int_0^{\pi/2}\df\theta\cdot\int_0^{1}\rho^3\df\rho=
    \left[\theta\right]_0^{\pi/2}\cdot\left[\frac{\rho^4}{4}\right]_0^{1}=\frac{\pi}{8}
\end{gather*}



Si considera la stessa funzione, ma in un dominio di integrazione diverso, corrispondente ad un ottavo di cerchio:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|x\geq0\land 0\leq y\leq x\land x^2+y^2\leq 1\right\}
\end{gather*}
Si passa a coordinate polari, quindi si ha un nuovo dominio di integrazione $D'$:
\begin{gather*}
    D'=[0,1]\times\left[0,\frac{\pi}{4}\right]
\end{gather*}
L'integrale diventa:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y\to\iint_{D'}\rho^3\df\theta\df\rho=\int_0^{\pi/4}\df\theta\cdot\int_0^{1}\rho^3\df\rho=\frac{\pi}{16}
\end{gather*}


\clearpage

\end{document}
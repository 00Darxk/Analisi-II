\documentclass{article}

\usepackage{cancel}
\usepackage{amsmath,amssymb}
\usepackage[includehead,nomarginpar]{geometry}
\usepackage{graphicx}
\usepackage{amsfonts} 
\usepackage{verbatim}
\usepackage{mathrsfs}  
\usepackage{lmodern}
\usepackage{braket}
\usepackage{bookmark}
\usepackage{fancyhdr}
\usepackage{romanbarpagenumber}
%\usepackage{minted}
%\usepackage{subfig}
\usepackage[italian]{babel}
\usepackage{float}
%\usepackage{wrapfig}
%\usepackage[export]{adjustbox}
\usepackage{contour}
\usepackage[normalem]{ulem}
\usepackage{circuitikz}
\allowdisplaybreaks

\setlength{\headheight}{12.0pt}
\addtolength{\topmargin}{-12.0pt}
\graphicspath{ {./Immagini/} }

%% TODO add metadata
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    pdftitle={Appunti di Analisi II},
    pdfauthor={Giacomo Sturm},
    pdfsubject={Analisi II},
    pdfkeywords={}
}

\newsavebox{\tempbox} %{\raisebox{\dimexpr.5\ht\tempbox-.5\height\relax}}


\makeatother
%% Derivate:
\newcommand{\df}{\mathrm{d}}
\newcommand{\diff}[2]{\displaystyle\frac{\df{#1}}{\df{#2}}}
\newcommand{\diffn}[3]{\displaystyle\frac{\df^{#3}{#1}}{\df{#2}^{#3}}}
\newcommand{\pdiff}[2]{\displaystyle\frac{\partial{#1}{\partial{#2}}}}
\newcommand{\pdiffn}[3]{\displaystyle\frac{\partial^{#3}{#1}{\partial{#2}^{#3}}}}

%% Integrali:
\newcommand{\intab}[4]{\displaystyle\int_{#1}^{#2}{#3}\df{#4}}
\newcommand{\intinf}[2]{\intab{-\infty}{+\infty}{#1}{#2}}
\newcommand{\intpinf}[2]{\intab{0}{+\infty}{#1}{#2}}
\newcommand{\intninf}[2]{\intab{-\infty}{0}{#1}{#2}}

%% Sommatorie:
\newcommand{\sumab}[4]{\displaystyle\sum_{#4=#1}^{#2}{#4}}
\newcommand{\suminf}[2]{\sumab{-\infty}{+\infty}{1}{2}}
\newcommand{\sumpinf}[2]{\sumab{0}{+\infty}{1}{2}}
\newcommand{\sumninf}[2]{\sumab{-\infty}{0}{1}{2}}

\renewcommand{\contentsname}{Indice}
\numberwithin{equation}{subsection}
\newcommand{\tageq}{\tag{\stepcounter{equation}\theequation}}
\AtBeginDocument{%
    \renewcommand{\figurename}{Fig.}
}
\renewcommand{\ULdepth}{1.8pt}
\contourlength{0.6pt}
\newcommand{\myuline}[1]{%
    \uline{\phantom{#1}}%
    \llap{\contour{white}{#1}}%
}
\fancypagestyle{link}{\fancyhf{}\renewcommand{\headrulewidth}{0pt}\fancyfoot[C]{Sorgente del file \LaTeX\space ed ultima versione del testo disponibile al link: \url{https://github.com/00Darxk/Analisi-II/}}}

\begin{document}

\title{%
    \textbf{Analisi II}  \\ 
    \large Appunti delle Lezioni di Analisi II \\
    \textit{Anno Accademico: 2024/25}}
\author{\textit{Giacomo Sturm}}
\date{\textit{Dipartimento di Ingegneria Industriale, Elettronica e Meccanica \\
Università degli Studi ``Roma Tre"}} 

\maketitle
\thispagestyle{link}

\clearpage


\pagestyle{fancy}
\fancyhead{}\fancyfoot{}
\fancyhead[C]{\textit{Analisi II - Università degli Studi ``Roma Tre"}}
\fancyfoot[C]{\thepage}
\pagenumbering{Roman}

\tableofcontents

%% TODO numerare equazioni

\clearpage
\pagenumbering{arabic}

\section{Serie Numeriche}

Una serie numerica $\{a_n\}$ è una \textit{particolare} successione numerica; 
è una particolare funzione che ha come dominio l'insieme dei numeri naturali $\mathbb{N}$ e come codominio un sottoinsieme $\mathbb{C}$ dell'asse dei numeri reali $\mathbb{R}$. 
\begin{equation}
    \{a_n\}:\mathbb{N}\rightarrow\mathbb{C}\in\mathbb{R}
\end{equation}

È di interesse studiare il comportamento della serie numerica quando la variabile indipendente $n$ tende all'infinito. Data una successione numerica, si interessa quindi:
\begin{equation}
    \lim_{n\to\infty}a_n
\end{equation}

Si generalizza nel limite di una funzione quando si sostituisce alla variabile $n$ una variabile indipendente reale $x\in\mathbb{R}$. 

Una successione può convergere ad un numero reale, può divergere positivamente o negativamente, in questi due casi è regolare, quindi ha un limite definito o indefinito. Altrimenti è possibile che il limite non esiste, quindi la sequenza non si stabilisce su nessun numero reale ed oscilla per $n$ tendente ad $\infty$. 

\begin{equation}
    \lim_{n\to\infty}a_n=\begin{cases}
        i\in\mathbb{R}\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{equation}

Si costruisce una serie numerica $\{s_n\}$, partendo da una sequenza nota $\{a_k\}$, si può costruire definendo per ogni valore $n$ il valore di $s_n$ tale che sia pari alla somma dei primi $a_n$ elementi della sequenza:
\begin{equation}
    \forall n\in\mathbb{N}:\,
    s_n:=a_1+\cdots+a_n
\end{equation}

$s_n$ viene chiamata somma parziale della serie $\{s_n\}$ e viene definita con il seguente simbolo:
\begin{equation}
    s_n:=\displaystyle\sum_{k=1}^\infty a_k
\end{equation}
La serie numerica è la successione delle somme parziali costruite sulla successione $\{a_k\}$. 

Una serie numerica si dice convergente se il limite della successione delle somme parziali, costruite a partire dalla successione $a_k$, è pari ad un numero $s$:
\begin{equation}
    \{s_n\}: \mbox{converge se}\,\lim_{n\to\infty}s_n=s\in\mathbb{R}
\end{equation}

Si dice divergente se il limite della successione delle somme parziali tende ad infinito:
\begin{equation}
    \{s_n\}: \mbox{diverge se}\,\lim_{n\to\infty}s_n=\pm\infty
\end{equation}

Se converge o diverge la serie numerica si dice regolare, se invece studiando il comportamento delle somme parziali per $n\to\infty$, il limite della somma non è definito, quindi la serie si dice irregolare:
\begin{equation}
    \{s_n\}: \mbox{è irregolare se}\,\lim_{n\to\infty}s_n=\nexists
\end{equation}

Studiare il comportamento della serie vuol dire studiare il comportamento delle somme parziali. La somma parziali si avrà sempre in forma aperta, se fosse possibile esprimere in forma chiusa la forma parziale, allora il limite è di facile calcolo. 

%% ESEMPIO

Considerando il seguente limite:
\begin{equation*}
    \lim_{n\to\infty}(1+2+\cdots+n)
\end{equation*}
Esiste una funzione per esprimere in forma chiusa questa funzione, dimostrabile per induzione:
\begin{equation*}
    \lim_{n\to\infty}\left(\displaystyle\frac{n(n+1)}{2}\right)=+\infty
\end{equation*}

Quindi è facile determinare che si tratta di una serie divergente ad infinito positivo. Questo passaggio d'ora in avanti non sarà più possibile, basterà stabilire il carattere di una serie, senza sapere il valore a cui converge. Solo nel caso della serie telescopica e della serie geometrica sarà possibile determinare il valore della convergenza. 

\subsection{Serie Telescopica}

Il caso più rappresentativo di una serie telescopica è la seguente:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k(k+1)}
\end{equation}

Analizzando la somma parziale $s_n$ fino ad un certo valore $n\in\mathbb{N}$ si ha:
\begin{gather*}
    s_n=\displaystyle\sum_{k=1}^n\frac{1}{k(k+1)}=\frac{1}{2}+\cdots+\frac{1}{n(n+1)}
\end{gather*} 

Utilizzando la tecnica dei fratti semplici si può riscrivere la somma parziale come:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k(k+1)}=\sum_{k=1}^\infty\left(\frac{1}{k}-\frac{1}{k+1}\right)
\end{gather*}

In questo modo calcolando la somma parziale si ottiene:
\begin{gather*}
    s_n=\displaystyle\sum_{k=1}^n\left(\frac{1}{k}-\frac{1}{k+1}\right)\\
    \left({1}-\frac{1}{2}\right)+
    \left(\frac{1}{2}-\frac{1}{3}\right)+
    \left(\frac{1}{3}-\frac{1}{4}\right)+
    \cdots+
    \left(\frac{1}{n-1}-\frac{1}{n}\right)+
    \left(\frac{1}{n}-\frac{1}{n+1}\right)
\end{gather*}
Si può notare come l'addendo 1/2 si cancella con l'addendo della differenza successiva, così con 1/3, così per ogni valore della sommatoria, permettendo quindi di scrivere la somma parziale $s_n$ in forma chiusa esprimendo solamente il primo addendo e l'ultimo addendo:
\begin{gather*}
    \left({1}-\cancel{\frac{1}{2}}\right)+
    \left(\cancel{\frac{1}{2}}-\bcancel{\frac{1}{3}}\right)+
    \left(\bcancel{\frac{1}{3}}-\cancel{\frac{1}{4}}\right)+
    \cdots+
    \left(\bcancel{\frac{1}{n-1}}-\cancel{\frac{1}{n}}\right)+
    \left(\cancel{\frac{1}{n}}-\frac{1}{n+1}\right)=
    1-\frac{1}{n+1}
\end{gather*}

Considerando il limite di questa serie si ha:
\begin{equation*}
    \lim_{n\to\infty}\left(1-\displaystyle\frac{1}{n+1}\right)=1
\end{equation*}

In generale una serie telescopica, ha i suoi termini $a_k$ definiti come la differenza tra il termine $k+1$-esimo ed il termine $k$-esimo di una particolare successione $\{A_k\}$:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty a_k=\sum_{k=1}^\infty\left(A_{k+1}-A_{k}\right)
\end{equation} 

\subsection{Serie Geometrica}

Una serie geometrica esprimibile come:
\begin{equation}
    \displaystyle\sum_{k=0}^\infty x^k
\end{equation}
Come altre serie dipende da un parametro reale $x\in\mathbb{R}$, questo si chiama ragione della serie. 

Si costruisce la somma parziale della serie:
\begin{equation*}
    s_n=\displaystyle\sum_{k=0}^n x^k=1+x+x^2+\cdots+x^n    
\end{equation*}
Si vuole esprimere questa somma in forma chiusa. Per $x=0$, per ogni valore di $n$, la somma vale sempre $1$, poiché:
\begin{gather*}
    \forall n\in\mathbb{N}: s_n=0^0+0^1+0^2+\cdots+0^n=1
\end{gather*}

Un altro caso analogo con $x=1$, si ha la seguente somma parziale:
\begin{gather*}
    \forall n\in\mathbb{N}: s_n=1+1+1+\cdots+1=1\cdot n
\end{gather*}

Questa serie quindi converge per $x=0$, diverge per $x=1$, mentre per altri valori reali non è ancora noto il suo comportamento. 
Si considera ora il caso generale con una ragione diversa da zero e da uno $\forall x\in\mathbb{R}\setminus\{0,1\}$. 
Si considera noto il valore $s_n$:
\begin{equation*}
    s_n=\displaystyle\sum_{k=0}^n x^k=1+x+x^2+\cdots+x^n    
\end{equation*}
Si moltiplica la somma parziale per la ragione e si sottrae alla somma parziale:
\begin{gather*}
    xs_n=x\cdot\displaystyle\sum_{k=0}^n x^k=\sum_{k=1}^nx^k\\
    (1-x)s_n=s_n-xs_n=1+\cancel{x}+\cancel{x^2}+\cdots+\cancel{x^n}-\left(\bcancel{x}+\bcancel{x^2}+\cdots+\bcancel{x^n}+x^{n+1}\right)=1-x^{n+1}
\end{gather*}

Della prima somma sopravvive solamente il primo addendo $1$, e della seconda l'ultimo addendo $x^{n+1}$, tutti gli altri si cancellano a vicenda, quindi per ottenere il valore della somma parziale si divide il primo ed il secondo membro per il fattore $1-x$:
\begin{equation}
    s_n=\displaystyle\frac{1-x^{n+1}}{1-x}
\end{equation}
Si provvede ora a calcolare il limite di questa somma parziale, dividendolo per la proprietà di linearità, supponendo che questi due limiti risultanti non corrispondono ad una forma indeterminata:
\begin{equation*}
    \lim_{n\to\infty}\displaystyle\frac{1-x^{n+1}}{1-x}=\lim_{n\to\infty}\frac{1}{1-x}-\lim_{n\to\infty}\frac{x^{n+1}}{1-x}
\end{equation*}
Il primo fattore non dipende da $n$ e si mette in evidenza, inoltre il primo limite è indipendente da $n$ e si ottiene:
\begin{equation*}
    \displaystyle\frac{1}{1-x}\left(1-\lim_{n\to\infty}x^{n+1}\right)
\end{equation*}
Il comportamento di questo limite dipende dalla ragione $x$:
\begin{gather}
    \lim_{n\to\infty}x^{n+1}=\begin{cases}
        0 &-1<x<1\\
        +\infty  & x>1\\
        \nexists & x\leq-1
    \end{cases}
\end{gather}
Per $|x|<1$ la funzione è decrescente, e tende a zero, mentre per $x>1$, la funzione è esponenziale e quindi tende ad infinito. Invece per $x<-1$ si considera il limite, mettendo in evidenza il segno negativo:
\begin{gather*}
    \lim_{n\to\infty}(-|x|)^{n+1}=
    \lim_{n\to\infty}\left[(-1)^{n+1}\cdot |x|^{n+1}\right]
\end{gather*}
Il secondo fattore diverge, mentre il primo fattore oscilla di segno in base alla parità di $n$, per cui questa funzione oscilla di ampiezza sempre maggiore, per cui è irregolare. 
Per $x=-1$ il secondo fattore vale uno, mentre il primo fattore si considera comunque, per cui continua ad oscillare alla stessa ampiezza, quindi rappresenta allo stesso modo un comportamento irregolare. 

Noto il comportamento di questo limite allora il valore della serie geometrica in base alla ragione è dato da:
\begin{equation}
    \displaystyle\sum_{k=0}^\infty x^k=\begin{cases}
        \displaystyle\frac{\strut 1}{\strut 1-x} &-1<x<1\\
        +\infty & x\geq1\\
        \nexists & x\leq-1
    \end{cases}
\end{equation}

Questa serie ha un addendo in più poiché parte da $k=0$, per cui esprimendola come una serie partendo da $k=1$ si ha:
\begin{equation*}
    \displaystyle\sum_{k=1}^\infty x^k=\displaystyle\sum_{k=0}^\infty x^k-1
\end{equation*}
Il valore di questa successione quindi si comporta analogamente al precedente, considerando l'addendo in più:

\begin{equation}
    \displaystyle\sum_{k=1}^\infty x^k=\begin{cases}
        \displaystyle\frac{\strut 1}{\strut 1-x}-1 &-1<x<1\\
        +\infty & x\geq1\\
        \nexists & x\leq-1
    \end{cases}
\end{equation}

\subsection{Criteri di Convergenza}

Esistono vari criteri per determinare la convergenza di una serie numerica. 

\subsubsection{Condizione Neccessaria Convergenza}

Il primo criterio definisce una condizione necessaria per la convergenza di una serie geometrica. 
Si considera per ipotesi che una data serie numerica converge, questo equivale a dire che la serie delle somme parziali converge:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty a_k\rightarrow s_n=\sum_{k=1}^n a_k:\mbox{converge}\\
    \lim_{n\to\infty}s_n=s
\end{gather*}

Considerando il limite della successione generata aumentando l'indice di uno: $n+1$, la differenza tra queste due successioni converge a zero, poiché rappresentano la stessa successione traslata di un elemento:
\begin{gather*}
    \lim_{n\to\infty}s_{n+1}=s\\
    \lim_{n\to\infty}(s_{n+1}-s_n)=0
\end{gather*}
La successione $s_{n+1}$ corrisponde alla prima successione $s_n$ sommata ad un ulteriore elemento $a_{n+1}$, per cui si può riscrivere la loro differenza come:
\begin{gather*}
    s_{n+1}=s_n+a_{n+1}\\
    s_{n+1}-s_{n}=a_{n+1}
\end{gather*}
Quindi la successione può convergere se il termine infinitesimo della serie converge:
\begin{equation}
    \lim_{n\to\infty}a_{n+1}=0
\end{equation}
Queste rappresenta solo una condizione necessaria, non garantisce che una serie converga, non è una condizione sufficiente. 
Se il termine infinitesimo di una serie non converge, allora la serie non può convergere, quindi diverge oppure è irregolare. 

\subsubsection{Teorema Per Serie Monotone (De)Crescenti}

Esiste un teorema che tratta le successioni numeriche, e si riflette sulle serie. Questo teorema afferma che data una successione monotona crescente $\{a_k\}\uparrow$ o decrescente $\{a_k\}\downarrow$, ovvero se tra il termine $a_k$ ed il termine $a_{k+1}$ esiste definitivamente una relazione d'ordine, $\forall k\geq k_0$. Allora la successione non può essere irregolare. 

Sia una serie $\sum_{k=0}^\infty a_k$, se $\forall k\geq k_0$ si ha $a_k>0$, allora la serie non è irregolare. Considerando un valore di $n\geq k_0$, si ha:
\begin{gather*}
    s_{n+1}=s_n+\overbrace{a_{n+1}}^{>0}\implies s_{n+1}>s_n
\end{gather*}

Poiché viene sommato ad $s_n$ un valore non nullo positivo, quindi una serie di termini di segno costante positivo corrisponde ad una successione di somme parziali definitivamente monotona crescente. Questa serie allora converge o diverge, è regolare. 

\subsubsection{Proprietà di Linearità}

Si considerano due serie $\sum a_k$ e $\sum b_k$, convergenti rispettivamente a $\alpha$ e $\beta$, la serie combinazione lineare delle due serie $\sum(Aa_k+Bb_k)$ allora converge al valore $A\alpha+B\beta$. Tramite questa proprietà è possibile scomporre una serie ed analizzare i singoli termini per determinare il carattere della serie da cui derivano. Se una delle due diverge, mentre l'altra converge, allora la serie combinazione lineare diverge, allo stesso segno della serie divergente, per qualunque valore di $A$ e $B$, vale anche se entrambe le serie convergono ad infinito di segno concorde. Se invece entrambe le serie divergono ed il segno discorde, allora questo genera una forma indeterminata e quindi non è possibile determinare il comportamento della serie combinazione lineare. 

\subsubsection{Criterio del Confronto}

Siano $\sum_{k=1}^\infty a_k$ e $\sum_{k=1}^\infty b_k$ due serie di segno definitivamente costante tale che vale la seguente condizione: $\forall k\geq k_0$ allora $0<a_k\leq b_k$. Allora se la serie maggiorante $\sum_{k=1}^\infty b_k$ converge, allora si dimostra che anche la serie minorante $\sum_{k=1}^\infty a_k$ converge. Analogamente vale il duale di questa proprietà se la serie minorante $\sum_{k=1}^\infty a_k$ diverge, allora anche la serie maggiorante $\sum_{k=1}^\infty b_k$ diverge.

\subsubsection{Criterio della Radice}

Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si basa sulla definizione di una successione ausiliaria. Per costruire questa successione ausiliaria si considera, da $k>k_0$, $\{\sqrt[k]{|a_k|}\}$. Si considera per ipotesi che questa successione sia regolare:
\begin{equation*}
    \lim_{k\to\infty}\sqrt[k]{|a_k|}=\Lambda
\end{equation*}

Se questo limite converge ad un valore positivo maggiore di uno, oppure diverge ad infinito positivo, allora è dimostrabile che la serie di partenza diverge. 
Se questo limite è positivo e minore di uno, allora la serie converge. Mentre se il limite è esattamente pari ad uno, allora il problema rimane aperto, e non è possibile stabilire il comportamento della serie tramite questa successione. 

\begin{equation}
    \displaystyle\sum_{k=1}^\infty a_k:\begin{cases}
        \text{diverge}&\Lambda > 1\,\lor\Lambda=+\infty\\
        \text{converge}&0\leq\Lambda<1\\
        ?&\Lambda=1
    \end{cases}
\end{equation}

\subsubsection{Criterio del Rapporto}

Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si basa sulla definizione di una successione ausiliaria. Per costruire questa successione ausiliaria si considera, da $k>k_0$:
\begin{equation*}
    \displaystyle\left\{\frac{a_{k+1}}{a_k}\right\}
\end{equation*}
Si considera per ipotesi che questa successione sia regolare, quindi converge a $\Lambda$
\begin{equation*}
    \lim_{k\to\infty}\displaystyle\frac{a_{k+1}}{a_k}=\Lambda
\end{equation*}

Esistono casi dove la successione ausiliaria creata è irregolare, e quindi non è possibile utilizzare questi criteri. 
Analogamente al criterio precedente, in base al valore del limite la serie diverge, converge, oppure non è possibile determinarne il carattere:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty a_k:\begin{cases}
        \text{diverge}&\Lambda > 1\,\lor\Lambda=+\infty\\
        \text{converge}&0\leq\Lambda<1\\
        ?&\Lambda=1
    \end{cases}
\end{equation}

\subsubsection{Criterio dell'Integrale}

Sia una serie definitivamente monotona crescente $\sum_{k=1}^\infty a_k,\,\forall k\geq k_0$. 
Si considera la funzione associata che sostituisce la serie: $\{a_k\}\rightarrow\{f(x)\}$. La funzione associata deve essere decrescente a partire da $k_0$: $f(x)\downarrow \forall x>k_0$. Sia:
\begin{equation*}
    t_n=\displaystyle\int_{k_0}^n f(x)\mathrm{d}x
\end{equation*}

Allora la successione definita su $t_n$: $\{t_n\}$ e la serie $\sum a_k$ hanno lo stesso carattere. 
Si applica il criterio dell'integrale sulla serie armonica generalizzata, questa soddisfa l'ipotesi da $k_0=1$:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k^\alpha},\,\alpha\in\mathbb{R}\\
    f(x)=\displaystyle\frac{1}{x^\alpha}
\end{gather*}
Se $\alpha$ fosse negativo, la funzione associata sarebbe monotona crescente, ma la serie sarebbe $\sum k^{|\alpha|}$, per cui divergerebbe. 
Per $\alpha=0$, tutti i termini della serie sono pari ad uno, quindi il termine generico è uno e la serie diverge allo stesso modo. Solo per $\alpha>0$ la serie converge, e quindi solo per questo caso ha senso lo studio della serie armonica generalizzata. 

Nel caso $\alpha>0$ la condizione necessaria è soddisfatta, quindi la funzione potrebbe convergere. Si studia il suo carattere con il criterio dell'integrale, si ha la seguente serie ausiliaria:
\begin{gather*}
    t_n=\displaystyle\int_{1}^n\frac{1}{x^\alpha}\mathrm{d}x=\begin{cases}
        \bigg|\ln(x)\bigg|_1^n &\alpha=1\\
        \displaystyle\frac{1}{1-\alpha}\bigg|x^{1-\alpha}\bigg|_1^n&\alpha\neq1
    \end{cases}=\begin{cases}
        \ln(n)&\alpha=1\\
        \displaystyle\frac{1}{1-\alpha}\left(n^{1-\alpha}-1\right)&\alpha\neq1
    \end{cases}
\end{gather*}

Per $\alpha=1$, la successione diverge, poiché il logaritmo è una funzione monotona crescente e non soddisfa la condizione necessaria di convergenza, mentre per $\alpha\neq1$:
\begin{gather*}
    \displaystyle\frac{1}{1-\alpha}\lim_{n\to\infty}\left(n^{1-\alpha}-1\right)=\begin{cases}
        +\infty&\alpha<1\\
        \displaystyle\frac{1}{1-\alpha}&\alpha>1
    \end{cases}
\end{gather*}
La serie diverge per $\alpha<1$, mentre converge per $\alpha>1$. 
Il carattere della serie armonica generalizzata è quindi dato dal seguente:
\begin{equation}
    \displaystyle\sum_{k=1}^\infty\frac{1}{k^\alpha}:\begin{cases}
        \text{diverge}&\alpha\le1\\
        \text{converge}&\alpha>1        
    \end{cases}
\end{equation}


Conviene applicare il criterio dell'integrale quando la funzione associata è facilmente integrabile. 

\subsubsection{Criterio di Condensazione}

Sia una serie di segno definitivamente positivo: $\sum_{k=1}^\infty a_k | a_k>0\,\forall k\geq k_0$. Si considera la serie monotona decrescente $a_k\downarrow$; allora la serie definita come:
\begin{equation}
    \sum_{k=1}^{\infty} 2^ka_{2^k}   
\end{equation}
Ha lo stesso carattere della serie di partenza. Generalmente si applica solo nel caso dove in $a_k$ è presente un fattore logaritmo di $k$. 

\subsubsection{Criterio del Confronto Asintotico}

In questo criterio si considerano due serie, entrambe a termini definitivamente positivi $\sum_{k=1}^\infty a_k$ e $\sum_{k=1}^\infty b_k$ con $a_k>0,\,b_k>0\,\forall k\geq k_0$. Allora se il limite del rapporto dei termini generici di queste due serie converge ad un numero reale non nullo, le due serie hanno lo stesso carattere:
\begin{gather*}
    \lim_{k\to\infty}\frac{a_k}{b_k}=l\neq0\in\mathbb{R}
\end{gather*}
Se $l=1$ allora le due successioni, analogamente per le funzioni, si dicono asintoticamente equivalenti per $k\to\infty$: $a_k\sim b_k$. 
Spesso si userà questo simbolo generalizzandolo come due funzioni asintoticamente equivalenti a meno di una costante, poiché è di interesse solamente il carattere e non il valore effettivo di una serie. 
Se invece il rapporto converge a zero e la serie $\sum b_k$ converge, allora anche la serie $\sum a_k$ converge, ovvero $a_k$ è un infinitesimo di ordine superiore a $b_k$. 
Se invece il limite di questo rapporto tende ad infinito, e la serie $\sum b_k$ diverge, allora divergerà anche la serie $\sum a_k$, $b_k$ è un infinitesimo di ordine superiore di $a_k$. 

Per confrontare funzioni fattoriali si considera la formula di Stirling, afferma che un fattoriale di un numero intero si comporta al limite per $k\to\infty$ come:
\begin{gather*}
    \displaystyle\lim_{k\to\infty}\frac{k!}{\sqrt{2k\pi}\left(\frac{k}{e}\right)^k}=1\\
    k!\sim\sqrt{2k\pi}\left(\frac{k}{e}\right)^k\tageq
\end{gather*}

\subsubsection{Criterio di Leibniz}

Il criterio di Leibniz è relativo a serie numeriche con termini di segno alterno, una prima famiglia di serie a termini di segno alterno permette di calcolarne il carattere, per altre invece non può essere determinato. Considerata una serie con $a_k>0\,\forall k>k_0$, si esprime il fattore che rende la serie alterna:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty(-1)^ka_k
\end{gather*}

Il criterio di Leibniz suppone di avere una serie del genere, siano i termini della serie decrescenti, tendenti a 0: $\{a_k\}\downarrow0$, allora la serie converge. 

Detta $s$ la somma della serie:
\begin{gather*}
    s=\displaystyle\sum_{k=0}^\infty(-1)^ka_k
\end{gather*}

All'aumentare di $n$, la somma $s_n$ dei primi $n$ elementi della serie, la serie oscilla sorpassando in positivo o in negativo la somma $s$, di valori sempre più piccoli, convergendo al valore $s$:
%% TODO asse reale con S1, S2, ... S oscillazione
\begin{gather*}
    |s-s_1| < |s_1-s_2|\\
    |s-s_n| \leq |s_n-s_{n-1}|=|a_n|
\end{gather*}

La somma $s_n$ si posiziona al lato opposto di $s_{n-1}$ e si trova ad una posizione più vicina alla somma $s$ rispetto al precedente, quindi ha una distanza minore. 

\subsubsection{Criterio della Convergenza Assoluta}

Il criterio di Leibniz si può utilizzare solo quando le serie hanno segno alterno, mentre, per altri tipo di serie in cui il segno non è né definitivamente positivo, o negativo, e né alterno, è necessario un altro criterio per poterne determinarne il carattere. 

Un criterio generale consiste nell'analizzare il carattere della serie $|a_k|$, questa serie risultante è a termini di segno costante positivo:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty|a_k|
\end{gather*}

Un teorema dimostrabile afferma che se una serie ha termini di segno non costante $\sum a_k$, se la serie formata mettendo in valore assoluto i termini della prima $\sum|a_k|$ converge, allora converge anche la serie iniziale. Si dice che converge in modo assoluto, o assolutamente. 

Se la serie $\sum a_k$ converge assolutamente, allora la serie converge semplicemente, la convergenza studiata con i criteri precedenti. 

\subsection{Serie di Potenze}

In generale una serie di potenza viene espressa, partendo da 0 o 1, come:
\begin{gather}
    \displaystyle\sum_{k=0}^\infty a_k(x-x_0)^k
\end{gather}
Con $x_0\in\mathbb{R}$, si dice serie di potenze con centro in $x_0$. Le serie di potenze sono molto importanti e di facile analisi, anche se il calcolo del loro limite non è triviale. 

Quando si analizzano serie di potenze si parla di intervallo di convergenza, poiché si analizza per quali valori del parametro $x$ la serie converge. Una serie geometrica è una particolare serie di potenze centrata in $x_0=0$, con $a_k=1$ per ogni valore di $k$, di cui si conosce anche la somma, per valori del parametro $x\in(-1,1)$:
\begin{gather*}
    \displaystyle\sum_{k=1}^\infty x^k=\frac{1}{1-x}
\end{gather*}

Tutte le volte che si ha una serie di potenze, la prima cosa che bisogna calcolare è il cosiddetto raggio di convergenza. La sua definizione è molto più ampia, ma studiando casi particolari non sarà necessario approfondirlo. Per calcolarlo si introduce una successione ausiliaria:
\begin{gather*}
    \left\{\displaystyle\left|\frac{a_k}{a_{k+1}}\right|\right\}
\end{gather*}
Questa serie si riferisce al criterio del rapporto, alternativamente si può usare la serie ausiliaria del criterio della radice:
\begin{gather*}
    \left\{\displaystyle\frac{1}{\sqrt[k]{a_k}}\right\}
\end{gather*}
Bisogna dare per ipotesi che queste successioni siano regolari, per $k\to\infty$. Questo valore $R$ si trova calcolando il limite per $k\to\infty$ di una di queste due successioni:
\begin{equation}
    R=\lim_{k\to\infty}\displaystyle\left|\frac{a_k}{a_{k+1}}\right|=\lim_{k\to\infty}\frac{1}{\sqrt[k]{a_k}}=\begin{cases}
        +\infty\\
        0\\
        l\in\mathbb{R}^+
    \end{cases}
\end{equation}

Se il limite esiste assume uno di questi tre possibili valori. Una volta determinato il raggio di convergenza, esiste un teorema che stabilisce dove questa serie risulta sicuramente convergente. 

Sia $R$ il raggio di convergenza della serie di potenze $a_k$ con centro in $x_0$: $\sum a_k(x-x_0)^k$. Allora si può affermare:
\begin{enumerate}
    \item Se $R=0$, la serie converge solo nel centro $x_0$. 
    \item Se $R=+\infty$, la serie converge in $\mathbb{R}$, ovvero qualunque sia il valore reale del parametro $x$. 
    \item Se $R\in\mathbb{R}^+$, finito positivo e diverso da zero, la serie converge assolutamente, e quindi semplicemente, in $(x_0-R, x_0+R)$. Inoltre la serie non converge nell'intervallo $(-\infty,x_0-R)$ e $(x_0+R, +\infty)$. 
\end{enumerate}

$x_0$ rappresenta il centro dell'intervallo di convergenza, se il raggio è zero, contiene solo il centro, se è infinito, contiene tutti i numeri reali. 
Per determinare il valore al limite dell'intervallo $x=x_0\pm R$, bisogna sostituire questo valore ad $x$ e studiare per via diretta il carattere della serie risultante. Per questo si distingue tra intervallo di convergenza ed insieme di convergenza, poiché potrebbero non coincidere, potrebbero comprendere gli estremi. Coincidono solo se ai valori estremi la serie non converge. 

\subsubsection{Teorema della Serie Derivata e Integrale}

Sia una serie di potenze con centro $x_0$:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty a_k(x-x_0)^k
\end{gather*}
Tale che il raggio di convergenza è un numero reale positivo, oppure diverge ad infinito: $R\in\mathbb{R}^+$ o $R=+\infty$. 
Allora per ogni valore nell'intervallo di convergenza centrato in $x_0$: 
$\forall x\in I_R(x_0)$, la funzione somma è di classe $S(x)\in C^{\infty}(I_R(x_0))$, quindi è derivabile infinite volte, e tutte le sue derivate sono funzioni continue. La derivata rispetto alla variabile $x$ della somma è:
\begin{gather}
    \forall x \in I_R(x_0)\implies\displaystyle\frac{\mathrm{d}}{\mathrm{d}x}S(x)=
    \frac{\mathrm{d}}{\mathrm{d}x}\sum_{k=0}^\infty a_k(x-x_0)^k=
    \sum_{k=0}^\infty a_k\frac{\mathrm{d}}{\mathrm{d}x}(x-x_0)^k=
    \sum_{k=1}^\infty a_kk(x-x_0)^{k-1}
\end{gather}
Il termine con $k=0$ è costante per cui la serie parte da $k=1$.
Oltre a poter derivare termine a termine è possibile integrare termine a termine della funzione somma:
\begin{gather*}
    \forall x\in I_R(x_0)\implies\displaystyle\int_{x_0}^xS(t)\mathrm{d}t=\int_{x_0}^x\sum_{k=0}^\infty a_k(t-x_0)^k\mathrm{d}t=\sum_{k=0}^\infty a_k\int_{t_0}^x(t-x_0)^k\mathrm{d}t\\
    \displaystyle\int_{x_0}^xS(t)\mathrm{d}t=
    \sum_{k=0}^\infty a_k\frac{t-x_0}{k+1}^{k+1}\tageq
\end{gather*}
L'integrale della somma è uguale alla serie degli integrali, analogamente alla derivata. 

\subsubsection{Espansione in Serie}

Si vogliono approssimare funzioni come la somma di una serie parametriche rispetto ad una fattore $x$, che diventerà la variabile indipendente della funzione. Una funzione algebrica si può rappresentare come una certa serie, dimostrato nel caso di una serie telescopica e geometrica. Per serie di segno definitivamente positivo è possibile rappresentarle in forma esplicita, mentre per serie che non rispettano questa condizione, molto probabilmente non è possibile, quindi non è possibile ottenere una rappresentazione algebrica di queste. 

Per ogni $x$ nell'intervallo $(-1,1)$ si è dimostrato per via diretta che la funzione definita in $\mathbb{R}\setminus\{1\}$: $(1-x)^{-1}$ si può esprimere come una serie di potenze con raggio di convergenza uno e centro nell'origine:
\begin{gather}\label{eq:1}
    \forall x\in(-1,1)\implies\displaystyle\frac{1}{1-x}=\sum_{k=0}^\infty x^k
\end{gather}
Si considera nell'intervallo $I_1(0)$ l'integrale di questa funzione, per il teorema appena enunciato si può esprimere come la somma di integrali, effettuando il passaggio sotto il segno dell'integrale alla sommatoria: 
\begin{gather*}
    \forall x \in I_1(0)\implies\displaystyle\int_{0}^x\frac{1}{1-t}\mathrm{d}t=
    \sum_{k=0}^\infty\int_{0}^x t^k\mathrm{d}t=
    \sum_{k=0}^\infty\frac{t^{k+}1}{k+1}\bigg|_{0}^x=
    \sum_{k=0}^\infty\frac{x^{k+1}}{k+1}=\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather*}
Calcolando l'integrale direttamente si ottiene: 
\begin{gather*}
    \forall x\in(-1,1)\implies\displaystyle\int_0^x\frac{1}{1-t}\mathrm{d}t=-\ln(1-x)
\end{gather*}
Si è scoperto che se la $x$ è contenuta in questo intervallo dato lo sviluppo in serie di una funzione si ottiene anche lo sviluppo in serie dell'integrale della stessa:
\begin{gather*}
    \forall x\in I_1(0)\implies -\ln(1-x)=\displaystyle\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather*}
L'uguaglianza si può estendere all'estremo $-1$ per il criterio di Leibniz, ma non per $x=1$:
\begin{gather}
    \forall x\in [-1,1)\implies -\ln(1-x)=\displaystyle\sum_{k=1}^\infty\frac{x^k}{k}
\end{gather}

Effettuando il cambio di variabile $-x=u$, l'intervallo di convergenza diventa $u\in(-1, 1]$:
\begin{gather*}
    -\ln(1+u)=\displaystyle\sum_{k=1}^\infty\frac{(-u)^k}{k}=
    \displaystyle\sum_{k=1}^\infty(-1)^k\frac{u^k}{k}\\
    \ln(1+u)=-\displaystyle\sum_{k=1}^\infty(-1)^k\frac{u^k}{k}=
    \displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{u^k}{k}\\
    \forall x\in(-1,1]\implies\ln(1+x)=\displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{x^k}{k}\tageq
\end{gather*}

Considerando la prima espansione \ref{eq:1}, si effettua la sostituzione $x=-u^2$: 
\begin{gather*}
    -1<x<1\\
    -1<-u^2<1\\
    -u^2<1\,\forall u\in\mathbb{R}\implies u^2<1:\,-1<u<1\\
    u\in(-1,1)
\end{gather*}

La funzione e corrispondente serie diventa quindi:
\begin{gather*}
    \forall u\in(-1,1)\implies\displaystyle\frac{1}{1+u^2}=\sum_{k=0}^\infty(-u^2)^k=
    \sum_{k=0}^\infty(-1)^ku^{2k}
\end{gather*}
A questo punto si integra membro a membro e si scambia l'integrale sotto il segno della sommatoria:
\begin{gather*}
    \displaystyle\int_0^u\frac{1}{1+t^2}\mathrm{d}t=
    \int_0^u\sum_{k=0}^\infty(-1)^kt^{2k}\mathrm{d}t=
    \sum_{k=0}^\infty(-1)^k\int_0^ut^{2k}\mathrm{d}t=
    \sum_{k=0}^\infty(-1)^k\frac{u^{2k+1}}{2k+1}\\
    \arctan u=\sum_{k=0}^\infty(-1)^k\frac{u^{2k+1}}{2k+1}
\end{gather*}

Quindi l'arcotangente di $x$ nell'intervallo $(-1,1)$ si può esprimere come la seguente serie:
\begin{equation}
    \forall x\in(-1,1)\implies\arctan x=\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{2k+1}
\end{equation}
Bisogna comunque controllare se questa serie converge anche agli estremi dell'intervallo di convergenza. Per $x=1$ si ha:
\begin{gather*}
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^k}{2k+1}
\end{gather*}
Questa serie converge per il criterio di Leibniz poiché la serie ha termini strettamente decrescenti convergenti a zero; mentre per $x=-1$ si ha:
\begin{gather*}
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^k(-1)^{2k+1}}{2k+1}=
    \displaystyle\sum_{k=0}^{\infty}\frac{(-1)^{3k+1}}{2k+1}
\end{gather*}
Analogamente alla precedente vale il criterio di Leibniz quindi converge. L'identità diventa quindi:
\begin{equation}
    \forall x\in[-1,1]\,\arctan x=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{2k+1}
\end{equation}
Questa serie venne utilizzata per calcolare il valore di pi greco, considerando la serie per il valore $x=1$:
\begin{gather*}
    \arctan(1)=\displaystyle\frac{\pi}{4}=\displaystyle\sum_{k=0}^\infty\frac{(-1)^k}{2k+1}\\
    \pi=4\displaystyle\sum_{k=0}^\infty\frac{(-1)^k}{2k+1}
\end{gather*}
Con un indice molto elevato si può ottenere un'approssimazione molto accurata del pi greco. 

\subsubsection{Serie di Taylor}

Questa serie di potenze si può chiamare serie di Taylor. Data una funzione derivabile con continuità infinite volte $f\in C^\infty(I_R(x_0)) $, la sua serie di Taylor si definisce come la seguente:
\begin{equation}
    \displaystyle\sum_{k=0}^\infty\frac{f^{(k)}(x_0)}{k!}(x-x_0)
\end{equation}

Per certe funzioni, e certi intervalli, si può estendere il grado del polinomio di Taylor fino all'infinito. L'espansione di Maclaurin si può ottenere dalla serie di Taylor, ponendo $x_0=0$.

Il polinomio di Maclaurin della funzione esponenziale è la seguente serie:
\begin{gather}
    e^x=\displaystyle\sum_{k=0}^n\frac{x^k}{k!}+o[x^n]
\end{gather}
Si può dimostrare che tendendo $n\to\infty$ la serie di Maclaurin ottenuta continua a coincidere alla serie esponenziale. Si vuole dimostrare lo sviluppo in serie dell'esponenziale. 
Partendo dalla serie di potenze si cattura il suo raggio di convergenza:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}\\
    R=\lim_{k\to\infty}\displaystyle\left|\frac{a_k}{a_{k+1}}\right|=
    \lim_{k\to\infty}\frac{1}{\cancel{k!}}(k+1)\cancel{!}=\lim_{k\to\infty}{k+1}=+\infty
\end{gather*}
Essendo il raggio di convergenza infinito, la serie converge in $\mathbb{R}$:
\begin{gather*}
    \forall x\in\mathbb{R}:\, S(x)=\displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}
\end{gather*}
Si vuole dimostrare che la somma di questa serie $S(x)$ coincide all'esponenziale $e^x$. Si applica il teorema della derivata di una serie:
\begin{gather*}
    \displaystyle\frac{\mathrm{d}}{\mathrm{d}x}S(x)=\frac{\mathrm{d}}{\mathrm{d}x}\sum_{k=0}^\infty\frac{x^k}{k!}=
    \displaystyle\sum_{k=1}^\infty\frac{1}{k!}\frac{\mathrm{d}}{\mathrm{d}x}x^k=
    \sum_{k=1}^\infty x^{k-1}\frac{\cancel{k}}{\cancel{k}(k-1)!}=
    \displaystyle\sum_{k=1}^\infty\frac{x^{k-1}}{(k-1)!}
\end{gather*}
La serie della derivata parte da $k=1$, poiché il primo addendo $a_0$ è costante e nel passaggio della derivata si annulla. 
\begin{gather*}
    S'(x)=\displaystyle\sum_{k=1}^\infty\frac{x^{k-1}}{(k-1)!}=
    \displaystyle\sum_{k=0}^\infty\frac{x^{k}}{k!}=S(x)
\end{gather*}

La derivata prima di questa funzione coincide con la funzione di partenza, a meno di una costante, per ogni $x\in\mathbb{R}$. Inoltre si ha che $S(0)=1$, questo rappresenta un problema di Cauchy, risolvendolo si ottiene la funzione $S(x)$:
\begin{gather*}
    \begin{cases}
        S'(x)=S(x)&\forall x\in\mathbb{R}\\
        S(0)=1
    \end{cases}\\
    \displaystyle\frac{S'(x)}{S(x)}=1\implies\int_0^x\frac{\df S(t)}{S(t)}=x\\
    \ln|S(t)|\bigg|_0^x=x\implies \ln|S(x)|-\cancelto{0}{\ln|S(0)|}=x\\
    S(x)=e^x
\end{gather*}
Per cui si è dimostrato che la funzione somma $S(x)$ è la funzione esponenziale, e si è definita la sua espansione:
\begin{equation}
    \forall x\in\mathbb{R}\implies\,e^x=\displaystyle\sum_{k=0}^\infty\frac{x^k}{k!}
\end{equation}

Si considera l'espansione di Maclaurin della funzione coseno:
\begin{gather*}
    \cos x=\displaystyle\sum_{k=0}^n(-1)^k\frac{x^{2k}}{(2k)!}+o[x^{2n}]
\end{gather*}
Si effettua un procedimento analogo, partendo dalla serie, tendendola all'infinito, e ci si aspetta che $o[x^{2n}]$ tende a zero. Si dimostra che la somma di questa serie $S(x)$ non può essere altro che la funzione coseno. 
Si determina il raggio di convergenza della serie:
\begin{gather*}
    \displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k}}{(2k)!}=S(x)\\
    %% TODO calcolo del raggio
    R=+\infty
\end{gather*}

Analogamente all'esponenziale la serie converge per $\forall x\in\mathbb{R}$. Si deriva membro a membro l'equazione:
\begin{gather*}
    S'(x)=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{\mathrm{d}}{\mathrm{d}x}\frac{x^{2k}}{(2k)!}=
    \sum_{k=1}^\infty(-1)^k\frac{\cancel{2k}}{\cancel{2k}}\frac{x^{2k-1}}{(2k-1)!}
\end{gather*}
Analogamente all'esponenziale il termine $a_0$ è una costante, quindi si annulla e la serie parte da $k=1$. Questa serie rappresenta, a meno del segno, lo sviluppo in serie del seno. Si deriva nuovamente membro a membro e si ottiene la seguente:
\begin{gather*}
    S''(x)=\displaystyle\sum_{k=1}^\infty(-1)^k\frac{\cancel{2k-1}}{\cancel{2k-1}}\frac{x^{2k-2}}{(2k-2)!}
\end{gather*}
Si effettua una traslazione, per impostare il valore iniziale a $k=0$, $k-1=n$:
\begin{gather*}
    S''(x)=\displaystyle\sum_{k=1}^\infty(-1)^{k+1}\frac{x^{2k-2}}{(2k-2)!}=
    -\sum_{n=0}^\infty(-1)^{n+1}\frac{x^{2n}}{(2n)!}=-S(x)
\end{gather*}
La seconda derivata della funzione iniziale coincide alla funzione stessa, quindi la funzione è o un coseno o un seno, le uniche due funzioni che rispettano questa condizione. Inoltre deve soddisfare $S(0)=1$, e solo la funzione coseno rispetta questo problema di Cauchy:
\begin{gather*}
    \begin{cases}
        S''(x)=-S(x)&\forall x\in\mathbb{R}\\
        S(0)=1
    \end{cases}
\end{gather*}

Quindi la funzione coseno si può esprimere nell'intero asse reale con la seguente espansione:
\begin{equation}
    \forall x\in\mathbb{R}:\cos x=\displaystyle\sum_{k=0}^\infty (-1)^k\frac{x^{2k}}{(2k)!}
\end{equation}

Si può dimostrare allo stesso modo l'espansione del seno sull'intero asse dei reali, partendo dalla sua espansione di Maclaurin:
\begin{gather*}
    \sin x =\sum_{k=0}^n(-1)^k\frac{x^{2k+1}}{(2k+1)!}+o[x^{2n+1}]
\end{gather*}
Si tende all'infinito, quindi l'infinitesimo $o[x^{2n+1}]$ tende a zero. Si considera la funzione somma della serie $S(x)$, e si determina il raggio di convergenza della serie:
\begin{gather*}
    S(x)=\sum_{k=0}^\infty (-1)^k\frac{x^{2k+1}}{(2k+1)!}\\
    R=\lim_{k\to\infty}\frac{(2(k+1)+1)!}{(2k+1)!}=+\infty
\end{gather*}
L'intervallo di convergenza coincide all'asse dei reali $\mathbb{R}$. Si applica il teorema della derivata della serie:
\begin{gather*}
    S'(x)=\sum_{k=0}^\infty(-1)^{k}\frac{x^{2k}}{(2k)!}
\end{gather*}
Questa coincide all'espansione della funzione coseno. Si deriva nuovamente e si applica un cambio di variabile, si trasla la serie per partire da 0, $k-1=u$:
\begin{gather*}
    S''(x)=\sum_{k=1}^\infty(-1)^k\frac{x^{2k-1}}{(2k-1)!}=-\sum_{u=0}^\infty(-1)^{u}\frac{x^{2u+1}}{(2u+1)!}=-S(x)
\end{gather*}
Si esprime il problema di Cauchy:
\begin{gather*}
    \begin{cases}
        S''(x)=-S(x)\\
        S(0)=0
    \end{cases}
\end{gather*}
L'unica funzione che rispetta questo problema di Cauchy è la funzione seno, quindi si è dimostrato che la funzione seno può essere espressa come la seguente serie:
\begin{gather}
    \forall x\in\mathbb{R}:\sin x=\displaystyle\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{(2k+1)!}
\end{gather}

\clearpage

\section{Integrali Impropri e Serie di Fourier}
\label{sec:int-1}
Prima di trattare la serie di Fourier, un altro metodo per esprimere funzioni tramite serie, oltre la serie di Taylor, è necessario conoscere gli integrali impropri. 

\subsection{Integrali Impropri di Seconda Specie}

L'unica ipotesi per cui si definisce un integrale proprio su intervallo $[a,b]$ di una funzione $f$ è che sia continua nell'intervallo. Si dimostra che l'integrale è definito:
\begin{gather*}
    \displaystyle\int_a^b f(x)\mathrm{d}x
\end{gather*}

Si vuole allentare l'ipotesi per considerare intervalli con una o più discontinuità. Sia una funzione $f$ continua e limitata in $[a,b)$, 
Per definire in termini più generali il concetto di integrale, con un punto di non continuità, si considera un intorno infinitesimo di $b$, ed agli estremi di questo interno $b-\varepsilon$, la funzione è continua: $[a,b-\varepsilon]$. In questo modo si rimuove la singolarità e si può definire l'integrale come:
\begin{gather*}
    \displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x
\end{gather*}
Ottenuta una funzione in termini di $\varepsilon$, si calcola il valore del limite per $\varepsilon\to0^+$, sotto queste ipotesi si dimostra che questo limite esiste ed è finito:
\begin{gather}
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x=\int_a^bf(x)\mathrm{d}x
\end{gather}
Si poteva scegliere come punto di discontinuità $a$ oppure un punto intermedio, si può sempre utilizzare la proprietà di additività degli integrali. 
Si allenta ulteriormente l'ipotesi, si suppone che la funzione $f$ sia continua ed illimitata nell'intervallo $[a,b)$.  

Analogamente si toglie l'intorno sinistro di $b$, e si forma un'intervallo dove la funzione è continua $[a, b-\varepsilon]$, si calcola in seguito l'integrale in funzione di $\varepsilon$ in questo intervallo. Per ottenere il valore dell'integrale sull'intervallo $[a,b]$ si calcola il valore del limite per $\varepsilon\to0^+$. 
Rinunciando all'ipotesi di limitatezza, non è più garantito che l'integrale sia definito, potrebbe esistere finito o infinito, oppure irregolare:
\begin{gather}
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}f(x)\mathrm{d}x=
    \begin{cases}
        l=\displaystyle\int_a^bf(x)\mathrm{d}x\in\mathbb{R}\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{gather}
Nel primo caso l'integrale è convergente al valore $l$, la funzione $f$ si dice integrabile in senso improprio nell'intervallo $[a,b]$; oppure in senso equivalente, l'integrale improprio della funzione $f$ è convergente. Questo integrale si dice integrale improprio della seconda specie. Nel secondo caso è divergente ad infinito, la funzione non è integrabile in senso improprio, l'integrale improprio di seconda specie diverge. Nell'ultimo caso l'integrale oscilla ed il limite non esiste, l'integrale improprio di seconda specie è irregolare. 

Segue il seguente teorema:
\begin{quotation}
    Sia $f$ una funzione continua ed illimitata in $[a,b)$, inoltre sia $f(x)\geq0$, o $\leq0$, nell'intorno sinistro del punto singolare $(b-\varepsilon, b)$. Allora l'integrale improprio di seconda specie su $f(x)$ in questo intervallo è regolare. 
\end{quotation}

\subsubsection{Integrali Impropri Notevoli}

Calcolare al variare del parametro reale $\alpha\in\mathbb{R}$ la convergenza del seguente integrale:
\begin{gather*}
\displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}    
\end{gather*}
Se $\alpha<0$ l'integrale converge, poiché diventa un integrale classico, se $\alpha=0$, l'integrale converge, poiché è costante. Diventa un'integrale improprio di seconda specie per $\alpha>0$, poiché $b$ diventa un punto singolare. In un caso si applica la regola delle potenze, mentre per $\alpha=1$ si ha: 
\begin{gather*}
    \displaystyle\int_a^b\frac{\mathrm{d}x}{b-x}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}\frac{\mathrm{d}x}{b-x}=
    \lim_{\varepsilon\to0^+}\left\{-\ln(b-x)\bigg|_a^{b-\varepsilon}\right\}=
    -\lim_{\varepsilon\to0^+}\left\{\ln(\varepsilon)-\ln(b-a)\right\}=+\infty
\end{gather*}
Quindi l'integrale diverge per $\alpha=1$, la funzione non è integrabile in questo intervallo per questo valore del parametro reale $\alpha$.

Per $\alpha\neq1$:
\begin{gather*}
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}\frac{\mathrm{d}x}{(b-x)^{\alpha}}=
    \lim_{\varepsilon\to0^+}\displaystyle\int_a^{b-\varepsilon}(b-x)^{-\alpha}\mathrm{d}x=
    -\lim_{\varepsilon\to0^+}\int_a^{b-\varepsilon}(b-x)^{-\alpha}\mathrm{d}(b-x)\\
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=
    -\lim_{\varepsilon\to0^+}\left\{\frac{(b-x)^{1-\alpha}}{1-\alpha}\bigg|_a^{b-\varepsilon}\right\}=
    \frac{\lim_{\varepsilon\to0^+}\left\{\varepsilon^{1-\alpha}-(b-a)^{1-\alpha}\right\}}{\alpha-1}\\
    \lim_{\varepsilon\to0^+}\varepsilon^{1-\alpha}=\begin{cases}
        0&1-\alpha>0\\
        +\infty&1-\alpha<0
    \end{cases}\\
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(b-x)^\alpha}=\begin{cases}
        \displaystyle\frac{(b-a)^{1-\alpha}}{1-\alpha}&\alpha<1\\
        +\infty&\alpha=1\\
        -\infty&\alpha>1
    \end{cases}\tageq
\end{gather*}
L'integrale improprio di seconda specie converge se $\alpha<1$, e diverge ad infinito se $\alpha\geq1$. 


Calcolare al variare del parametro reale $\alpha\in\mathbb{R}$ la convergenza del seguente integrale:
\begin{gather*}
    \displaystyle\int_a^b\frac{\mathrm{d}x}{(x-a)^\alpha}    
\end{gather*}
Analogamente al precedente, converge per $\alpha\leq0$, mentre per $\alpha=1$ diventa:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\int_{a+\varepsilon}^b\frac{\df x}{x-a}=\lim_{\varepsilon\to0^+}\left\{\ln(x-a)\bigg|_{a+\varepsilon}^b\right\}=\lim_{\varepsilon\to0^+}\ln(b-a)-\ln(\varepsilon)=+\infty
\end{gather*}
Quindi diverge, mentre per $\alpha\neq1$:
\begin{gather*}
    \lim_{\varepsilon\to0^+}\int_{a+\varepsilon}^b\frac{\mathrm{d}x}{(x-a)^\alpha}=\frac{1}{1-\alpha}\lim_{\varepsilon\to0^+}\left\{(x-a)^{1-\alpha}\bigg|_{a+\varepsilon}^b\right\}=\frac{1}{1-\alpha}\lim_{\varepsilon\to0^+}\left\{(b-a)^{1-\alpha}-\varepsilon^{1-\alpha}\right\}\\
    \lim_{\varepsilon\to0^+}\varepsilon^{1-\alpha}=\begin{cases}
        0&\alpha<1\\+\infty&\alpha>1
    \end{cases}\\
    \int_a^b\frac{\df x}{(x-a)^\alpha}=\begin{cases}
        \displaystyle\frac{\strut(b-a)^{1-\alpha}}{\strut1-\alpha}&\alpha<1\\
        +\infty&\alpha=1\\
        -\infty&\alpha>1
    \end{cases}\tageq
\end{gather*}

\subsubsection{Criterio del Confronto}

Siano $f$ e $g$ due funzioni continue e illimitate in $[a, b)$, e sia $\forall x\in(b-\varepsilon, b)$ la funzione $f$ maggiorata dalla funzione $g$: $0\leq f(x)\leq g(x)$. 
Allora se l'integrale improprio della funzione maggiorante converge, allora converge anche l'integrale improprio della funzione minorante:
\begin{gather}
    \displaystyle\int_a^b g(x)\mathrm{d}x=\mathbb{R}\implies
    \displaystyle\int_a^b f(x)\mathrm{d}x=\mathbb{R}
\end{gather}
Inoltre se l'integrale improprio della funzione minorante diverge, allora anche l'integrale improprio della funzione maggiorante diverge. 
\begin{gather}
    \displaystyle\int_a^b f(x)\mathrm{d}x=\pm\infty\implies
    \displaystyle\int_a^b g(x)\mathrm{d}x=\pm\infty
\end{gather}

\subsubsection{Criterio del Confronto Asintotico}

Siano $f$ e $g$ continue e illimitate in $[a, b)$, e sia che $\forall x\in(b-\varepsilon, b)$ entrambe le funzioni $f(x)$ e $g(x)$ mantengano lo stesso segno: $f(x),g(x)\geq0$ o $f(x),g(x)\leq0$. 

Allora:
\begin{gather}
    \lim_{x\to b^-}\frac{f(x)}{g(x)}=l\in\mathbb{R}^+\implies \int_a^b f(x)\mathrm{d}x\land\int_a^b f(x)\mathrm{d}x:\mbox{hanno lo stesso carattere}
\end{gather}
Un caso particolare è che le due funzioni siano asintoticamente equivalenti: $f(x)\sim g(x)$, se questo è verificato allora gli integrali impropri di queste due funzioni hanno lo stesso carattere. Questa è una condizione parallela ed indipendente. 
Se invece il limite del rapporto per $x\to b^-$ è nullo ed inoltre, l'integrale sull'intervallo $[a,b)$ di $g(x)$ converge, allora converge anche l'integrale di $f(x)$:
\begin{gather}
    \displaystyle\lim_{x\to b^-}\frac{f(x)}{g(x)}=0\land\int_a^bg(x)\mathrm{d}x\in\mathbb{R}\implies\int_a^bf(x)\mathrm{d}x\in\mathbb{R}
\end{gather}
Invece se questo limite diverge ad infinito, e la funzione $g(x)$ non è integrabile in senso improprio, allora diverge anche l'integrale improprio della funzione $f(x)$:
\begin{gather}
    \displaystyle\lim_{x\to b^-}\frac{f(x)}{g(x)}=\pm\infty\land\displaystyle\int_a^bg(x)\mathrm{d}x=\pm\infty\implies\int_a^bf(x)\mathrm{d}x=\pm\infty
\end{gather}

\subsubsection{Criterio di Convergenza Assoluta}

Sia $f$ continua e illimitata in $[a, b)$; se il modulo della funzione $|f(x)|$ è integrabile in senso improprio in $[a,b]$, allora converge anche l'integrale in senso improprio della funzione $f(x)$ in $[a,b]$. Si dice che la funzione $f(x)$ è assolutamente integrabile, se l'integrale converge in modo assoluto allora converge anche in modo semplice. 

\begin{gather}
    \int_a^b |f(x)|\df x\in\mathbb{R}\implies\int_a^bf(x)\df x\in\mathbb{R}
\end{gather}

\subsection{Integrali Impropri di Prima Specie}

Sia la funzione $f$ continua in $[a,+\infty)$, allora ha senso parlare dell'integrale:
\begin{gather*}
    \displaystyle\int_a^hf(x)\mathrm{d}x
\end{gather*}
Per $h>a$, una volta calcolato questo integrale, per ottenere il valore dell'integrale improprio sull'intero intervallo $[a,+\infty)$ si calcola il limite per $h\to+\infty$:
\begin{gather}
    \lim_{h\to+\infty}\displaystyle\int_a^hf(x)\mathrm{d}x=\begin{cases}
        l=\displaystyle\int_a^{+\infty}f(x)\mathrm{d}x\in\mathbb{R}\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{gather}
Se il limite esiste, la funzione è integrabile in modo improprio nell'intervallo $[a,+\infty)$, analogamente l'integrale improprio di prima specie della funzione $f$ converge. Altrimenti il limite può non converge, oppure può essere irregolare e non esistere. 

\subsubsection{Integrali Impropri Notevoli}

Studiare la convergenza del seguente integrale, al variare del parametro reale $\alpha\in\mathbb{R}$, con $a>0$:
\begin{gather*}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}
\end{gather*}
Si considera il primo caso per $\alpha=1$:
\begin{gather*}
    \displaystyle\int_a^{+\infty}\frac{1}{x}\df x=\lim_{h\to\infty}\ln x\bigg|_a^h=\lim_{h\to\infty}(\ln h-\ln 0)=+\infty
\end{gather*}
Per $\alpha\neq1$:
\begin{gather*}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}=\lim_{h\to\infty}\int_a^{h}x^{-\alpha}\df x=\lim_{h\to\infty}\frac{x^{1-\alpha}}{1-\alpha}\bigg|_a^h=
    \frac{1}{1-\alpha}\lim_{h\to\infty}\left\{h^{1-\alpha}-a^{1-\alpha}\right\}
\end{gather*}
Si considera per quali esponenti si ha $h$ divergente o convergente a zero:
\begin{gather*}
    h^{1-\alpha}=\begin{cases}
        +\infty & \alpha<1\\
        0^+ & \alpha>1
    \end{cases}
\end{gather*}
Quindi l'integrale di partenza diventa:
\begin{gather}
    \intab{a}{+\infty}{\frac{1}{x^\alpha}}{x}=
    \begin{cases}
        +\infty& \alpha\leq1\\
        \displaystyle\frac{\strut a^{1-\alpha}}{\strut\alpha-1}&\alpha>1
    \end{cases}
\end{gather}


Si considera il seguente integrale notevole:
\begin{gather*}
    \displaystyle\int_{a}^{+\infty}\frac{\df x}{x^\alpha(\ln x)^\beta}
\end{gather*}
Può essere dimostrato, ma non verrà fatto, che questo converge se $\alpha>1$ e $\forall\beta\in\mathbb{R}$. Oppure converge sempre se $\alpha=1$ e $\beta>1$. Mentre l'integrale diverge a $+\infty$ se $\alpha<1$, qualunque sia $\beta$ reale: $\forall\beta\in\mathbb{R}$, oppure se $\alpha=1$ e $\beta\leq1$. 
\begin{gather}
    \displaystyle\int_{a}^{+\infty}\frac{\df x}{x^\alpha(\ln x)^\beta}=\begin{cases}
        l\in\mathbb{R}&\alpha>1\land\forall\beta\in\mathbb{R}\\
        l\in\mathbb{R}&\alpha=1\land\beta>1\\
        +\infty&\alpha=1\land\beta\leq1\\
        +\infty&\alpha<1\land\forall\beta\in\mathbb{R}
    \end{cases}    
\end{gather}

\subsubsection{Condizione Necessaria di Convergenza}

Sia $f$ continua nell'intervallo $[a,+\infty)$ e sia l'integrale improprio di prima specie su questo intervallo convergente, allora:
\begin{gather}
    \int_a^{+\infty}f(x)\df x\in\mathbb{R}\implies\lim_{x\to+\infty}f(x)=0
\end{gather}

\subsubsection{Teorema Regolarità dell'Integrale}

Sia $f$ continua nell'intervallo $[a,+\infty)$ e sia $f$ definitivamente non negativa $f(x)\geq0$ in $(\delta, +\infty)$, dove $\delta$ è un numero reale arbitrariamente grande. 
Allora l'integrale improprio della funzione $f(x)$ sull'intervallo $[a,+\infty)$ è regolare. 

\subsubsection{Criterio del Confronto}

Il criterio del confronto afferma le stesse nozioni enunciate nel criterio del confronto per integrali impropri di seconda specie. 
Siano $f$ e $g$ due funzioni continue nello stesso intervallo illimitato superiormente $[a,+\infty)$. E sia $f$ definitivamente maggiorata da $g$: $0\leq f(x)\leq g(x)$. 

Allora se l'integrale di $g(x)$ converge, allora converge anche l'integrale di $f(x)$, invece se l'integrale sulla funzione $f(x)$ diverge, anche l'integrale di $g(x)$ diverge:
\begin{gather}
    \int_a^{+\infty}g(x)\df x\in\mathbb{R}\implies\int_a^{+\infty}f(x)\df x\in\mathbb{R}\\
    \int_a^{+\infty}f(x)\df x=\pm\infty\implies\int_a^{+\infty}g(x)\df x=\pm\infty
\end{gather}

\subsubsection{Criterio del Confronto Asintotico}

Siano $f$ e $g$ due funzioni continue nello stesso intervallo illimitato superiormente $[a,+\infty)$. E siano definitivamente positive $f(x),\,g(x)\geq0$.

Allora se il limite del rapporto tra $f$ e $g$ esiste ed è finito, gli integrali impropri di $f$ e $g$ hanno lo stesso carattere, in particolare $f(x)\sim_{+\infty} g(x)$:
\begin{gather}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=l\in\mathbb{R}^+\implies\int_a^{+\infty}f(x)\df x\land\int_a^{+\infty}g(x)\df x:\mbox{ stesso carattere}
\end{gather}

Invece se il limite del rapporto è nullo, e l'integrale improprio della funzione $g$ converge, allora anche l'integrale improprio di $f$ converge:
\begin{gather}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=0\land\int_a^{+\infty}g(x)\df x\in\mathbb{R}\implies\int_a^{+\infty}f(x)\df x\in\mathbb{R}
\end{gather}


Se il limite del rapporto diverge, e l'integrale improprio della funzione $g$ diverge, allora anche l'integrale improprio sulla funzione $f$ diverge:
\begin{gather}
    \lim_{x\to+\infty}\displaystyle\frac{f(x)}{g(x)}=+\infty\land\int_a^{+\infty}f(x)\df x=\pm\infty\int_a^{+\infty}g(x)\df x=\pm\infty
\end{gather}

\subsubsection{Criterio di Convergenza Assoluta}

Sia $f$ continua in $[a,+\infty)$, allora se l'integrale improprio della funzione $|f(x)$ converge, anche l'integrale improprio senza valore assoluto converge. Questo si dice criterio di convergenza assoluta ed implica la convergenza semplice. La funzione $f$ si dice assolutamente integrabile. 
\begin{gather}
    \int_a^{+\infty}|f(x)|\df x\in\mathbb{R}\implies\int_a^{+\infty}f(x)\df x\in\mathbb{R}
\end{gather}
Un integrale può converge semplicemente in senso improprio, ma non in senso assoluto, dato che non si tratta di una condizione necessaria e sufficiente. 

\subsection{Serie di Fourier} 

Le serie di Fourier sono serie di funzioni utilizzate per approssimare funzioni periodiche. 
Una funzione $f$ definita su $D_f$ illimitato, si dice periodica di periodo $T$ se $\forall x\in D_f$ valgono le seguenti:
\begin{enumerate}
    \item $x+kT\in D_f\,\,\forall k\in\mathbb{Z}$
    \item $f(x+kT)=f(x)$
\end{enumerate}

Una funzione $f$ si dice continua a tratti in un intervallo limitato $I$, se $f$ è continua in $I$, tranne che in una quantità finita di punti di discontinuità di prima o terza specie. 
È integrabile in $I$ ed il suo integrale esiste, è utile poiché per determinare la serie di Fourier bisognerà risolvere integrali impropri su funzioni di questo tipo. 


Una funzione $f$ si dice regolare a tratti in un intervallo limitato $I$, se è continua a tratti in $I$, e se ha derivata continua in $I$ tranne che nei punti di discontinuità più altri punti in quantità finita. In tali punti esistono finiti i limiti della derivata: $\lim_{x\to x_0^-}f'(x)\neq\lim_{x\to x_0^+}f'(x)$. 

Una funzione si dice continua o regolare a tratti in $\mathbb{R}$, se in lo è in ogni arbitrario intervallo limitato. 


Sia $f$ una funzione continua a tratti in $\mathbb{R}$, periodica di periodo $T$; l'integrale su un periodo $T$, $\forall a\in\mathbb{R}$, si può esprimere in maniera equivalente come:
\begin{gather*}
    \displaystyle\intab{a}{a+T}{f(x)}{x}=
    \displaystyle\intab{0}{T}{f(x)}{x}=
    \displaystyle\intab{-T/2}{T/2}{f(x)}{x}
\end{gather*}
Per semplicità si vuole considerare un intervallo simmetrico, per facilitare il calcolo, sfruttando eventuali simmetrie della funzione. 


La serie di Fourier di $f$ viene definita come:
\begin{gather}
    f(x)=\displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)+b_k\sin\left(\frac{2k\pi}{T}x\right)
\end{gather}
Dove i coefficienti $a_k$ e $b_k$ sono dati da:
\begin{gather}
    a_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x\\
    b_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x
\end{gather}

Può succedere che la funzione $f$ rispetta la simmetria, e quindi si possono semplificare queste formule. Se $f$ è pari si ha:
\begin{gather*}
    a_k=\displaystyle\frac{4}{T}\int_{0}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x\\
    b_k=\displaystyle\frac{2}{T}\int_{-T/2}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x=0\\
    f(x)=\displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x\right)
\end{gather*}
Mentre se $f$ è dispari si ha:
\begin{gather*}
    a_k=\displaystyle\frac{4}{T}\int_{-T/2}^{T/2}f(x)\cos\left(\frac{2k\pi}{T}x\right)\df x=0\\
    b_k=\displaystyle\frac{4}{T}\int_{0}^{T/2}f(x)\sin\left(\frac{2k\pi}{T}x\right)\df x\\
    f(x)=\displaystyle\sum_{k=1}^\infty b_k\sin\left(\frac{2k\pi}{T}x\right)
\end{gather*}

Sia $f$ regolare a tratti in $\mathbb{R}$ ed inoltre sia periodica di periodo $T$. Allora se $f$ è continua in $x_0$:
\begin{gather}
    f(x_0)=\displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x_0\right)+b_k\sin\left(\frac{2k\pi}{T}x_0\right)
\end{gather}
Se $f(x)$ non è continua in $x_0$ allora:
\begin{gather}
    f(x_0)=\displaystyle\frac{a_0}{2}+\sum_{k=1}^\infty a_k\cos\left(\frac{2k\pi}{T}x_0\right)+b_k\sin\left(\frac{2k\pi}{T}x_0\right)=\frac{f(x_0^-)+f(x_0^+)}{2}
\end{gather}
Dove:
\begin{gather*}
    f(x_0^-)=\lim_{x\to x_0^-}f(x)\\
    f(x_0^+)=\lim_{x\to x_0^+}f(x)
\end{gather*}

\clearpage

\section{Equazioni Differenziali}

Le equazioni differenziali sono un modello matematico di tipo algebrico, sono un modo di studiare un fenomeno, in genere fisico. Prima di studiare il fenomeno bisogna studiare le grandezze di questo fenomeno, ed in seguito bisogna individuare un legame per definire o possibilmente determinare l'evoluzione del fenomeno stesso. 
Vengono usate per analizzare questi fenomeni poiché le equazioni che ne descrivono il comportamento spesso dipendono dal cambiamento stesso del fenomeno, rappresentato da termini derivati. 

Un'equazione differenziale è un'equazione dove l'incognita è una funzione $y(x)$, continua nell'intervallo su cui è definita l'equazione, e sono presenti dei termini differenziali di $n$-esimo ordine della funzione $y$ stessa:
\begin{equation}
    f(x, y, y', \cdots, y^{(n)})=0
\end{equation}
La funzione e tutte le sue derivate sono tutte definite su un insieme dell'asse reale $\mathbb{R}$. 

Considerando il valore generico della variabile indipendente $x$, l'equazione differenziale è una relazione tra i valori della $x$ ed i valori assunti dalla funzione incognita $y$ e le sue derivate. 
Per ordine dell'equazione si intende l'ordine massimo della derivata presente nell'equazione, $n$-esimo. Se è possibile esplicitare la derivata $n$-esima dell'equazione, allora l'equazione si dice espressa in forma normale:
\begin{equation}
    y^{(n)}=f(x, y, y', \cdots, y^{(n-1)})
\end{equation}

Un'equazione differenziale si dice lineare se sia la funzione che le sue derivate sono elevate ad una potenza massima pari ad uno, e non sono presenti termini misti. 

%% TODO informazione inutile ??
% Si considera un'equazione differenziale ordinaria di primo ordine $y'=f(x,y)$, si possono rappresentare sul piano le coppie di questa funzione $(\bar{x},\bar{y})$, e la derivata ha un significato grafico ovvero la pendenza della funzione in questo punto. Questa funzione viene definita in un intervallo che individua un rettangolo, se per ogni punto di questo insieme si può disegnare 
% un segmento che rappresenta la pendenza in questo punto, si genera una figura simile ad un campo vettoriale. La funzione $y'$ è l'inviluppo di tutti questi segmenti così individuati. 

%% TODO teorema per unicità problema di Cauchy
Sia un valore $x_0\in I$, dove $I$ è l'intervallo su cui è definita l'equazione differenziale, e la funzione $y(x)$ continua, poiché derivabile. Se $y_0=y(x_0)\neq0$, nell'intorno di $x_0$, $I(x_0)$, la funzione $y(x)$ ha sempre lo stesso segno se:
\begin{gather*}
    \forall x\in I(x_0):y(x)\neq0\implies \displaystyle\frac{y(x)}{y_0}>0
\end{gather*}
Altrimenti esisterebbe una soluzione all'equazione differenziale $y(x)=0$. 

\subsection{Equazioni a Variabili Separabili}

Un'equazione differenziale ordinaria a variabili separabili è un'equazione che può essere ricondotta ad una forma nota come la seguente:
\begin{equation}
    y'=g(x)\cdot h(y)
\end{equation}
Un'equazione a variabili separabili a tante soluzioni del tipo $y(x)=\bar{y}$, quanti sono gli zeri distinti della funzione $h(y)$, poiché l'equazione si riduce alla forma $0=0$. Queste soluzioni si dicono integrali singolari, questi integrali singolari vengono esclusi dai procedimenti successivi; non si cerca una soluzione costante. Per $h(y)\neq0$ quindi si può risolvere considerando:
\begin{gather*}
    \displaystyle\frac{\df y}{\df x}=g(x)\cdot h(y)\\
    \displaystyle\frac{1}{h(y)}\df y=g(x)\df x\\
    \displaystyle\int\frac{1}{h(y)}\df y=\int g(x)\df x
\end{gather*}
In seguito si prova ad esprimere esplicitamente l'incognita $y$ in funzione della variabile indipendente $x$. Questo primo modo di procedere è laborioso. 
Si può risolvere in modo più rigoroso considerando la primitiva del primo membro:
\begin{gather*}
    H(y)=\displaystyle\int\frac{1}{h(y)}\df y\implies H'(y)=\frac{1}{h(y)}
\end{gather*}
Data una primitiva $H(y)$ per il teorema fondamentale del calcolo integrale, avendo una qualsiasi costante $c\in\mathbb{R}$, la funzione $G(y)$ definita come $G(y)=H(y)+c$ anch'essa rappresenta una primitiva. 
Sostituendola nell'equazione di partenza si ottiene:
\begin{gather*}
    H'(y)y'=g(x)
\end{gather*}
Il primo membro ora somiglia alla derivata di una funzione composta, quindi si può riscrivere come:
\begin{gather*}
    \displaystyle\frac{ \df H}{\df x}=g(x)\\
    \displaystyle H(y(x))=\int g(x)\df x+c
\end{gather*}
In teoria $H(y)$ è una funzione monotona, e quindi continua, poiché la sua derivata è il reciproco di $h(y)$ e non si annulla per l'ipotesi di lavoro iniziale, quindi è invertibile. Allora si considera la funzione inversa di $H(y)$: $H^{-1}(y)$. Applicandola membro a membro all'equazione ottenuta precedentemente si ha:
\begin{gather*}
    H^{-1}\left[H(y(x))\right]=H^{-1}\left[\displaystyle\int g(x)\df x+c\right]\\
    y(x)=H^{-1}\left[\displaystyle\int g(x)\df x+c\right]\tageq
\end{gather*}
Avendo un numero infinito di primitive $H(y)$ possibili, allora esisteranno un numero non finito di soluzioni all'equazione differenziale. Alcune di queste soluzioni possono corrispondere agli integrali singolari dell'equazione determinati precedentemente. 
Anche se la funzione è invertibile non è detto che si riesca ad individuare la sua inversa, per cui a volte bisogna accontentarsi dell'espressione implicita: 
\begin{gather*}
    \displaystyle H(y(x))=\int g(x)\df x+c
\end{gather*}

\subsection{Problema di Cauchy}

Il problema di Cauchy consiste nell'assegnare una condizione iniziale ad un'equazione differenziale, ovvero richiede che la soluzione dell'equazione differenziale $y(x)$ assuma un determinato valore $y_0$ in corrispondenza del valore $x_0$:
\begin{gather}
    \begin{cases}
        y'=f(x,y)\\
        y(x_0)=y_0
    \end{cases}
\end{gather}
Una soluzione ad un problema di Cauchy è quindi unica. 
Se l'equazione ha un ordine maggiore del primo, sono presenti tanti vincoli quanto è l'ordine $n$ dell'equazione:
\begin{gather*}
    \begin{cases}
        y^{(n)}=f(x,y,\cdots,y^{(n-1)})\\
        y(x_0)=y_0\\
        y'(x_1)=y_1\\
        \vdots\\
        y^{(n-1)}(x_{n-1})=y_{n-1}
    \end{cases}
\end{gather*}

\subsubsection{Teorema di Picard: Esistenza ed Unicità di una Soluzione}

Data un'equazione differenziale del primo ordine in forma normale, supponendo siano note le condizioni iniziali $y_0$:
\begin{gather*}
    y'=f(x,y)\\
    y_0=y(x_0)
\end{gather*}

Il teorema di Picard afferma che:
\begin{quotation}
    Se le funzioni $f$ e $f_y$ sono continue in un rettangolo $(x,y)\in\mathbb{R}^2$, avente i lati paralleli agli assi, contente il punto $(x_0,y_0)$. Allora esiste un numero reale $h$, tale che nell'intervallo di $x_0$ di raggio $h$: $|x-x_0|\leq h$, il problema di Cauchy definito da $y'=f(x,y)$ e $y_0=y(x_0)$ ammette una ed una sola soluzione nell'intervallo $|x-x_0|\leq h$.      
\end{quotation}

\subsection{Equazioni Differenziali Lineari del Primo Ordine}
\label{sec:eq-dff-1}

Equazioni differenziali lineari del primo ordine, sono equazioni differenziali della seguente forma:
\begin{gather}
    y'+p(x)y=f(x)
\end{gather}
Dove le funzioni $p$ ed $f$ sono definite su un intervallo dove è definita anche la funzione incognita $y(x)$. La funzione $p$ viene chiamata funzione coefficiente e la  $f$ funzione forzante. Per risolvere questo tipo di equazioni è fondamentale la determinazione del fattore integrante. 


Si vuole lavorare in modo che un membro diventi una derivata, considerando l'equazione generale si moltiplicano ambo i lati per la funzione $\mu$:
\begin{gather*}
    \mu y'+\mu p(x)y=\mu f(x)
\end{gather*}
Si impone che il primo membro moltiplicato per questa funzione $\mu$ produca esattamente la derivata di $\mu\cdot y$:
Si vuole avere la derivata del prodotto al primo membro:
\begin{gather*}
    \cancel{\mu y'}+\mu p(x)y=D[\mu\cdot y]=\mu'y+\cancel{\mu y'}\\
    \mu p(x)=\mu'\implies\frac{\mu'}{\mu}=p(x)\\
    \ln\mu=\displaystyle\int p(x)\df x\\
    \mu=e^{\int p(x)\df x}
\end{gather*}
Imponendo questo vincolo si è riportata l'equazione in un'equazione di variabili separabili in termini di $\mu$ ed $x$. 

Ottenuto il fattore integrante si può ritornare alla funzione di partenza, considerando la forzante ed integrando ambo i membri, per ottenere la soluzione all'equazione:
\begin{gather*}
    \overbrace{\mu y'+\mu p(x)y}^{D[\mu\cdot y]}=\mu f(x)\\
    \mu y=\int\mu f(x)\df x+c\\
    y(x)=\mu^{-1}(x)\int\mu(x)f(x)\df x+c\mu^{-1}(x)\tageq
\end{gather*}


Nel caso in cui la forzante è nulla, ci si trova nella situazione:
\begin{gather*}
    y'+a(x)y=0
\end{gather*}
Allora l'integrale particolare definito su $I$ è della forma:
\begin{equation}
    y(x)=ce^{-A(x)}\mbox{ con } A(x)=\int a(x)\df x
\end{equation}
Sostituendo la soluzione nell'equazione differenziale di partenza infatti si ottiene:
\begin{gather*}
    D[ce^{-A(x)}]+ca(x)e^{-A(x)}=-ca(x)e^{-A(x)}+ca(x)e^{-A(x)}=0
\end{gather*}

\subsubsection{Operatore Differenziale}

Sia $p(x)$ continua in $I$, l'operatore differenziale $L$ assegna ad ogni funzione $y$ il seguente:
\begin{gather}
    L[y]=y'+p(x)y
\end{gather}
Questo operatore è molto comodo per rappresentare equazioni differenziali lineare di primo ordine. 
L'operatore differenziale è lineare, per cui data una funzione $y_1$, tale che $L[y_1]=0$ e $y_2$ tale che $L[y_2]=0$, allora si ha:
\begin{gather*}
    L[c_1y_1+c_2y_2]=c_1y'_1+p(x)c_1y_1+c_2y'_2+p(x)c_2y_2=c_1L[y_1]+c_2L[y_2]=0
\end{gather*}
La combinazione lineare di due soluzioni è soluzione dell'equazione lineare omogenea. 

Data una soluzione $\omega_1$ ed $\omega_2$ ad un'equazione differenziale lineare di primo ordine non omogenea: $L[\omega_1]=f(x)$ e $L[\omega_2]=f(x)$, allora si ha che:
\begin{gather*}
    L[\omega_1-\omega_2]=L[\omega_1]-L[\omega_2]=f(x)-f(x)=0
\end{gather*}
La differenza tra queste due soluzioni, rappresenta una soluzione per l'equazione omogenea $\omega_1-\omega_2=y$; essendo queste due soluzioni generali, la differenza di due qualsiasi soluzioni generali dell'equazione differenziale produce una soluzione all'equazione omogenea. Ogni soluzione della omogenea si può esprimere come dimostrato precedentemente:
\begin{gather*}
    \bar{y}=ce^{-A(t)}\mbox{ dove } A(t)=\displaystyle\int p(x)\df x
\end{gather*}
Per la soluzione generale ad un'equazione non omogenea si ottiene fissando una particolare soluzione non omogenea ed aggiungendo l'integrale generale per la sua soluzione omogenea:
\begin{gather}
    \omega_1-\omega_2=\bar{y}\implies\omega_1=\omega_2+\bar{y}=\omega_2+c\cdot e^{-A(t)}
\end{gather}
Questo permette di semplificare l'integrazione in un caso abbastanza particolare. 
Supponendo che $p(x)$ sia una costante $k$, allora la soluzione particolare $\bar{y}$ è dello stesso tipo della forzante $f(x)$, per il criterio della similarità. 
La funzione $f(x)$ può essere una costante, un polinomio, una funzione sinusoidale o esponenziale, oppure una combinazione di lineare di queste, e per il criterio di similarità la funzione soluzione omogenea è una funzione della stessa classe. Questo rappresenta un modo euristico per risolvere il problema, considerando una soluzione dello stesso tipo, a differenza di una costante, da individuare. 



Se si ha un esponenziale nella soluzione particolare che coincide all'integrale omogeneo e $p(x)=\alpha$:
\begin{gather}
    L[y]=y'+\alpha y=\beta e^{-\alpha x}
\end{gather}
La soluzione particolare non è del tipo $ke^{-\alpha x}$ come la forzante $\beta e^{-\alpha x}$; non segue completamente la regola della similarità ed invece è del tipo:
\begin{gather*}
    \bar{y}=kxe^{-\alpha x}\\
    \bar{y}'=ke^{-\alpha x}-\alpha kxe^{-\alpha x}
\end{gather*}
La costante $k$ è quindi:
\begin{gather*}
    ke^{-\alpha x}-\cancel{\alpha kxe^{-\alpha x}}+\bcancel{\alpha kxe^{-\alpha x}}=\beta e^{-\alpha x}\\
    k=\beta
\end{gather*}
La soluzione generale dell'equazione differenziale è quindi:
\begin{gather}
    y=ce^{-\alpha x}+\bar{y}=ce^{-\alpha x}+\beta xe^{-\alpha x}
\end{gather}

\subsubsection{Principio di Sovrapposizione}

Sia $L[y]=y'+p(x)y=0$, e siano due soluzioni particolari $\bar{y}_1$ e $\bar{y}_2$ rispettivamente $L[\bar{y}_1]=f(x)$ e $L[\bar{y}_2]=g(x)$, allora l'equazione differenziale $L[y]=f(x)+g(x)$ ha soluzione particolare in $\bar{y}_1+\bar{y}_2$. 
Analogamente la loro combinazione lineare rappresenta integrale particolare dell'equazione differenziale: $c_1\bar{y}_1+c_2\bar{y}_2$. 

\subsection{Riduzione dell'Ordine}

Data un'equazione differenziale $y'=f(x,y)$, può essere che al secondo membro non sia presente la variabile $y$, e quindi assuma la forma $y'=f(x)$. Questa equazione differenziale si può risolvere quindi per integrazione diretta:
\begin{gather*}
    y=\displaystyle\int f(x)\df x=F(x)+c
\end{gather*}

Analogamente per un'equazione differenziale del tipo $y''=f(x,y,y')$, se non è presente il termine $y$ si ha $y''=f(x,y')$. Si può effettuare una sostituzione con $z=y'$, per ridurre l'ordine dell'equazione differenziale:
\begin{gather}
    y''=f(x,y'),\,z=y'\implies z'=f(x,z)
\end{gather}
Risolvendo per $z$, si può ottenere la soluzione $y$ tramite integrazione diretta:
\begin{gather}
    y=\displaystyle\int z\df z
\end{gather}

\subsection{Equazioni di Bernoulli}

Un'equazione di Bernoulli è un'equazione differenziale del tipo:
\begin{gather}
    y'+p(x)y+q(x)y^m=0
\end{gather}
Per risolvere questo tipo di equazioni si moltiplicano ambo i membri per $y^{-m}$:
\begin{gather*}
    y^{-m}y'+p(x)y^{1-m}+q(x)=0
\end{gather*}
A questo punto si introduce un'altra variabile $u$, si pone $u=y^{1-m}$:
\begin{gather*}
    u'=(1-m)y^{-m}y'\implies \frac{u'}{1-m}=y^{-m}y'\\
    \displaystyle\frac{u'}{1-m}+p(x)u+q(x)=0
\end{gather*}
In questo modo è diventata un'equazione differenziale lineare del primo ordine, risolubile con i metodi precedenti. 


Un'esercizio abbastanza frequente è l'esercizio inverso, dove viene data una soluzione ad un'equazione differenziale $y(x)$ e si chiede di ottenere un'equazione differenziale. 

Il primo metodo consiste nel derivare la soluzione per trovare il valore della costante, e poi sostituirlo nell'equazione originaria. 

Un altro metodo consiste nel prendere la porzione della soluzione corrispondente alla soluzione omogenea, tale che $L[y_0]=0$, ed eguagliarla a $ce^{-A(x)}$, per determinare $p(x)$, derivando $A(x)$. 
Quindi si può esprimere come:
\begin{gather*}
    L[y]=f(x)\equiv y'+A'(x)y=f(x)
\end{gather*}

\subsection{Equazioni di Manfredi}

Le equazioni di Manfredi sono equazioni differenziali che riguardano funzioni omogenee di grado zero. Una funzione è detta omogenea di grado zero, se data una funzione $f(x,y)$ vale la seguente:
\begin{gather*}
    \forall t\in\mathbb{R}\implies f(tx,ty)=f(x,y)    
\end{gather*}
Quindi le equazioni di manfredi sono della forma:
\begin{gather}
    y'=f(x,y)=f(tx,ty)
\end{gather}
Una forma comune per questo tipo di equazioni è la seguente:
\begin{gather*}
    y'=f\left(\frac{ax+by}{cx+dy}\right)
\end{gather*}
Per determinare l'integrale di queste equazioni si considera la seguente sostituzione $t=x^{-1}$:
\begin{gather*}
    y'=f\left(1,\displaystyle\frac{y}{x}\right)
\end{gather*}
Per trovare una soluzione si effettua un'ulteriore sostituzione $z=y/x$:
\begin{gather*}
    y=xz,\,y'=z+xz'\\
    z+xz'=f(1,z)=F(z)
\end{gather*}
Quest'ultima diventa un'equazione a variabili separabili del tipo:
\begin{gather*}
    xz'=F(z)-z\\
    \displaystyle\frac{\df z}{F(z)-z}=\frac{\df x}{x}
\end{gather*}
Dopo aver ottenuto la soluzione in termini di $z$, si può riportare rispetto ad $y$ tramite:
\begin{equation}
    y=z\cdot x
\end{equation}

\subsection{Equazioni di Riccati}

La conoscenza di una radice permette di semplificare l'esercizio di determinare ulteriori radici di un polinomio. Analogamente conoscendo una soluzione di un'equazione differenziale, è possibile individuare più facilmente altre soluzioni. 
L'equazione di Riccati del primo ordine è del tipo:
\begin{gather}
    y'=p(t)y^2+q(t)y+r(t)
\end{gather}
Sembra, anche se non lo è, un'equazione di Bernoulli. Si suppone si conosca una soluzione $y_1$ di questa equazione, a questo punto si sostituisce $y=y_1+1/z$:
\begin{gather*}
    y_1'-\displaystyle\frac{z'}{z}=p(t)\left(y_1+\frac{1}{z}\right)^2+q(t)\left(y_1+\frac{1}{z^2}\right)+r(t)\\
    y_1'-\displaystyle\frac{z'}{z^2}=p(t)\left(y_1^2+2\frac{y_1}{z}+\frac{1}{z^2}\right)+q(t)\left(y_1+\frac{1}{z}\right)+r(t)\\
    \displaystyle-\frac{z'}{z^2}=-y_1'+p(t)y_1^2+p(t)\frac{1}{z^2}+2\frac{p(t)y_1}{z}+q(t)\left(y_1+\frac{1}{z}\right)+r(t)
\end{gather*}
Sapendo che $y_1$ è una soluzione, si possono eliminare alcuni termini:
\begin{gather*}
    -z'=\left(-\cancel{y_1'}+\bcancel{p(t)y_1^2}+p(t)\frac{1}{z^2}+2\frac{p(t)y_1}{z}+\bcancel{q(t)y_1}+\frac{q(t)}{z}+\bcancel{r(t)}\right)z^2\\
    z'=-(2y_1p(t)+q(t))z-p(t)
\end{gather*}
Risolvendo questa equazione differenziale rispetto a $z$, si può ottenere la soluzione $y$ come:
\begin{equation}
    y=y_1+\frac{1}{z}
\end{equation}

\subsection{Equazioni Esatte}

Le equazioni esatte sono un tipo di equazioni differenziali nella forma:
\begin{gather}
    X(x,y)\df x+Y(x,y)\df y=0
\end{gather}
Si può portare nella forma di un'equazione differenziale come:
\begin{gather*}
    X(x,y)+Y(x,y)\displaystyle\frac{\df y}{\df x}=0\\
    y'=\displaystyle-\frac{X(x,y)}{Y(x,y)}
\end{gather*}

La soluzione è una funzione $\Phi$ che ammette derivate parziali, le quali sono uguali a $X$ e $Y$:
\begin{gather*}
    \displaystyle\frac{\partial\Phi}{\partial x}=X(x,y)\\
    \displaystyle\frac{\partial\Phi}{\partial y}=Y(x,y)
\end{gather*}
E derivata nulla rispetto ad $x$:
\begin{gather*}
    \displaystyle\frac{\df\Phi}{\df x}=0
\end{gather*}
Le sue derivate parziali sono i coefficienti della forma lineare differenziale dell'equazione esatta:
\begin{gather*}
    \displaystyle\frac{\df\Phi}{\df x}=\frac{\partial\Phi}{\partial x}+\frac{\partial\Phi}{\partial y}\frac{\df y}{\df x}=
    X(x,y)+Y(x,y)\frac{\df y}{\df x}=0
\end{gather*}
Se questo è verificato la soluzione è del tipo $\Phi(x,y)=c$, ma devono essere verificate le condizioni per l'esistenza della soluzione. 

Deve essere verificato il teorema di Schwarz, la condizione di chiusura, ovvero le derivate miste devono essere congruenti:
\begin{gather*}
    \displaystyle\frac{\partial\Phi}{\partial x\partial y}=\frac{\partial\Phi}{\partial y\partial x}
\end{gather*}
In un dominio rettangolare del piano $(x,y)$, le funzioni $X$ e $Y$ devono essere continue, quindi devono essere continue le derivate parziali di $\Phi$. 

Data un'equazione in forma esatta, per individuare la funzione $\Phi$, si può scegliere di integrare $X$ o $Y$, rispetto a $x$ o $y$, per ottenere una funzione della stessa forma di $\Phi$:
\begin{gather*}
    \Phi_x=X\\
    \Phi=\int X\df x =F(x,y)+h(y)
\end{gather*}
Dove $F(x,y)$ è una primitiva di $X$ e $h(y)$ rappresenta la costante di integrazione, poiché derivando su una sola variabile tutti i termini dipendenti interamente da $y$ diventano nulli. 
Per determinare il valore di questa costante di integrazione, si deriva la funzione $\Phi$ così ottenuta rispetto a $y$ e si confronta con $Y$:
\begin{gather*}
    \Phi_y=\frac{\partial F}{\partial y}+h'(y)=Y
\end{gather*}
Dopo aver determinato $h(y)$, si ha che la funzione $\Phi$ è data da:
\begin{gather}
    \Phi(x,y)=F(x,y)+h(y)=c
\end{gather}
Questo procedimento è analogo se si fosse integrato il fattore $Y$ rispetto ad $y$:
\begin{gather*}
    \Phi(x,y)=G(x,y)+h(x)=c
\end{gather*}

\subsubsection{Fattore Integrante}

Il problema nella risoluzione di equazioni esatte, è la ricerca del fattore integrante $\mu$ che moltiplicato ad entrambi i membri rende l'equazione esatta. Questo può dipendere da entrambe le variabili indipendenti, ma generalmente conviene scegliere un fattore integrante che dipende o solo dalla $x$ o solo dalla $y$. 
Questo fattore integrante è lo stesso delle equazioni differenziali lineari di primo ordine \ref{sec:eq-dff-1}, poiché rappresentano una forma di equazioni esatte. 

Data un'equazione in forma esatta:
\begin{gather*}
    X(x,y)\df x+Y(x,y)\df y=0
\end{gather*}
Si considera un fattore integrante $\mu(x)$ e si moltiplicano ambo i membri:
\begin{gather*}
    \mu(x)X(x,y)\df x+\mu(x)Y(x,y)\df y=0
\end{gather*}
Si verifica la condizione di chiusura:
\begin{gather*}
    \frac{\partial}{\partial y}\left(\mu(x)X(x,y)\right)=\mu(x)X_y\\
    \frac{\partial}{\partial x}\left(\mu(x)Y(x,y)\right)=\mu'(x)Y+\mu(x)Y_x\\
    \mu(x)X_y=\mu'(x)Y+\mu(x)Y_x  
\end{gather*}
Questo fattore integrante deve essere tale per verificare la condizione. Si dividono entrambi i membri per $\mu(x)$:
\begin{gather*}
    \frac{\mu'}{\mu}Y+Y_x=X_y    
\end{gather*}
Questa è un'equazione differenziale a variabili separabili in termini di $\mu$:
\begin{gather*}
    Y\frac{\mu'}{\mu}=X_y-Y_x\\
    \frac{\df \mu}{\df x}\frac{1}{\mu}=\frac{X_y-Y_x}{Y}\\
    \frac{\df\mu}{\mu}=\frac{X_y-Y_x}{Y}\df x
\end{gather*}
Poiché l'equazione di partenza non rispetta la condizione di chiusura, il termine $X_y-Y_x$ è diverso da zero. Bisogna determinare la funzione $K$, definita come segue, e bisogna verificare che si tratta di una funzione nella sola $x$:
\begin{gather}
    K(x)=\frac{X_y-Y_x}{Y}
\end{gather}
Allora il fattore integrante $\mu$ è dato da:
\begin{gather*}
    \int\frac{\df\mu}{\mu}=\int K(x)\df x\\
    \ln\mu=\int K(x)\df x\\
    \mu(x)=e^{\int K(x)\df x}\tageq
\end{gather*}
Analogamente se $\mu$ dipende interamente dalla $y$, si ha:
\begin{gather*}
    \mu(y)X(x,y)\df x+\mu(y)Y(x,y)\df y=0    
\end{gather*}
Le derivate parziali sono quindi:
\begin{gather*}
    \mu'X+\mu X_y=\mu Y_x
\end{gather*}
Si ottiene la seguente equazione a variabili separabili:
\begin{gather*}
    \frac{\df\mu}{\mu}=\frac{X_y-Y_x}{-X}\df y
\end{gather*}
Si considera $-X$ al denominatore per mantenere il numeratore equivalente al precedente caso con $\mu(x)$, si verifica ora che il secondo membro sia una funzione interamente in $y$:
\begin{gather*}
    K(y)=\frac{Y_x-X_y}{X}
\end{gather*}
Allora si risolve l'equazione a variabili separabili rispetto a $\mu(y)$:
\begin{gather*}
    \mu(y)=e^{\int K(y)\df y}
\end{gather*}

\subsection{Equazioni Differenziali del Secondo Ordine}

Un'equazione differenziale del secondo ordine è un'equazione che presente un termine $y$ derivato secondo. Molte equazioni di secondo grado non hanno una soluzione calcolabile in modo esplicito, ma sono presenti molte equazioni particolari di cui si può calcolare la soluzione. 
Le equazioni di Airy sono un tipo di equazioni del secondo ordine, la cui soluzione è calcolabile esplicitamente del tipo $y''-xy=0$. 
Si tratteranno solamente equazioni lineari del secondo ordine:
\begin{gather}
    y''+P(x)y'+Q(x)y=R(x)
\end{gather}
Il teorema dell'esistenza ed unicità delle soluzioni afferma che se queste funzioni $P(x),\,Q(x),\,R(x)$ sono continue su un'intervallo $[a,b]$, con $x_0$ un punto in questo intervallo, allora la soluzione in questo intervallo esiste ed è unica, dati i vincoli $y_0=y(x_0)$ e $y_0'=y'(x_0)$. 


Si considera un caso particolare:
\begin{gather}
    y''=f(x)
\end{gather}
La sua soluzione è immediata, è sufficiente integrare ambo le parti:
\begin{gather*}
    y'=\displaystyle\int f(t)\df x+c_1\\
    y=\displaystyle\int\left(\int f(t)\df x+c_1\right) \df x+c_2\tageq
\end{gather*}


Si considerano prima equazioni di secondo grado lineari con il termine noto nullo:
\begin{gather*}
    y''+a(x)y'+b(x)y=0
\end{gather*}
L'operatore differenziale $L[y]$, per funzioni integrabili due volte rappresenta la trasformazione che ad ogni funzione due volte derivabile associa:
\begin{gather*}
    L[y]=y''+a(x)y'+b(x)y
\end{gather*}
Questo problema di integrazione si risolve in modo semplice quando i coefficienti sono delle costanti:
\begin{gather}
    y''+ay'+by=0
\end{gather}
Per individuare una soluzione si considerano funzioni del tipo $e^{\lambda t}$:
\begin{gather*}
    y=e^{\lambda t}\\
    y'=\lambda e^{\lambda t}\\
    y''=\lambda^2e^{\lambda t}
\end{gather*}
Sostituendo nell'equazione di partenza si ottiene:
\begin{gather*}
    \lambda^2e^{\lambda t}+a\lambda e^{\lambda t}+be^{\lambda t}=0\\
    e^{\lambda t}\left[\lambda^2+a\lambda+b\right]=0
\end{gather*}
L'esponenziale non può essere mai nullo, quindi solo se il polinomio in termini di $\lambda$ è nullo esiste una soluzione, con $\lambda$:
\begin{gather*}
    \lambda=\displaystyle\frac{-a\pm\sqrt{a^2-4b}}{2}
\end{gather*}
Quest'equazione da risolvere si chiama equazione caratteristica, e la soluzione dipende dal discriminante $\Delta$:
\begin{gather}
    \Delta:\begin{cases}
    >0&y=c_1e^{\lambda_1t}+c_2e^{\lambda_2t}\\
    =0&y=c_1te^{\lambda t}+c_2e^{\lambda t}\\
    <0&y=e^{\mathrm{Re}\{\lambda\}t}\left(c_1\cos(\mathrm{Im}\{\lambda\}t)+c_2\sin(\mathrm{Im}\{\lambda\}t)\right)
    \end{cases}    
\end{gather}

\subsubsection{Operatore Differenziale}

Se i coefficienti dell'equazione differenziale ordinaria di secondo ordine non sono costanti si ha:
\begin{gather}
    y''+P(x)y'+Q(x)y=0
\end{gather}
Si considera l'operatore differenziale:
\begin{gather*}
    L[y]=y''+P(x)y'+Q(x)y
\end{gather*}
Questo operatore è lineare, quindi siano $y_1$ e $y_2$ soluzioni dell'equazione non omogenea, allora una loro combinazione lineare è anch'essa una soluzione:
\begin{gather*}
    L[c_1y_1
    +c_2y_2]=c_1y_1''+c_1P(x)y_1'+c_1Q(x)y_1+c_2y_2''+c_2P(x)y_2'+c_2Q(x)y_2=c_1L[y_1]+c_2L[y_2]\\
    L[c_1y_1+c_2y_2]=c_1L[y_1]+c_2L[y_2]\tageq
\end{gather*}
Considerando ora l'equazione non omogenea, data $\bar{y}$ la soluzione dell'equazione non omogenea, e $y_1$ una soluzione dell'equazione omogenea, allora l'operatore applicato alla loro combinazione lineare diventa:
\begin{equation}
    L[y_1+\bar{y}]=\cancelto{0}{L[y_1]}+L[\bar{y}]=L[\bar{y}]=R(x)
\end{equation}
Il primo addendo è nullo poiché è soluzione dell'equazione omogenea, quindi la combinazione lineare tra una soluzione dell'equazione omogenea e di quella non omogenea, è una soluzione per l'equazione non omogenea.
Mentre date due soluzioni per l'equazione non omogenea $\bar{y}_1$ e $\bar{y}_2$, l'operatore differenziale applicato alla loro differenza sarà nullo:
\begin{equation}
    L[\bar{y}_1-\bar{y_2}]=L[\bar{y}_1]-L[\bar{y}_2]=R(x)-R(x)=0
\end{equation}
La differenza di due soluzioni dell'equazione non omogenea è una soluzione all'equazione omogenea. Quindi fissando una delle due soluzioni si può attuare lo stesso procedimento per le equazioni lineari di primo ordine, dove 
la soluzione generale per un'equazione differenziale è data dalla combinazione lineare dell'integrale particolare dell'omogenea $\bar{y}$ e di una soluzione generale per la non omogenea $y_1$:
\begin{gather*}
    L[y_1+\bar{y}]=R(x)\\
    y=y_1+\bar{y}\tageq
\end{gather*}



Date due funzioni $y_1(x)$ e $y_2(x)$ queste si dicono linearmente indipendenti se non esistono costanti $c_i\neq0$ tali che $c_1y_1(x)+c_2y_2(x)=0$. Se invece esistono queste costanti, sempre diverse da zero, le funzioni si dicono linearmente dipendenti:
\begin{gather}
    \exists\,c_1,c_2\neq0:c_1y_1(x)+c_2y_2(x)=0\implies y_1,y_2\mbox{ linearmente dipendenti}\\
    \forall\,c_1,c_2\neq0:c_1y_1(x)+c_2y_2(x)\neq0\implies y_1,y_2\mbox{ linearmente indipendenti}
\end{gather}


Siano $y_1(x)$ e $y_2(x)$ soluzioni linearmente indipendenti di un'equazione lineare di secondo ordine omogenea $L[y]=0$, allora ogni soluzione è data da una combinazione lineare di queste due soluzioni $y=c_1y_1+c_2y_2$:
\begin{equation}
    L[y_1]=L[y_2]=0\implies \forall c_1,c_2\in\mathbb{R}:L[c_1y_1+c_2y_2]=0
\end{equation}
Date le condizioni al contorno $y_0$ e $y_0'$, si possono individuare le costanti $c_1$ e $c_2$:
\begin{gather*}
    y(x_0)=c_1y_1(x_0)+c_2y_2(x_0)=y_0\\
    y'(x_0)=c_1y_1'(x_0)+c_2y_2'(x_0)=y_0'
\end{gather*}
Questo sistema ha soluzione se il determinante dei coefficienti è diverso da zero:
\begin{gather*}
    \left|\begin{matrix}
        y_1(x_0) & y_2(x_0)\\
        y_1'(x_0) & y_2'(x_0)
    \end{matrix}\right|=y_1(x_0)\cdot y_2'(x_0)-y_2(x_0)\cdot y_1'(x_0)\neq0
\end{gather*}
Questo si chiama il Wronskiano $W(x)$ relativo a $y_1$ e $y_2$: $W(y_1(x),y_2(x))$.  
Si vogliono trovare due soluzioni linearmente indipendenti; se il Wronskiano è nullo allora le soluzioni non solo linearmente indipendenti e quindi non può essere utilizzato per individuare la soluzione. 

%% TODO ??

\subsection{Equazioni di Eulero}

Le equazioni di Eulero sono equazioni differenziali ordinarie lineari di ordine $n$, a coefficienti non costanti, del tipo:
\begin{equation}
    a_0x^ny^{(n)}+a_1x^{n-1}y^{(n-1)}+\cdots+a_ny=f(x)
\end{equation}
Con $a_0\neq0$. Si considerano solo equazioni del secondo ordine, anche se il metodo risolutivo è analogo per ordini superiori. Le soluzioni a questo tipo di equazioni sono del tipo $y=x^\alpha$, sostituendo la soluzione nell'equazione si ottiene:
\begin{gather*}
    a_0x^2\alpha(\alpha-1)x^{\alpha-2}+a_1x\alpha x^{\alpha}+a_2x^{\alpha}=f(x)\\
    x^\alpha(a_0\alpha^2+(a_1-a_0)\alpha+a_2)=f(x)
\end{gather*}
Questa è una situazione molto simile al polinomio caratteristico, poiché non esiste un esponente tale che $x^\alpha=0$. Questa si chiama equazione indiciale. Trovando le radici di questa equazioni, si ottengono le due soluzioni all'omogenea:
\begin{gather*}
    a_0\alpha^2+(a_1-a_0)\alpha+a_2=0\\
    y=c_1x^{\alpha_1}+c_2x^{\alpha_2}\tageq
\end{gather*}
Questo metodo è efficace quando le equazioni sono omogenee, altrimenti non conviene più di altri metodi. 


Il metodo canonico per la risoluzione di queste equazioni prevede il cambio di variabile $x=e^t$ e $t=\ln x$, per eliminare i termini polinomiali rispetto alla $x$. Le derivate dell'equazione differenziale diventano quindi:
\begin{gather*}
    \diff{y}{x}=\diff{y}{t}\cdot\diff{t}{x}=\dot y\cdot\frac{1}{x}\\
    \diffn{y}{x}{2}=\frac{\df}{\df x}\left[\dot y\cdot\frac{1}{x}\right]=\left(\diff{\dot y}{t}\cdot\diff{t}{x}\right)\frac{1}{x}-\dot y\frac{1}{x^2}=\frac{1}{x^2}(\ddot y-\dot y)
\end{gather*}
Si utilizza la notazione puntata di Newton per le derivate nel tempo; l'equazione diventa:
\begin{gather*}
    a_0\cancel{x^2}\frac{1}{\cancel{x^2}}(\ddot y-\dot y)+a_1\cancel{x}\frac{1}{\cancel{x}}\dot y+a_2y=0\\
    a_0\ddot y+(a_1-a_0)\dot y+a_2y=0
\end{gather*}
Quest'equazione ha la stessa forma dell'equazione indiciale, quindi si può vedere come le soluzioni ottenute con i due metodi sono le stesse. Passando al polinomio caratteristico si ottiene esattamente l'equazione indiciale:
\begin{gather*}
    a_0\lambda^2+(a_1-a_0)\lambda+a_2=0
\end{gather*}
Ottenute le due soluzioni $\lambda_1$ e $\lambda_2$, la soluzione omogenea dell'equazione, rispetto a $t$, è quindi:
\begin{gather*}
    y=c_1e^{\lambda_1t}+c_2e^{\lambda_2t}
\end{gather*}
Sostituendo $t=\ln x$, si ottiene:
\begin{gather}
    y=c_1x^{\lambda_1}+c_2x^{\lambda_2}
\end{gather}
Questa è la stessa soluzione, ottenuta tramite l'equazione indiciale. 

% \subsection{??}

% Data un'equazione differenziale del terzo ordine generale
% \begin{gather*}
%     y'''+ay''+by'+cy=0
% \end{gather*}
% Con $y=e^{\lambda t}$, si ottiene il polinomio caratteristico di questa equazione differenziale:
% \begin{gather*}
%     \lambda^3+a\lambda^2+a\lambda+c=0
% \end{gather*}
% Note le radici di questo polinomio 

\clearpage

\section{Trasformata di Laplace}

La trasformata di Laplace essenzialmente è un'integrale improprio di prima specie. 
Una funzione si dice discontinua a tratti in un intervallo $[a,b]$, se è continua tranne che in un numero finito di punti, dove presenta delle discontinuità di prima o di seconda specie. Queste funzioni sono integrabili sull'intervallo $[a,b]$, e questi integrali si chiamano integrali impropri. Questi integrali e le regole per il loro calcolo sono già stati discussi in una sezione precedente \ref{sec:int-1}. 

La trasformata di Laplace è una funzione di questo tipo. Data una funzione $f(t)$ definita per $t\geq0$, allora la trasformata di Laplace $\mathcal{L}$ di questa funzione è definita come il seguente integrale improprio:
\begin{gather}
    F(s)=\mathcal{L}[f(t)]=\intpinf{f(t)e^{-st}}{t}
\end{gather}
Quest'integrale deve essere finito per certi valori di $s$ maggiori di una certa soglia. La trasformata di Laplace è una funzione in $s$, $F(s)$, più propriamente la trasformata è un limite:
\begin{gather}
    \mathcal{L}[f(t)]=\lim_{\omega\to\infty}\int_0^\omega f(t)e^{-st}\df t
\end{gather}

\subsection{Trasformate di Funzioni Elementari}

Si determina la trasformata di una costante $f(t)=k$, utilizzando la definizione della trasformata di Laplace:
\begin{gather*}
    \mathcal{L}[k]=\lim_{w\to\infty}\int_0^\omega ke^{-st}\df t
\end{gather*}
Quest'integrale è immediato:
\begin{gather*}
    F(s)=\lim_{\omega\to\infty}\left\{-\frac{1}{s}ke^{-st}\bigg|_0^\omega\right\}
\end{gather*}
Si possono invertire i limite di integrazione:
\begin{gather*}
    F(s)=\lim_{\omega\to\infty}\left\{\frac{1}{s}ke^{-st}\bigg|_\omega^0\right\}=
    \frac{k}{s}-\cancelto{0}{\frac{k}{s}\lim_{\omega\to\infty}e^{-s\omega}}
\end{gather*}
La trasformata di una costante è quindi:
\begin{gather}
    \mathcal{L}[k]=\frac{k}{s}
\end{gather}


Si considera la trasformata di una funzione lineare:
\begin{gather*}
    \mathcal{L}[t]=\lim_{\omega\to\infty}\int_0^\omega te^{-st}\df t
\end{gather*}
Si integra per parti:
\begin{gather*}
    \mathcal{L}[t]=\lim_{\omega\to\infty}-\frac{1}{s}\left\{te^{-st}+\frac{1}{s}e^{-st}\bigg|_0^\omega\right\}=
    \lim_{\omega\to\infty}\left\{\cancelto{0}{-\frac{\omega}{s} e^{-s\omega}}+\cancelto{0}{-\frac{1}{s^2}e^{-s\omega}}+\frac{1}{s^2}\right\}=\frac{1}{s^2}\\
    \mathcal{L}[t]=\frac{1}{s^2}\tageq
\end{gather*}


In generale una funzione del tipo $f(t)=t^n$ ha una trasformata di Laplace del tipo:
\begin{gather}
    \mathcal{L}\left[t^n\right]=\frac{n!}{s^{n+1}}
\end{gather}
Si dimostra per induzione, per $n=0$ si ha:
\begin{gather*}
    \mathcal{L}[1]=\frac{1}{s}
\end{gather*}
Questo si è già calcolato precedentemente. 
Si suppone che sia vero per $n=k$, quindi si ha:
\begin{gather*}
    \mathcal{L}\left[t^{k}\right]=\frac{k!}{s^{k+1}}
\end{gather*}
Si determina allora per $n=k+1$:
\begin{gather*}
    \mathcal{L}\left[t^{k+1}\right]=\int_0^{+\infty} t^{k+1}e^{-st}\df t
\end{gather*}
Integrando per parti si ha:
\begin{gather*}
    \mathcal{L}\left[t^{k+1}\right]=\overbrace{\left[-\frac{t^{k+1}e^{-st}}{s}\right]_0^{+\infty}}^0+\frac{k+1}{s}\int_0^{+\infty}t^ke^{-st}\df t=\frac{k+1}{s}\mathcal{L}\left[t^k\right]=\frac{k+1}{s}\frac{k!}{s^{k+1}}=\frac{(k+1)!}{s^{k+2}}
\end{gather*}
Si è quindi verificata la tesi. In genere queste funzioni si chiamano funzioni di tipo $k$ polinomiale, e si rappresentano come $f(t)=t^k/k!$, poiché la loro trasformata è più semplice, essendo indipendente dalla costante $k!$:
\begin{equation}
    \mathcal{L}\left[\frac{t^k}{k!}\right]=\frac{1}{s^{k+1}}
\end{equation}


Si determina la trasformata di Laplace del seno:
\begin{gather*}
    \mathcal{L}\left[\sin(at)\right]=\int_0^{+\infty}\sin(at)e^{-st}\df t
\end{gather*}
Integrando per parti si ha:
\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline
        &D&I\\\hline
        +&$e^{-st}$&$\sin(at)$\\\hline
        -&$-se^{-st}$&$-\cos(at)/a$\\\hline
        +&$s^2e^{-st}$&$-\sin(at)/a^2$\\\hline
    \end{tabular}
\end{center}
\begin{gather*}
    \mathcal{L}[\sin at]=-e^{-st}\frac{\cos(at)}{a}-se^{-st}\frac{\sin(at)}{a^2}-\frac{s^2}{a^2}\overbrace{\int_0^{+\infty}e^{-st}\sin(at)\df t}^{\mathcal{L}[\sin(at)]}\\
    \left(1+\frac{s^2}{a^2}\right)\mathcal{L}[\sin(at)]=\left[-e^{-st}\frac{\cos(at)}{a}-se^{-st}\frac{\sin(at)}{a^2}\right]_0^{+\infty}=\frac{1}{a}\\
    \mathcal{L}[\sin(at)]=\frac{1}{a}\frac{a^2}{a^2+s^2}=\frac{a}{a^2+s^2}\tageq
\end{gather*}
Analogamente per il coseno si ha:
\begin{equation}
    \mathcal{L}[\cos(at)]=\frac{s}{a^2+s^2}\tageq
\end{equation}


Si determina la trasformata dell'esponenziale:
\begin{gather}
    \mathcal{L}\left[e^{bt}\right]=\intpinf{e^{-st}e^{bt}}{t}=\intpinf{e^{-(s-b)t}}{t}=-\frac{1}{s-b}e^{-(s-b)}\bigg|_0^{+\infty}=\frac{1}{s-b}
\end{gather}

\subsection{Proprietà della Traslazione in Frequenza}

La trasformata di un'esponenziale si può interpretare anche come il prodotto di una costante per l'esponenziale:
\begin{gather*}
    \mathcal{L}\left[e^{bt}\cdot 1\right]=\frac{1}{s-b}
\end{gather*}
Considerando ora invece della costante, una funzione generica $f(t)$ si ha:
\begin{gather}
    \mathcal{L}\left[e^{bt}\cdot f(t)\right]=\intpinf{f(t)e^{-(s-b)t}}{t}=F(s-b)
\end{gather}
Dato che la trasformata di Laplace della funzione $f(t)$ è:
\begin{gather*}
    \mathcal{L}[f(t)]=\intpinf{f(t)e^{-st}}{t}=F(s)
\end{gather*}
Quindi effettuando la trasformata di una funzione, moltiplicata per un esponenziale $e^{-bt}$, la funzione risultante è la trasformata della funzione traslata dal fattore costante all'esponente dell'esponenziale, nel dominio $s$. 
Questa proprietà della trasformata si chiama traslazione in frequenza. 

\subsection{Teorema della Derivata e dell'Integrale}

Si vuole calcolare la trasformata della derivata di una funzione generica $f(t)$, sapendo il valore $f(0)$:
\begin{gather*}
    \mathcal{L}[f'(t)]=\intpinf{\frac{\df f(t)}{\df t}e^{-st}}{t}
\end{gather*}
Applicando l'integrazione per parti si ottiene:
\begin{gather*}
    \intpinf{\frac{\df f(t)}{\df t}e^{-st}}{t}=e^{-st}f(t)\bigg|_0^{+\infty}+s\intpinf{f(t)e^{-st}}{t}=-f(0)+sF(s)\\
    \mathcal{L}\left[\frac{\df f(t)}{\df t}\right]=sF(s)-f(0)\tageq
\end{gather*}


Analogamente si determina la trasformata dell'integrale di una funzione generica $f(t)$:
\begin{gather*}
    \mathcal{L}\left[\int_0^t f(\varphi)\df \varphi\right]=\intpinf{e^{-st}\left(\int_0^t f(\varphi)\df\varphi\right)}{t}
\end{gather*}
Si considera questa funzione integrale $g(t)$, e la trasformata della sua derivata:
\begin{gather*}
    g(t)=\int_0^t f(\varphi)\df\varphi\\
    g'(t)=f(t)\\
    \mathcal{L}[g'(t)]=sG(s)-\cancelto{0}{g(0)}=F(s)=\mathcal{L}[f(t)]\\
    \mathcal{L}\left[\int_0^tf(\varphi)\df\varphi\right]=G(s)=\frac{F(s)}{s}\tageq
\end{gather*}

\subsection{Equazioni Differenziali nel Dominio di Laplace}

Si considera il seguente problema di Cauchy:
\begin{gather*}
    \begin{cases}
        y'-y=0\\
        y(0)=1
    \end{cases}
\end{gather*}
La trasformata è un'operazione lineare, dato che l'integrale un operatore lineare; quindi è possibile scomporre la trasformata di una equazione differenziale come la combinazione lineare di trasformate:
\begin{gather*}
    \mathcal{L}[y'-y]=\mathcal{L}[0]\\
    \mathcal{L}[y']-\mathcal{L}[y]=0\\
    sY(s)-\cancelto{1}{y(0)}-Y(s)=0\\
    Y(s)(s-1)=1\implies Y(s)=\frac{1}{s-1}
\end{gather*}
Considerando che $\mathcal{L}[1]=1/s$ e considerando la proprietà della traslazione in frequenza:
\begin{gather*}
    \frac{1}{s-1}=G(s-1)\\
    G(s)=\frac{1}{s}=\implies g(t)=1\\
    Y(s)=G(s-1)=\mathcal{L}[g(t)e^{bt}]=\mathcal{L}[e^t]\\
    y(t)=e^{t}
\end{gather*}
Passando per il dominio di Laplace quindi è possibile risolvere più semplicemente equazioni differenziali, poiché la derivata nel tempo diventa una moltiplicazione per $s$ in frequenza, quindi invece di risolvere un'equazione differenziale si risolve un polinomio rispetto ad $s$. Il passaggio importante è l'antitrasformata, o immediata attraverso trasformate notevoli, oppure utilizzando la definizione per l'antitrasformata, anche se questa non verrà trattata in questo corso. 

Tra le funzioni e le rispettive trasformate è presente una corrispondenza biunivoca, come per la trasformata esiste una trasformata inversa che le riporta in $t$, chiamata antitrasformata di Laplace. Il problema per risolvere le equazioni differenziali diventa quindi la ricerca dell'antitrasformata corrispondente di $Y(s)$. 
Poiché la trasformata è un'operazione lineare, se si scompone $Y(s)$ in fratti semplici e si cercano le funzioni, che trasformate, generano questi termini; allora la loro combinazione lineare sarà la funzione $y(t)$, la cui trasformata corrisponde alla soluzione $Y(s)$ in Laplace. 

\subsection{Proprietà di Scala}

Data una funzione generica $f(t)$ e la sua trasformata $F(s)$, con $s>a$, la trasformata di $f(bt)$ è data da:
\begin{gather}
    \mathcal{L}[f(bt)]=\frac{1}{b}F\left(\frac{s}{b}\right)
\end{gather}
Rimanendo sopra alla soglia $a$, con $s/b>a$, si effettua un cambio di variabile, $u=t/b$ per calcolare direttamente questa proprietà:
\begin{gather*}
    \frac{1}{b}F\left(\frac{s}{b}\right)=\frac{1}{b}\intpinf{e^{-s/bt}f(t)}{t},\,t=ub\\
    \frac{1}{\cancel{b}}\intpinf{e^{-su}f(ub)\bcancel{b}}{u}=\intpinf{e^{-su}f(ub)}{u}=\mathcal{L}[f(ub)]
\end{gather*}
Per cui si è verificata la proprietà. 

\subsection{Teorema dell'Esistenza della Trasformata}

Si considerano due proprietà importanti relative agli integrali impropri. La prima è relativa al criterio del confronto per gli integrali impropri:
\begin{quotation}
    Siano due funzioni $f$ e $g$ continue a tratti per $t>a$, ed un numero arbitrariamente grande $M$. Se si ha $|f(t)|\leq g(t)$ per $t>M$, allora se l'integrale improprio di $g$ converge su $[M,+\infty)$, allora converge anche l'integrale improprio di $f$ sullo stesso intervallo:
    \begin{gather*}
        |f(t)|\leq g(t),\,\,\int_M^{+\infty}g(t)\df t\in\mathbb{R}\implies\int_M^{+\infty}f(t)\df t\in\mathbb{R}
    \end{gather*}

    Analogamente, se $f(t)\geq g(t)\geq0$ per $t\geq M$, allora se l'integrale di $g$ diverge, allora diverge anche l'integrale su $f$:
    \begin{gather*}
        f(t)\geq g(t)\geq0,\,\,\int_M^{+\infty}g(t)\df t=\infty\implies\int_M^{+\infty}f(t)\df t=\infty
    \end{gather*} 
\end{quotation}
%% why tho?? like, is this (^^^) needed at all? idk 

Una funzione $f(t)$ si dice di ordine esponenziale $e^{\alpha t}$ per $\alpha>0$, se esistono due costanti $\exists\,N,k>0$ tali che per $t\geq k$ vale la seguente:
\begin{equation}
    |f(t)|\leq Ne^{\alpha t}
\end{equation} 
Se una funzione $f$ è di ordine esponenziale, allora la funzione ammette trasformata. 

\subsection{Proprietà della Traslazione nel Tempo}

Data una funzione $f(t)$ e la sua trasformata $F(s)$, si considera una traslazione nell'asse $t$ di una quantità $\tau>0$:
\begin{gather*}
    \mathcal{L}[f(t-\tau)]=\intpinf{f(t-\tau)e^{-st}}{t}
\end{gather*}
Applicando una sostituzione $u=t-\tau$ si ottiene:
\begin{gather*}
    \int_{-\tau}^{+\infty}{ f(u)e^{-(u+\tau)s}}{\df u}=e^{-s\tau}\intpinf{f(u)e^{-su}}{u}+e^{-s\tau}\int_{-\tau}^0f(u)e^{-su}\df u\\
    \mathcal{L}[f(t-\tau)]=e^{-s\tau}F(s)+e^{-s\tau}\int_{-\tau}^0f(u)e^{-su}\df u
\end{gather*}
Se $f(t)=0$, per $\tau<0$, come definito all'inizio della sezione per le funzioni trattate, allora l'integrale su $[-\tau,0]$ è nullo, e diventa:
\begin{gather}
    \mathcal{L}[f(t-\tau)]=e^{-s\tau}F(s)
\end{gather}

\subsection{Trasformata di Funzioni Periodiche}

Si considera una funzione $f(t)$ periodica di periodo $\tau$, quindi si ha $f(t+\tau)=f(t)$. Le funzioni generalmente considerate dalla trasformata sono funzioni nulle per valori negativi della variabile $t$. 
Poiché si possono considerare solo funzioni nulle per $t\leq 0$, $f(t)=0$, ma dato che è periodica si ha che deve essere nulla anche per un primo periodo $f(t-\tau)=f(t-\tau+\tau)=f(t)=0$, per $0\leq x\leq\tau$. Quindi deve essere presente un periodo di distanza dall'origine, prima che la funzione possa assumere valori diversi da zero. 


Data una funzione $f$ periodica di periodo $\tau$, la sua trasformata di Laplace è data da:
\begin{equation}
    \mathcal{L}\left[f(t)\right]=\frac{1}{1-e^{-\tau s}}\int_0^\tau e^{-st}f(t)\df t
\end{equation}
Considerando una funzione periodica, di periodo $\tau$, e considerando la sua trasformata di Laplace traslata di $\tau$ si ottiene per la formula di traslazione nel tempo:
\begin{gather*}
    \mathcal{L}\left[f(t-\tau)\right]=e^{-s\tau}\mathcal{L}\left[f(t)\right]
\end{gather*}
Mentre per la definizione della trasformata di Laplace, considerando che $f(t)=0$ in $t\in(-\infty,\tau]$:
\begin{gather*}
    \mathcal{L}\left[f(t-\tau)\right]=
    \int_{\tau}^{+\infty}e^{-st}f(t)\df t=
    \int_{0}^{+\infty}e^{-st}f(t)\df t-\int_{0}^{\tau}e^{-st}f(t)\df t=
    \mathcal{L}\left[f(t)\right]-\int_0^\tau e^{-st}f(t)\df t
\end{gather*}
Eguagliando le due forme ottenute si ha:
\begin{gather*}
    e^{-s\tau}\mathcal{L}\left[f(t)\right]=\mathcal{L}\left[f(t)\right]-\int_0^\tau e^{-st}f(t)\df t\\
    \mathcal{L}\left[f(t)\right]\left(1-e^{-s\tau}\right)=\int_0^\tau e^{-st}f(t)\df t\\
    \mathcal{L}\left[f(t)\right]=\frac{1}{1-e^{-s\tau}}\int_0^\tau e^{-st}f(t)\df t
\end{gather*}
La seguente formula è quindi la trasformata di una funzione periodica. 

\clearpage

\section{Funzioni Multi-Variabili}


Una funzione è definita come $f:D_f\subseteq\mathbb{R}\to C_f\subseteq\mathbb{R}$, si può estendere questa definizione, aumentando la dimensione del dominio:
\begin{gather*}
    f:D_f\subseteq\mathbb{R}^2\to C_f\subseteq\mathbb{R}\\
    P=(x,y)\rightarrow z=f(x,y)
\end{gather*}
Il suo grafico $\mathscr{G}_f$ si può definire come l'insieme dei punti tridimensionali tali che:
\begin{gather*}
    \mathscr{G}_f=\left\{(x,y,z)\in\mathbb{R}^3\big|(x,y)\in D_f,\,z=f(x,y)\right\}
\end{gather*}
Si considera la seguente funzione bidimensionale:
\begin{gather*}
    z=f(x,y)=x^2+y^2
\end{gather*}
Questo paraboloide ha la seguente forma nello spazio tridimensionale: 
%% TODO add img paraboloide da IA-ML
\begin{figure}[H]
    \centering%
    \includegraphics[scale=0.5]{example-image.png}%    
\end{figure}
Tenendo fissa una variabile, e considerando un taglio di questa figura, si ottiene una parabola. 

Aumentando la dimensione del dominio della funzione ulteriormente, impedisce a questa di essere rappresentata:
\begin{gather*}
    f: D_f\subseteq\mathbb{R}^3\to C_f\subseteq\mathbb{R}\\
    P=(x,y,z)\to w=(x,y,z)
\end{gather*}
Aumentando ulteriormente rende ancora più difficile la sua rappresentazione. 


Analogamente è possibile aumentare la dimensione del codominio, in questo modo si crea una funzione vettoriale:
\begin{gather*}
    f:D_f\subseteq\mathbb{R}\to C_f\subseteq\mathbb{R}^2\\
    t\to f(t)=\begin{pmatrix}
        x(t)\\y(t)
    \end{pmatrix}
\end{gather*}
Questa è un'equazione parametrica per rappresentare una curva nel piano. Funzioni vettoriali a due dimensioni, di una variabile reale servono per descrivere pariteticamente una curva nel piano bidimensionale. 

Si può aumentare arbitrariamente l'ordine del codominio, in modo che l'immagine della variabile sia un vettore nello spazio $n$-dimensionale. Le componenti di questo vettore vengono chiamate equazioni parametri di una curva nello spazio. 
% \begin{gather*}
%     f:D_f\subseteq\mathbb{R}\to C_f\subseteq\mathbb{R}^n\\
%     t\to f(t)=\begin{pmatrix}
%         x_1(t)\\\vdots\\x_n(t)
%     \end{pmatrix}
% \end{gather*}
Generalizzando ancora il concetto si può avere un ordine superiore al primo sia per il dominio che pe ril codominio della funzione:.
\begin{gather*}
    f: D_f\subseteq\mathbb{R}^2\to C_f\subseteq\mathbb{R}^3\\
    (u,v)\to f(u,v)=\begin{pmatrix}
        x(u,v)\\y(u,v)\\z(u,v)
    \end{pmatrix}
\end{gather*}
Avendo due variabili indipendenti si definisce un'equazione parametrica per una superficie. Questo tipo di funzioni sono molto usate in fisica per definire spazi campi vettoriali, se le dimensioni di dominio e codominio sono uguali, e altre funzioni per definire campi di forze. 

\subsection{Funzioni Reali a Più variabili Reali}

Dopo aver generalizzato la nozione di funzione, si considerano funzioni reali a più variabili reali: $\mathbb{R}\to\mathbb{R}^n$. 


Si considera la seguente funzione:
\begin{gather*}
    z=f(x,y)=2x^2+2xy-y-5
\end{gather*}
Non sono presenti vincoli sul dominio della funzione, essendo composta solamente da potenze: $D_f\subseteq\mathbb{R}^2$. Altre funzioni invece presentano dei vincoli per definire il loro dominio:
\begin{gather*}
    z=f(x,y)=\sqrt{2x+y-5}
\end{gather*}

Bisogna impostare un vincolo per determinare la scelta appropriata della $x$ e della $y$, il dominio deve considerare nel piano euclideo tutti i numeri reali che soddisfano la condizione:
\begin{gather*}
    2x+y-5\geq0
\end{gather*}
Dal punto di vista teorico non sono presenti problemi, i problemi sono dal punto di vista pratico, bisogna risolvere una disequazione di più incognite. 
Si parte dall'equazione per poi risolvere la disequazione, si considera quindi la retta:
\begin{gather*}
    2x+y-5=0\\
    y=-2x+5
\end{gather*}
Tutti i punti che soddisfano quest'equazione sono punti accettabili. 
%% TODO add img retta 
Dopo aver rappresentato questa retta, si divide il piano in una porzione sopra e sotto alla retta, bisogna determinare la porzione che soddisfa la disequazione $y>-2x+5$, quindi bisogna scegliere tutti i punti superiori alla retta. Il dominio della funzione è individuato dal semipiano superiore alla retta, compresa:
\begin{gather*}
    D_f=\left\{(x,y)\in\mathbb{R}^2\big| 2x+y-5\geq0\right\}
\end{gather*}

%% TODO ex analogo
Data la funzione:
\begin{gather*}
    z=f(x,y)=\displaystyle\frac{2x+y}{x^2+y^2}
\end{gather*}
Questa funzione presente una singolarità, nel punto dove si annulla il denominatore, ovvero dove $x^2+y^2=0$, quindi nell'origine: $D_f=\mathbb{R}^2\setminus\{(0,0)\}$



Considerare la seguente funzione:
\begin{gather*}
    z=f(x,y)=\displaystyle\frac{\sqrt[4]{x^2+y^2-2x-4y-11}}{\ln(2x+y)}
\end{gather*}
Per definire il suo dominio, bisogna utilizzare tre vincoli, uno per la radice, uno per il denominatore, ed uno per il logaritmo:
\begin{gather*}
    \begin{cases}
        x^2+y^2-2x-4y-11\geq0\\
        \ln(2x+y)\neq0\\
        2x+y>0
    \end{cases}
\end{gather*}
Partendo dall'ultima disequazione si considera la retta $2x+y=0\to y=-2x$, poiché è una relazione stretta, i punti che appartengono a questa equazione vanno scartati. 
% x   | y
% -------
% 0   | 0
% 1/2 | 1
%% TODO add img retta e piano 
Essendo $y>-2x$ si considerano tutti i punti sopra a questa retta. Passando alla seconda disequazione, affinché il logaritmo non sia nullo bisogna imporre:
\begin{gather*}
    2x+y\neq1\\
    y\neq-2x+1
\end{gather*}
Rappresentando questa retta, bisogna escludere solamente i punti di questa retta $y=-2x+1$. 
%% TODO add img retta sovrapposta al semipiano precedente
La prima disequazione rappresenta un'equazione di un cerchio, centrato in punto da determinare:
\begin{gather*}
    x^2+y^2-2x-4y-11\geq0\\
    (x^2-2x+1)+(y^2-4y+4)-16\geq0\\
    (x-1)^2+(y-4)^2\geq4^2
\end{gather*}
Si è ottenuta l'equazione di una circonferenza, di raggio 4 e centro in $(2,4)$:
\begin{gather*}
    (x-1)^2+(y-4)^2=4^2
\end{gather*}
%% TODO add img circonferenza al semipiano precedente
Questo vincolo esclude tutti i punti interni, circonferenza esclusa. Il dominio della funzione è quindi data da:
\begin{gather*}
    D_f=\left\{(x,y)\in\mathbb{R}^2\big|(x-1)^2+(y-4)^2\geq4^2\land y\neq-2x+1\land y>-2x\right\}
\end{gather*}

\subsubsection{Limite Multi-Variabile}

Considerare la seguente funzione:
\begin{gather*}
    z=f(x,y)=\displaystyle\frac{\arcsin(2x+y)}{\sqrt{5-2x-3y}}
\end{gather*}
Per determinare il dominio della funzione, bisogna analizzare il comportamento della funzione in punti di accumulazione ed analizzare il loro comportamento, generalizzando il concetto di limite. La distanza euclidea in due dimensioni, dati due punti $P=(x_p,y_p)$ e $Q=(x_q,y_q)$, è data da:
\begin{gather*}
    \df(PA)=\sqrt{(x_p-x_q)^2+(y_p-y_q)^2}
\end{gather*}
Si deve definire l'intorno di un punto in due dimensioni $P_0(x_0,y_0)$, di raggio $\delta>0$:
\begin{equation}
    I_\delta(P_0)=\left\{P\in\mathbb{R}^2\big| \df (P_0P)<\delta\right\}
\end{equation}
%% TODO add img intorno aperto, senza circonferenza
Dato l'intorno sferico di un punto, bisogna definire il punto di accumulazione, e studiare il comportamento della funzione in questo punto. 
$P_0\in\mathbb{R}^2$ è punto di accumulazione di $D_f$ se $\forall\delta>0$ si ha che l'intorno sferico di raggio $\delta$ bucato $I_\delta(P_0)\setminus\{P_0\}$ deve contenere almeno un punto del dominio:
\begin{equation}
    \left(I_\delta(P_0)\setminus\{P_0\}\right)\cap D_f\neq0
\end{equation}
Ci si può avvicinare arbitrariamente al punto $P_0$, senza mai lasciare il dominio $D_f$. 

Si suppone di avere una funzione $f$ definita su un piano euclideo ed ha valori reali:
\begin{gather*}
    f: D_f\subseteq\mathbb{R}^2\to C_f\subseteq\mathbb{R}
    (x,y)\to x=f(x,y)% funzione analitica
\end{gather*}
Si considera un punto di accumulazione $P_0\in\mathbb{R}^2$ del dominio $D_f$. 

Il limite della funzione, avvicinandosi al punto $P_0$ può essere:
\begin{gather*}
    \lim_{P\to P_0}f(x,y)=\lim_{(x,y)\to (x_0,y_0)}f(x,y)=\begin{cases}
        l\in\mathbb{R}\\
        \pm\infty\\
        \nexists
    \end{cases}
\end{gather*}
Nei primi due casi la funzione è regolare, mentre nel terzo caso la funzione è irregolare. 

Si estende il concetto di continuità, se il limite di $P\to P_0$ di $f$ esiste ed ha un valore $l$, allora se $\forall\varepsilon>0\,\exists\delta_\varepsilon>0$ talle che $\forall P\in D_f$ per cui $\df(P_0P)<\delta_\varepsilon$ allora $|f(x,y)<l+\varepsilon$. 
\begin{equation}
    \forall\varepsilon>0\,\exists\delta_\varepsilon>0\big|\forall P\in D_f\mbox{ per cui }\df(P_0P)<\delta_\varepsilon\implies l-\varepsilon<f(x,y)<l+\varepsilon
\end{equation}
Allora la funzione è continua in $P_0$ se:
\begin{equation}
    \lim_{P\to P_0}f(x,y)=f(x_0,y_0)
\end{equation}
Dal punto di vista applicativo su una sola dimensione è sufficiente controllare due limiti, da destra e da sinatra, poiché sono gli unici due modi in cui si può tendere al punto di accumulazione $x_0$. Ma in più di una dimensione sono presenti infiniti modi di tendere ad un punto di accumulazione $P_0$. 
Il problema è individuare le traiettorie che portano al punto di accumulazione, se esistono due traiettorie per cui il limite non esiste, allora il limite non esiste. 
Si considera il seguente limite:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{xy}{x^2+y^2}
\end{gather*}
Si fissa $x=0$ e si considera di arrivare a $P_0$ per $y\to 0^+$, quindi il punto $P$ di partenza appartiene all'asse $y$:
\begin{gather*}
    \lim_{y\to0}\displaystyle\frac{0}{0+y^2}=0
\end{gather*}
Analogamente se ci si muove sull'asse delle $x$:
\begin{gather*}
    \lim_{x\to0}\displaystyle\frac{0}{x^2+0}=0
\end{gather*}
Si ci si muove sulla bisettrice del primo quadrante, definita da $y=x$, si ha invece:
\begin{gather*}
    \lim_{x=y\to0}\displaystyle\frac{x^2}{2x^2}=\frac{1}{2}
\end{gather*}
Secondo la bisettrice quindi il limite è diverso, ma poiché un limite non può avere valori diversi per traiettorie diverse, è irregolare. Quindi non è possibile estendere la funzione al punto $P_0=(0,0)$. 

Invece considerando il seguente limite:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^3}{x^2+y^2}
\end{gather*}
Se ci si muove sull'asse $x$ o $y$, si ha lo stesso limite pari a zero, così per la bisettrice. L'unico strumento, in questo corso, per calcolare questi limiti è il passaggio alle coordinate polari: $(x,y)\to(\rho,\theta)$:
\begin{gather*}
    \begin{cases}
        x=x_0+\rho\cos\theta\\
        y=y_0+\rho\sin\theta\\
    \end{cases}
\end{gather*}
In questo caso il punto di accumulazione $P_0$ si trova nell'origine, quindi:
\begin{gather*}
    \begin{cases}
        x=\rho\cos\theta\\
        y=\rho\sin\theta\\
    \end{cases}    
\end{gather*}
Applicando questa sostituzione il limite diventa:
\begin{gather*}
    \lim_{\rho\to0}\displaystyle\frac{\rho^3\cos^3\theta}{\rho^2(\cancelto{1}{\cos^2\theta+\sin^2\theta})}=\lim_{\rho\to0}\rho\cos^3\theta
\end{gather*}
Se si può eliminare la presenza del parametro $\theta$, si può ragionare solamente con il parametro $\rho$ e risolvere direttamente questo limite. Si applica quindi il teorema del confronto:
\begin{gather*}
    -\rho\leq\rho\cos^3\theta\leq\rho
\end{gather*}
Studiare questo limite è come studiare il limite degli estremi, e se questi coincidono allora il valore del limite coincide a questo valore, per il teorema del confronto:
\begin{gather*}
    \lim_{\rho\to0}-\rho=\lim_{\rho\to0}\rho=0\\
    \lim_{\rho\to0}\rho\cos^3\theta=0
\end{gather*}
Quindi il limite originale esiste e tende a zero:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^3}{x^2+y^2}=0
\end{gather*}
Tendenzialmente si svincolano le dipendenze a $\theta$ tramite il confronto $|\cos\theta|\leq1$ e $|\sin\theta|\leq1$. 


Si considera il seguente limite:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^3y}{x^2+y^2}\\
    \lim_{\rho\to0}\displaystyle\frac{\rho^3\cos^3\theta\cdot\rho\sin\theta}{\rho^2}\\
    \lim_{\rho\to0}\rho^2\cos^3\theta\sin\theta    
\end{gather*}
Per il teorema del confronto si ha:
\begin{gather*}
    -\rho\leq\rho\cos^3\theta\sin\theta\leq\rho\\
    \lim_{\rho\to0}-\rho=\lim_{\rho\to0}\rho=0\\
    \lim_{\rho\to0}\rho\cos^3\theta\sin\theta=0
\end{gather*}
Il limite quindi è definito ed ha valore:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^3y}{x^2+y^2}=0
\end{gather*}

% recap su vari limiti xy/x^2+y^2: \nexists
%% RECAP

Si considera una funzione il cui limite non esiste nell'origine:
\begin{gather*}
    f(x,y)=\begin{cases}
        \displaystyle\frac{\strut xy}{\strut x^2+y^2}&(x,y)\neq(0,0)\\
        0&(x,y)=(0,0)
    \end{cases}
\end{gather*}
In questo modo è definita nell'origine, ma affinché sia continua anche nell'origine, il valore del limite, deve coincidere al valore della funzione nell'origine:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}f(x,y)\neq f(0,0)=0
\end{gather*}
Dato che il limite non esiste, allora non può essere uguale a zero, e non è continua nell'origine, ma è definita su tutto il dominio $D_f=\mathbb{R}^2$. 

Il passaggio a coordinate polari, con centro in $(x_0,y_0)$ permette di risolvere questi limiti. Dopo aver cambiato le coordinate, si prova svincolare il calcolo dall'angolo $\theta$, in modo da renderlo indipendente dalla traiettoria. 



%% TODO add to esercizi
Determinare se esiste un valore $\alpha\in\mathbb{R}$ tale che la seguente funzione è continua:
\begin{gather*}
    f(x,y)=
    \begin{cases}
        \displaystyle\frac{\strut x^4+y^2e^x}{\strut\sqrt{x^2+y^2}}&(x,y)\neq(0,0)\\
        \alpha&(x,y)=(0,0)    
    \end{cases}
\end{gather*}

Non si riesce ad individuare due traiettorie per cui il limite diverge, quindi si calcola direttamente, effettuando un cambiamento di coordinate:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{x^4+y^2e^x}{\sqrt{x^2+y^2}}=
    \lim_{\rho\to0}\frac{\rho^4\cos^4\theta+\rho^2\sin^2\theta e^{\rho\cos\theta}}{\rho}=
    \lim_{\rho\to0}\rho^3\cos^4\theta+\rho\sin^2\theta (1+\cos\theta+o[\rho])
\end{gather*}
Si usa una formula di Maclaurin dell'esponenziale per riscrivere l'esponenziale come:
\begin{gather*}
    e^t=1+t+o[t]\mbox{ per }t\to0
\end{gather*}
Il limite diventa:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\rho^3\cos^4\theta+\rho\sin^2+\rho^2\cos^2\theta\sin\theta+o[\rho^2]
\end{gather*}
Tutti i termini in questo limite tendono a zero, quindi il limite tende a zero. 
La funzione originale quindi è continua se $\alpha=0$:
\begin{gather*}
    f(x,y)=
    \begin{cases}
        \displaystyle\frac{\strut x^4+y^2e^x}{\strut\sqrt{x^2+y^2}}&(x,y)\neq(0,0)\\
        0&(x,y)=(0,0)    
    \end{cases}
\end{gather*}


Determinare il valore $\alpha\in\mathbb{R}$ per cui la funzione data risulti continua anche nell'origine:
\begin{gather*}
    f(x,y)=
    \begin{cases}
        \displaystyle\frac{\strut x^2y^2}{\strut3x^2+y^2}&(x,y)\neq(0,0)\\
        \alpha&(x,y)=(0,0)    
    \end{cases}
\end{gather*}
Si effettua un cambio di coordinate nel limite per coordinate polari centrate nell'origine:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}\displaystyle\frac{\strut x^2y^2}{\strut3x^2+y^2}=
    \lim_{\rho\to0}\frac{\rho^4\cos^2\theta\sin^2\theta}{\rho^2\left(3\cos^2\theta+\sin^2\right)}=
    \lim_{\rho\to0}\frac{\rho^2\cos^2\theta\sin^2\theta}{2\cos^2\theta+1}
\end{gather*}
Il denominatore è sempre maggiore o uguale a zero, quindi per il teorema del confronto si ha:
\begin{gather*}
    0\leq\frac{\rho^2\cos^2\theta\sin^2\theta}{2\cos^2\theta+1}\leq\rho^2\sin^2\theta\cos^2\theta\leq\rho^2\to0
\end{gather*}
Essendo sia il limite maggiorante che minorante tendente a zero, allora il limite converge a zero, ed il valore $\alpha=0$:
\begin{gather*}
    f(x,y)=
    \begin{cases}
        \displaystyle\frac{\strut x^2y^2}{\strut3x^2+y^2}&(x,y)\neq(0,0)\\
        0&(x,y)=(0,0)    
    \end{cases}
\end{gather*}

\subsection{Derivate Parziali}

Si suppone di avere una funzione $z=f(x,y)$, definita nel dominio $D_f$. Si suppone esista un punto $P_0=(x_0,y_0)\in D_f\cap\mathscr{D}D_f$, punto di accumulazione, derivabile di $f$. %% TODO simbolo per insieme derivabile

%% TODO add img grafico

Si considera un incremento solamente sull'asse $x$, dal punto $P_0$, per quantificare questo incremento si considera la differenza del valore di $z$: $\Delta z$, in seguito a questo incremento, ovvero il rapporto incrementale:
\begin{gather*}
    \displaystyle\frac{f(x_0+h,y)-f(x_0,y_0)}{h}
\end{gather*}
Si considera il limite di questo rapporto incrementale:
\begin{gather*}
    \lim_{h\to0}\displaystyle\frac{f(x_0+h,y)-f(x_0,y_0)}{h}=l\in\mathbb{R}
\end{gather*}
Se questo limite del rapporto incrementale ottenuto aumentando solamente la variabile indipendente $x$, esiste ed è finito, allora la funzione $f$ si dice parzialmente derivabile rispetto ad $x$ nel punto $x_0$. Se esiste ed è finito, si indica come:
\begin{gather*}
    f_x(P_0)=f_x(x_0,y_0)=\displaystyle\frac{\partial f}{\partial x}(x_0,y_0)
\end{gather*}
Questa viene chiamata derivata parziale di $f$ rispetto ad $x$ nel punto $P_0$. 

Analogamente si considera un incremento solamente sulla variabile indipendente $y$ di $k$. A seguito di questo spostamento fino al punto $P(x_0,y_0+k)$ del dominio, anche la funzione subisce un incremento. Si considera ora il rapporto incrementale dovuto a questo incremento:
\begin{gather*}
    \lim_{k\to0}\displaystyle\frac{f(x_0,y_0+k)-f(x_0,y_0)}{k}=l\in\mathbb{R}
\end{gather*}
Se esiste ed è definito il limite del rapporto incrementale, allora la funzione si dice parzialmente derivabile rispetto a $y$ nel punto $y_0$. Si rappresenta analogamente come:
\begin{gather*}
    f_y(P_0)=f_y(x_0,y_0)=\displaystyle\frac{\partial f}{\partial y}(x_0,y_0)
\end{gather*}
% È il concetto di differnziabilità che estende il concetto di derivabilità. 
%% TODO add affinché esiste il piano derivata allora la funzione deve essere differenziabile

Si considera una funzione polinomiale $f$, definita e continua su $D_f\in\mathbb{R}^2$:
\begin{gather*}
    f(x,y)=2x^3+5x^2y+3xy^4-2y^3
\end{gather*}
La funzione è parzialmente derivabile rispetto a $x$ ed $y$ in tutti i punti di $\mathbb{R}^2$. Per calcolare la derivata si utilizza il calcolo dei limiti delle derivate:
\begin{gather*}
    f_x(x,y)=6x^2+10xy+3y^4=\displaystyle\frac{\partial f}{\partial x}\\
    f_y(x,y)=5x^2+12xy^3-6y^2=\displaystyle\frac{\partial f}{\partial y}
\end{gather*}
%% TODO cambiare con de/de
Si possono derivare nuovamente rispetto $x$ ed $y$, formando derivate parziali miste:
\begin{gather*}
    f_{xx}(x,y)=12x+10y=\displaystyle\frac{\partial^2 f}{\partial x^2}\\
    f_{xy}=10x+12y^3=\displaystyle\frac{\partial^2 f}{\partial y\partial x}\\
    f_{yx}=10x+12y^3=\displaystyle\frac{\partial^2 f}{\partial x\partial y}\\
    f_{yy}=36xy^2-12y=\displaystyle\frac{\partial^2f}{\partial y^2}
\end{gather*}
L'ordine delle variabili è rilevante, dato che due derivate parziali miste non sono necessariamente equivalenti $f_{xy}\neq f_{yx}$, ma se la funzione è continua allora per il teorema di Schwarz le derivate parziali miste sono uguali. 

Date queste derivate parziali seconde si possono ottenere le derivate terze, derivando parzialmente queste altre funzioni. 

%% TODO determinare dov'è derivabile la funzione f = 2x\ln(x+2y^2+1)+3y^2
% parabola x > -2y^2-1: punti a destra e non della parabola sono validi per la continuità


%% TODO add 2/5/25


In una dimensione, se una funzione è derivabile in un punto, allora è anche continua in quel punto, mentre questo concetto non si estende in due dimensioni, quindi se una funzione bidimensionale è derivabile in un punto $P_0$ sia rispetto ad $x$ che ad $y$, questo non implica che sia continua nello stesso punto $P_0$. 
Un esempio di una funzione del genere è la seguente:
\begin{gather*}
    f(x,y)=\begin{cases}
        \displaystyle\frac{\strut xy}{\strut x^2+y^2}&(x,y)\neq(0,0)\\
        0&(x,y)=(0,0)
    \end{cases}
\end{gather*}


Affinché sia continua il limite della funzione tendente all'origine deve essere uguale a zero:
\begin{gather*}
    \lim_{(x,y)\to(0,0)}f(x,y)=\nexists
\end{gather*}
Questo limite è già stato dimostrato che non converge, per una traiettoria bisettrice infatti converge a $1/2$, metre su una traiettoria che si muove solamente lungo uno dei due assi, converge a $0$. La funzione non ammette limite, quindi non è continua nel punto $(0,0)$. Per essere continua deve essere regolare e valere $0$. 


Dal punto di vista grafico per studiare la derivabilità bisogna considerare un incremento $h$ sull'asse $x$ ed $y$, e si studia il limite di questa funzione, rispetto all'origine:
\begin{gather*}
    \lim_{h\to0}\displaystyle\frac{f(h,0)-f(0,0)}{h}=\lim_{h\to0}\frac{0-0}{h}=0
\end{gather*}
Questo diventa un limite di una funzione ad una variabile. La derivata parziale rispetto ad $x$ nell'origine esiste e vale $0$, analogamente per simmetria si ha che esiste anche la derivata parziale rispetto ad $y$ e vale anch'essa zero:
\begin{gather*}
    \displaystyle\frac{\partial f}{\partial x}(0,0)=0\\
    \displaystyle\frac{\partial f}{\partial y}(0,0)=0
\end{gather*}

\subsection{Integrali Doppi}

Un'integrale doppio è definito su un dominio di integrazione $D\in\mathbb{R}^2$, e si indica come:
\begin{gather*}
    \iint_Df(x,y)\df x\df y
\end{gather*}
Si semplifica l'analisi di questi integrali imponendo che questo dominio $D$ sia un dominio normale rispetto all'asse $x$, è l'insieme dei punti del piano tali che la variabile indipendente $x$ si deve muovere esclusivamente tra due costanti:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\bigg|a\leq x\leq b,\alpha(x)\leq y\leq\beta(x)\right\}
\end{gather*}
Dove $\alpha$ e $\beta$ sono continue in $[a,b]$. 

%% TODO img esempio dominio normale di integrazione rispetto all'asse x

Il caso più semplice è che il dominio normale di integrazione è un rettangolo. Si utilizza questa definizione di domino poiché esiste una formula che semplifica il calcolo di integrali doppi, a cui verrà attribuito anche un significato geometrico. 
Un'integrale doppio si può calcolare come il prodotto tra due integrali:
\begin{gather*}
    \displaystyle\iint_D f(x,y)\df x \df y=\int_a^b\df x\int_{\alpha(x)}^{\beta(x)}f(x,y)\df y
\end{gather*}
Questo integrale rappresenta il volume del sotto-grafico, è un'estensione della relazione tra area sottesa da un grafico ed integrale monodimensionale. 

C'è anche la possibilità di definire un domino normale rispetto all'asse $y$, ed in questo caso si inverte il ruolo delle due variabili. 

%% TODO img esempio dominio normale di integrazione rispetto all'asse y
Per questi integrali vale la proprietà additiva $D=D_1\cup D_2$, quindi l'integrale su $D$ è uguale alla somma tra gli integrali su $D_1$ e $D_2$. 

Si considera un triangolo $T$ nel piano definito da tre vertici $A=(0,0)$, $B=(2,0)$ e $C=(1,1)$, si vuole calcolare l'integrale su questo triangolo della funzione $f=xy+y^2$:
\begin{gather*}
    \iint_T(xy+y^2)\df x\df y
\end{gather*}

%% TODO img triangolo
Si utilizza la formula:
\begin{gather*}
    a=0\land b=2\\
    \alpha(x)=0\land
    \beta(x)=\begin{cases}
        x&0\leq x\leq 1\\
        2-x &1\leq x\leq 2
    \end{cases}\\
\end{gather*}
Si divide l'intervallo di integrazione in $T_1$ e $T_2$ e si ottiene quindi:
\begin{gather*}
    \iint_T(xy+y^2)\df x\df y=
    \int_0^1\df x\int_{0}^{x}(xy+y^2)\df y+
    \int_1^2\df x\int_{0}^{2-x}(xy+y^2)\df y\\
    \int_0^1\df x\left(\frac{1}{2}x^3+\frac{1}{3}x^3\right)+
    \int_1^2\df x\left(\frac{1}{2}x(2-x)^2+\frac{1}{3}(2-x)^3\right)\\
    \displaystyle\frac{5}{6}\int_0^1x^3\df x+\int_1^2\frac{1}{2}\left(x^3-4x^2+4x\right)+\frac{1}{3}\left(-x^3+6x^2-12x+8\right)\df x\\
    \frac{5}{24}+\int_1^2\frac{1}{6}x^3-2x+\frac{8}{3}\df x=\frac{5}{24}+\left[\frac{1}{24}x^4-x^2+\frac{8}{3}x\right]_1^2\\
    \frac{5}{25}+\left(\frac{16}{24}-4+\frac{16}{3}\right)-\left(\frac{1}{24}-1+\frac{8}{3}\right)=\frac{20}{24}-3+\frac{8}{3}=\frac{20-3\cdot24+8\cdot8}{24}=\frac{84-72}{24}=\frac{1}{2}
\end{gather*}


Si considera il seguente integrale doppio:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y
\end{gather*}
Dove $D=[1,2]\times[0,1]$.
%% TODO img dominio di integrazione sull'asse xy
Si risolve mediante la formula:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y=\int_1^2\df x\int_0^1(x^2+y^2)\df y=\int_1^2\left[x^2y+\frac{1}{3}y^3\right]_0^1\df x\\
    \int_1^2\left(x^2+\frac{1}{3}\right)\df x=\frac{1}{3}\left[x^3+x\right]_1^2=\frac{1}{3}(8+2-1-1)=\frac{8}{3}
\end{gather*}
Si considera ora il dominio normale rispetto all'asse $y$:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y=\int_0^1\df y\int_1^2(x^2+y^2)\df x=
    \int_0^1\left[y^2x+\frac{1}{3}x^3\right]_1^2\df y\\
    \int_0^1\left(y^2+\frac{7}{3}\right)\df y=\frac{1}{3}\left[y^3+7y\right]_0^1=\frac{1}{3}(1+7-0)=\frac{8}{3}
\end{gather*}


Si considera il seguente integrale:
\begin{gather*}
    \iint_D xy\df x \df y
\end{gather*}
Dove $D$ è il dominio delimitato nel primo quadrante costituito ad un quarto di cerchio, centrato nell'origine e di raggio 1. Questo dominio è normale sia rispetto all'asse $x$ che rispetto all'asse $y$. Si considera il dominio di integrazione normale rispetto all'asse $x$ e si applica la formula di riduzione:
\begin{gather*}
    x\in[0,1]
    y\in\left[\alpha(x)=0,\beta(b)=\sqrt{1-x^2}\right]\\
    \iint_D xy\df x \df y=\int_0^1\df x\int_0^{\sqrt{1-x^2}}xy\df y=\int_0^1 x\df x\int_0^{\sqrt{1-x^2}}y\df y=
    \frac{1}{2}\int_0^1 x\left(\sqrt{1-x^2}\right)^2\df x\\
    \frac{1}{2}\int_0^1 (x-x^3)\df x=\frac{1}{2}\left[\frac{1}{2}x^2-\frac{1}{4}x^4\right]_0^1=\frac{1}{2}\left(\frac{1}{2}-\frac{1}{4}\right)=\frac{1}{8}
\end{gather*}

Applicando la formula poiché $x$ è indipendente da $y$ si può spostare direttamente all'integrale esterno, ma i due integrali non si possono separare come il prodotto di due integrali, poiché la variabile $y$ dipende ancora da $x$ quindi devono essere calcolati insieme. 

Si considera lo stesso integrale, dove il dominio di integrazione è dato da $D=[0,1]\times[0,1]$:
\begin{gather*}
    \iint_D xy\df x\df y=\int_0^1\df x\int_0^1 xy\df y
\end{gather*}
Poiché le due variabili sono indipendenti, e l'intervallo di integrazione di $y$ è indipendente dalla variabile $x$, si possono trattare i due integrali come indipendenti e quindi si può trattare come fosse un prodotto di integrali:
\begin{gather*}
    \int_0^1\df x\int_0^1 xy\df y=\int_0^1 x\df x\cdot\int_0^1 y\df y
\end{gather*}


Si considera l'integrale:
\begin{gather*}
    \iint_D(x+y)\df x \df y
\end{gather*}
Dove il dominio $D$ è definito sul primo quadrante tale che:
\begin{gather*}
    x^2+y^2\leq1\\
    y\leq2x
\end{gather*}
Per definire il dominio si considerano le due equazioni $x^2+y^2=1$ e $y=2x$. I punti della prima equazione sono tutti i punti che si trovano sulla circonferenza di raggio 1 e centrata nell'origine, quindi si considerano tutti i punti dell'arco di circonferenza nel primo quadrante. Poiché la relazione è $x^2+y^2<1$, si considerano tutti i punti interni alla circonferenza, quindi tutti i punti nel primo quadrante appartenente a questo spicchio di circonferenza. 
Considerando ora la seconda equazione, la retta $y=2x$, i punti del piano che la soddisfano sono tutti i punti del piano al di sotto di questa retta, $y<2x$. 
%% TODO img dominio di integrazione intersezione tra primo quadrante, retta y=2x e cerchio (0,0) 1

La funzione $\beta(x)$ è composta da due funzioni la prima è un tratto di retta, la seconda è un arco di circonferenza, quindi conviene utilizzare la proprietà additiva per dividere in due il domino $D$ nel punto di intersezione sull'asse $x$ di queste due funzioni:
\begin{gather*}
    \beta_1(x)=2x\\
    \beta_2(x)=\sqrt{1-x^2}\\
    2x=\sqrt{1-x^2}\\
    4x^2=1-x^2\\
    5x^2=1\implies x=\pm\frac{1}{\sqrt{5}}=\pm\frac{\sqrt{5}}{5}
\end{gather*}
Si considerano solo i punti nel primo quadrante si considerano solo i valori positivi. I due domini di integrazione $D_1$ e $D_2$ sono quindi:
\begin{gather*}
    D_1=\left\{(x,y)\in\mathbb{R}^2\bigg|0\leq x\leq \frac{\sqrt{5}}{5}\land 0\leq y\leq 2x\right\}\\
    D_2=\left\{(x,y)\in\mathbb{R}^2\bigg|\frac{\sqrt{5}}{5}\leq x\leq 1\land 0\leq y\leq \sqrt{1-x^2}\right\}\\
    \iint_D(x+y)\df x \df y=\overbrace{\iint_{D_1}(x+y)\df x \df y}^{I_1}+\underbrace{\iint_{D_2}(x+y)\df x \df y}_{I_2}
\end{gather*}
A questo punto si analizzano individualmente i due integrali $I_1$ e $I_2$. Si utilizza la formula di risoluzione:
\begin{gather*}
    I_1=\iint_{D_1}(x+y)\df x \df y=\int_0^{1/\sqrt{5}}\df x\int_0^{2x}(x+y)\df y=\int_0^{1/\sqrt{5}}\left[xy+\frac{1}{2}y^2\right]_0^{2x}\df x\\
    \int_0^{1/\sqrt{5}}2x^2+2x^2\df x=4\int_0^{{1}/{\sqrt{5}}}x^2\df x=\left[\frac{4}{3}x^3\right]_0^{1/\sqrt{5}}=\frac{4}{3\sqrt{125}}
\end{gather*}
Si considera il secondo integrale:
\begin{gather*}
    I_2=\iint_{D_1}(x+y)\df x \df y=\int_{1/\sqrt{5}}^1\df x\int_0^{\sqrt{1-x^2}}(x+y)\df y=
    \int_{1/\sqrt{5}}^1\left[xy+\frac{1}{2}y^2\right]_0^{\sqrt{1-x^2}}\df x\\
    \int_{1/\sqrt{5}}^1x\sqrt{1-x^2}+\frac{1}{2}\left(\sqrt{1-x^2}\right)^2\df x=
    \overbrace{\int_{1/\sqrt{5}}^1x\sqrt{1-x^2}\df x}_{I_3}+\underbrace{\frac{1}{2}\int_0^{1/\sqrt{5}}(1-x^2)\df x}_{I_4}\\
    % I_4=\int_0^{1/\sqrt{5}}1-x^2\df x=\frac{1}{2}\left[\right]
\end{gather*}
%% TODO finire calcolo integrale



Calcolare l'integrale doppio della funzione $x^2+y^2$ per un dominio che giace sul primo e secondo quadrante, sotteso dalle curve $y=0$ e $1-x^2$:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y=\int_{-1}^1\df x\int_0^{1-x^2}(x^2+y^2)\df y=\int_{-1}^1\left[x^2y+\frac{1}{3}y^3\right]_0^{1-x^2}\df x\\
    \int_{-1}^1x^2(1-x^2)+\frac{1}{3}(1-x^2)^3\df x=
    \int_{-1}^1\cancel{x^2}\cancel{-x^4}+\frac{1}{3}\bcancel{-x^2}\bcancel{+x^4}-\frac{1}{3}x^6\df x\\
    \frac{1}{3}\int_{-1}^11-x^6\df x=\frac{1}{3}\left[x-\frac{1}{7}x^7\right]_{-1}^1=\frac{2}{3}\left[x-\frac{1}{7}x^7\right]_0^1=\frac{2}{\cancel{3}}\cdot\frac{\cancelto{2}{6}}{7}=\frac{4}{7}
\end{gather*}


Calcolare l'area della regione giacente nel primo quadrante delimitata dalle curve di equazione $y=x$ e $y^2=2x$. Se la funzione integranda è costante ed uguale ad uno, allora l'integrale doppio rappresenta l'area del dominio di integrazione:
\begin{gather*}
    \iint_D\df x\df y=\int_0^{x_0}\df x\int_x^{\sqrt{2x}}\df y
\end{gather*}
Il problema è quindi determinare il dominio di integrazione. Dal punto di vista geometrico bisogna individuare l'ascissa $x_0$ dell'intersezione delle due curve:
\begin{gather*}
    y=\frac{y^2}{2}\implies y=2
\end{gather*}
Si risolve quindi l'integrale:
\begin{gather*}
    \iint_D\df x\df y=\int_0^2\df x\int_x^{\sqrt{2x}}\df y=\int_0^2(\sqrt{2x}-x)\df x=
    \left[\frac{4\sqrt{2}}{3}x^{3/2}-\frac{1}{2}x^2\right]_0^2=\frac{4\sqrt{2}}{3}2\sqrt{2}-2=\frac{10}{3}
\end{gather*}

\subsubsection*{Esercizi 16/5/25}

Calcolare il seguente integrale doppio:
\begin{gather*}
    \iint_D\frac{x}{x+y+1}\df x\df y
\end{gather*}
Dove il dominio $D$ è dato da:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\land x\leq y\land x+y\leq 2\right\}
\end{gather*}
Per la prima disequazione il dominio di integrazione si trova nel primo e quarto quadrante. La seconda disequazione divide il piano in due porzioni, essendo una bisettrice del primo quadrante, poiché contiene tutti i punti $(x,y)$ dove si ha $y\geq x$, allora si considera la porzione superiore di piano divisa da questa bisettrice, semiretta compresa, nel primo quadrante. 
Si considera ora l'ultima disequazione:
\begin{gather*}
    x+y\leq2\\
    y=2-x
\end{gather*}
Questa individua una retta che nel primo quadrante è individuata dai punti $(2,0)$ e $(0,2)$, questa interseca la seconda disequazione nel punto $(1,1)$. Si considerano tutti i punti nella parte inferiore individuati da questa retta, retta compresa. 
Considerando l'intersezione con le altre disequazioni individuate, allora il dominio di integrazione $D$ è un triangolo individuato dai punti $(0,0)$, $(2,0)$ e $(1,1)$. Si può esprimere come:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\leq1\land x\leq y\leq2-x\right\}
\end{gather*}
Questo dominio è normale rispetto all'asse $x$, quindi si considera la formula:
\begin{gather*}
    \iint_D\frac{x}{x+y+1}\df x\df y=\int_0^1\df x\int_{x}^{2-x}\frac{x}{x+y+1}\df y
\end{gather*}
Non essendo indipendenti non si possono separare. Si calcola quindi il primo integrale facilmente essendo immediato:
\begin{gather*}
    \int_0^1\df x\int_{x}^{2-x}\frac{x}{x+y+1}\df y=
    \int_0^1x\left[\ln|x+y+1|\right]_x^{2-x}\df x=
    \int_0^1x\ln3 - x\ln|2x+1|\df x\\
    \ln3\left[\frac{x^2}{2}\right]_0^1-\int_0^1x\ln|2x+1|\df x    
\end{gather*}
Si risolve questo secondo integrale tramite integrazione per parti:
\begin{gather*}
    \ln\sqrt{3}-\left(\ln|2x+1|\cdot\frac{x^2}{2}\bigg|_0^1-\frac{2}{2}\int_0^1\frac{x^2}{2x+1}\df x\right)=
    \cancel{\ln\sqrt{3}}-\bcancel{\ln\sqrt{3}}+\int_0^1\frac{x^2}{2x+1}\df x\\
    \iint_D\frac{x}{x+y+1}\df x\df y=\int_0^1\frac{x^2}{2x+1}\df x=\frac{\ln3}{8}
\end{gather*}
% Si effettua la divisione tra polinomi: 
% \begin{gather*}
%     \frac{x^2}{2x+1}=Ax+\frac{Bx+C}{2x+1}\\
%     Ax(2x+1)+Bx+C=x^2\\
%     2Ax^2+Ax+Bx+C=x^2\\
%     A=\frac{1}{2},B=-\frac{1}{2}
% \end{gather*}
%  x^2 0 0 | 2x 1
%% TODO risolvere integrale


Si considera lo stesso esercizio, dove il dominio di integrazione consiste nel trapezoide definito dai punti $(0,0)$, $(1,0)$, $(1,1)$ e $(2,0)$. Quindi è sufficiente aggiungere al valore ottenuto dal precedente esercizio all'integrale doppio sul dominio di integrazione individuato dai punti $(0,0)$, $(1,1)$, $(1,0)$:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big| 0\leq x\leq1\land 0\leq y\leq x\right\}
\end{gather*}
%% TODO risolvere esercizio


Calcolare il volume del sotto-grafico della funzione $f(x,y)=e^x\cos(y-x)$, con un dominio di integrazione $D$ è dato da:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\leq\frac{\pi}{2}\land x\leq y\leq\pi\right\}
\end{gather*}
% Bisogna determinare il segno della funzione per %% TODO ??
Il dominio di integrazione risulta essere un trapezio individuato dai punti $(0,0)$, $(\pi/2, \pi/2)$, $(\pi/2,\pi)$ e $(0,\pi)$. Su questo insieme deve essere valutato il segno della funzione. Un esponenziale è un fattore sempre positivo, quindi il segno della funzione dipende dalla funzione sinusoidale. Bisogna che la funzione sia positiva sull'intero intervallo, altrimenti il calcolo del volume deve essere determinato differentemente, sui domini dov'è positivo e negativo ed in seguito effettuare la differenza. Si determina dov'è che la funzione è positiva:
\begin{gather*}
    f(x,y)\geq0\implies \cos(y-x)\geq0\\
    -\frac{\pi}{2}+2k\pi\leq y-x\leq\frac{\pi}{2}+2k\pi\,\,\forall k\in\mathbb{Z}\\
    x-\frac{\pi}{2}+2k\pi\leq y\leq x+\frac{\pi}{2}+2k\pi\,\,\forall k\in\mathbb{Z}
\end{gather*}
Per rimanere nel dominio di integrazione l'unico valore di $k$ accettato è $k=0$, quindi si ha:
\begin{gather*}
    x-\frac{\pi}{2}\leq y\leq x+\frac{\pi}{2}
\end{gather*}
Considerando l'intervallo di $x$ ammissibili $x\in[0,\pi/2]$, allora l'insieme dei punti dove la funzione è positiva è delimitata dai punti $(0,-\pi/2)$, $(\pi/2,0)$, $(\pi/2,\pi)$ e $(0,\pi/2)$. Considerando l'intersezione con il dominio di integrazione $D$, la funzione positiva nel dominio $D_1$ definito da $(0,0)$, $(\pi/2,\pi/2)$, $(\pi/2,\pi)$ e $(0,\pi/2)$, mentre è negativa nel dominio $D_2$ definito dai punti $(0,\pi/2)$, $(\pi/2,\pi)$ e $(\pi,0)$. Il volume è quindi dato da:
\begin{gather*}
    V=\iint_{D_+}e^x\cos(y-x)\df x\df y-\iint_{D_-}e^x\cos(y-x)\df x\df y
\end{gather*}
I domini di integrazione $D_1$ e $D_2$ sono definiti come:
\begin{gather*}
    D_+=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\leq\frac{\pi}{2}\land x\leq y\leq x+\frac{\pi}{2}\right\}\\
    D_-=\left\{(x,y)\in\mathbb{R}^2\big|0\leq x\leq\frac{\pi}{2}\land x+\frac{\pi}{2}\leq y\leq {\pi}\right\}
\end{gather*}
Sono entrambi normali rispetto alla $x$, quindi si applica la formula:
\begin{gather*}
    I_+=\iint_{D_+}e^x\cos(y-x)\df x\df y=\int_0^{\pi/2}\df x\int_x^{x+\pi/2}e^x\cos(y-x)\df y\\
    I_-=\iint_{D_-}e^x\cos(y-x)\df x\df y=\int_0^{\pi/2}\df x\int_{x+\pi/2}^\pi e^x\cos(y-x)\df y
\end{gather*}
Il fattore $e^x$ è costante rispetto alla $y$ per entrambi gli integrali quindi si può portare fuori dal primo integrale:
\begin{gather*}
    I_+=\int_0^{\pi/2}e^x\df x\int_x^{x+\pi/2}\cos(y-x)\df y=
    \int_0^{\pi/2}e^x\left[\sin(y-x)\right]_x^{x+\pi/2}\df x\\
    I_-=\int_0^{\pi/2}e^x\df x\int_{x+\pi/2}^\pi\cos(y-x)\df y=
    \int_0^{\pi/2}e^x\left[\sin(y-x)\right]_{x+\pi/2}^\pi\df x
\end{gather*}
%% TODO risolvere
\begin{gather*}
    V=\frac{3}{2}e^{\pi/2}-\frac{5}{2}
\end{gather*}


\subsubsection{Trasformazione Regolare di Coordinate}

Questo metodo è analogo al calcolo di un limite a multi-variabile, questo processo permette di semplificare il calcolo dell'integrale, e del dominio di integrazione. 
Si suppone di avere un integrale doppio di una funzione continua $f(x,y)$ in un dominio di integrazione $D$:
\begin{gather*}
    \iint_Df(x,y)\df x\df y
\end{gather*}
Si suppone di avere un dominio di integrazione $D$ ed una funzione $f(x,y)$ eccessivamente complessi. 
Si considera un trasferimento di coordinate, rispetto ad una nuova coppia di coordinate $(u,v)$:
\begin{gather*}
    \begin{cases}
        x=x(u,v)\\
        y=y(u,v)
    \end{cases}
\end{gather*}
Per trasferire il dominio e la funzione si considera la seguente formula: 
\begin{gather*}
    \iint_Df(x,y)\df x\df y\to
    \iint_{D'}f[x(u,v),y(u,v)]|\det J|\df u\df v
\end{gather*}
Dove $J$ è la matrice jacobiana, di cui bisogna calcolare il determinante, questa matrice è del tipo $2\times 2$, ed è definita come: %% TODO cambiare J in math-qualcosa
\begin{gather*}
    J(u,v)=\begin{pmatrix}
        \displaystyle\frac{\partial\strut x}{\partial\strut u}&\displaystyle\frac{\partial\strut x}{\partial\strut v}\\
        \displaystyle\frac{\partial\strut y}{\partial\strut u}&\displaystyle\frac{\partial\strut y}{\partial\strut v}
    \end{pmatrix}
\end{gather*}


Si parla di trasformazione regolare di coordinate se sono soddisfatte tre ipotesi. Se le funzioni $x(u,v)$ e $y(u,v)$ sono funzioni di classe $C$ derivabili sia rispetto ad $x$ che ad $y$ con continuità; se queste funzioni sono invertibili; infine il determinante della matrice jacobiana deve essere diverso da zero. 


Considerando una trasformazione in coordinate polari si ha:
\begin{gather*}
    \begin{cases}
        x=x_0+\rho\cos\theta\\
        y=y_0+\rho\sin\theta
    \end{cases}
\end{gather*}
Dove $x_0$ e $y_0$ sono le coordinate del centro. Quando si considera la trasformazione in coordinate polari, il determinante della matrice jacobiana $\det J$ è sempre uguale a $\rho$. 

\subsubsection*{Esercizi 16/5/25}

Calcolare il seguente integrale doppio:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y
\end{gather*}
Dove il dominio di integrazione $D$ è dato da:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|x\geq0\land y\geq0\land x^2+y^2\leq 1\right\}
\end{gather*}
Questo esercizio si risolve prima in coordinate cartesiane e poi polari. Il dominio è un quarto di cerchio nel primo quadrante centrato nell'origine e di raggio unitario:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y=\int_0^1\df x\int_0^{\sqrt{1-x^2}}(x^2+y^2)\df y
    % =\int_0^1\left[x^2y+\frac{y^3}{3}\right]_0^{\sqrt{1-x^2}}\df x\\
    % \int_0^1x^2\sqrt{1-x^2}+\frac{1}{3}\sqrt{1-x^2}-\frac{1}{3}\sqrt{1-x^2}\df x
\end{gather*}

Si effettua una trasformazione regolare in coordinate polari:
\begin{gather*}
    \begin{cases}
        x=\rho\cos\theta\\
        y=\rho\sin\theta
    \end{cases}
\end{gather*}
Per rimanere nel quarto di circonferenza la variabile $\rho$ deve essere compresa in $[0,1]$, mentre la variabile $\theta$ effettua un quarto di rotazione, quindi deve essere contenuto in $[0,\pi/2]$ 
L'integrale diventa quindi:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y\to
    \iint_{D'}\rho^2(\cancelto{1}{\cos^2\theta+\sin^2\theta})|\det J|\df\theta\df\rho
\end{gather*}
Dove il nuovo dominio di integrazione è $D'=[0,1]\times[0,\pi/2]$: %% TODO img del rettangolo corrispondente in coordinate polari, trasformazione dal quarto di cerchio
\begin{gather*}
    \iint_{D'}\rho^2\cdot\rho\df\theta\df\rho=\int_0^{\pi/2}\df\theta\cdot\int_0^{1}\rho^3\df\rho=
    \left[\theta\right]_0^{\pi/2}\cdot\left[\frac{\rho^4}{4}\right]_0^{1}=\frac{\pi}{8}
\end{gather*}



Si considera la stessa funzione, ma in un dominio di integrazione diverso, corrispondente ad un ottavo di cerchio:
\begin{gather*}
    D=\left\{(x,y)\in\mathbb{R}^2\big|x\geq0\land 0\leq y\leq x\land x^2+y^2\leq 1\right\}
\end{gather*}
Si passa a coordinate polari, quindi si ha un nuovo dominio di integrazione $D'$:
\begin{gather*}
    D'=[0,1]\times\left[0,\frac{\pi}{4}\right]
\end{gather*}
L'integrale diventa:
\begin{gather*}
    \iint_D(x^2+y^2)\df x\df y\to\iint_{D'}\rho^3\df\theta\df\rho=\int_0^{\pi/4}\df\theta\cdot\int_0^{1}\rho^3\df\rho=\frac{\pi}{16}
\end{gather*}

\subsection{Integrali Tripli}

Un integrale triplo, è un integrale su una funzione a tre variabili:
\begin{gather*}
    \iiint_Df(x,y,z)\df x\df y\df z
\end{gather*}
Si analizzeranno integrali a tre variabili su domini definito nel seguente modo:
\begin{gather*}
    D=\left\{(x,y,z)\in\mathbb{R}^3\big|x,y\in B\land \alpha(x,y)\leq z\leq \beta(x,y)\right\}
\end{gather*}
Dove $B$ deve essere normale rispetto all'asse $x$, e le funzioni $\alpha$ e $\beta$ sono continue nel dominio $B$, allora l'integrale si può calcolare come:
\begin{gather*}
    \iint_B\df x\df y\int_{\alpha(x,y)}^{\beta(x,y)}f(x,y,z)\df z
\end{gather*}



%% ESERCIZI
Calcolare l'integrale triplo della seguente funzione:
\begin{gather*}
    \iiint_D\frac{1}{(x+y+z+1)^3}\df x\df y\df z
\end{gather*}
Dove il dominio $D$ è dato da:
\begin{gather*}
    D=\left\{(x,y,z)\in\mathbb{R}^3\big|(x,y)\in T\land0\leq z\leq 1-x-y\right\}
\end{gather*}
%% TODO add immagine 3d
Dove $T$ è il triangolo di vertici $(0,0,0)$, $(1,0,0)$ e $(0,1,0)$. L'integrale diventa:
\begin{gather*}
    \iint_T\df x\df y\int_0^{1-x-y}\frac{1}{(x+y+z+1)^3}\df z=
    -\frac{1}{2}\iint_D\frac{1}{(\cancel{x}+\cancel{y}+1-\bcancel{x}-\bcancel{y}+1)^2}-\frac{1}{(x+y+1)^2}\df x\df y\\
    -\frac{1}{2}\iint_T\left(\frac{1}{4}-\frac{1}{(x+y+1)^2}\right)=-\frac{1}{8}\iint_T\df x\df y+\frac{1}{2}\iint_T\frac{1}{(x+y+1)^2}\df x\df y
\end{gather*}
Il primo integrale rappresenta l'area del triangolo e si può calcolare senza calcolarne l'integrale, il secondo si risolve come un integrale doppio: 
\begin{gather*}
    -\frac{1}{16}+\frac{1}{2}\int_0^1\df y\int_0^{1-x}\frac{1}{(x+y+1)^2}\df y=
    -\frac{1}{16}+\frac{1}{2}\int_0^1\left(-\frac{1}{\cancel{x}+1-\bcancel{x}+1}+\frac{1}{x+1}\right)\df x\\
    -\frac{1}{16}+\frac{1}{2}\left(-\frac{1}{2}+\ln2-\cancelto{0}{\ln1}\right)=\ln\sqrt{2}-\frac{5}{16}
\end{gather*}

\subsection{Integrali Curvilinei}

Per definire il concetto di integrale curvilineo, bisogna definire il concetto di curva nello spazio, un arco di curva regolare, semplice, nel piano $\mathbb{R}^2$ o nello spazio $\mathbb{R}^3$. 
Un arco di curva nel piano non è altro che un'applicazione di una funzione vettoriale $\varphi$ che ha come dominio in intervallo e restituisce un vettore nel piano:
\begin{gather*}
    \varphi:[a;b]\subset\mathbb{R}\to\mathbb{R}^2
\end{gather*}
Per ogni $t$ appartenente al dominio, la funzione restituisce un vettore $\varphi(t)$:
\begin{gather*}
    \varphi(t)=\begin{pmatrix}
        x=x(t)\\
        y=y(t)
    \end{pmatrix}
\end{gather*}
Una curva $\gamma$ è parametrizzata rispetto ad una funzione $\varphi$:
\begin{gather*}
    \gamma=\begin{cases}
        x=x(t)\\y=y(t)
    \end{cases}
\end{gather*}
Un arco di curva nel piano è assegnato quando si assegna una funzione parametrica. 
Solitamente si userà il simbolo $\gamma(A,B)$, dove $A$ e $B$ sono due punti del piano, che ne rappresentano gli estremi: 
\begin{gather*}
    \varphi(a)=(x(a),y(a))=A\\
    \varphi(b)=(x(b),y(b))=B
\end{gather*}
Di solito data una curva vi è dato un orientamento, normalmente si assegna l'orientamento nell'ordine degli estremi, questa curva ha un orientamento da $A$ a $B$. Può essere che i due estremi sono coincidenti, in questo caso si dice che la curva è chiusa, non si tratta più di un arco. 

Un arco di curva è regolare e semplice, se soddisfa tre condizioni:
\begin{itemize}
    \item Deve esistere il vettore tangente: $x(t),y(t)\in C^1([a;b])$
    \item Bisogna verificare l'esistenza del versore tangente: $x'(t)^2+y'(t)^2>0$
    \item Non possono esistere punti doppi: $\forall t_1,t_2\in(a,b)\to \varphi(t_1)\neq\varphi(t_2)$
\end{itemize}
Per la prima condizione, in ogni punto della curva è sempre possibile tracciare il vettore tangente, di componenti $(x'(t),y'(t))$. 
Le prime due condizioni rendono la curva regolare, per essere anche semplice, non devono essere presenti punti ripetuti, ovvero la curva non può incrociare sé stessa. 


Una curva, non regolare, che può essere scomposta in più curve regolari, si dice generalmente regolare. Per calcolare l'integrale curvilineo di una curva generalmente regolare, si sommano gli integrali delle curve regolari scomposte. Questa condizioni devono essere verificate almeno a tratti. 

La lunghezza di una curva $\gamma$ si calcola come:
\begin{gather*}
    \text{length}(\gamma)=\int_a^b\sqrt{x'(t)^2+y'(t)^2}\df t
\end{gather*}

Tutte queste condizioni definite per le curve nel piano, valgono anche per le curve nello spazio, solamente è presente una condizione in più. 
Si considera la curva $\gamma$:
\begin{gather*}
    \gamma:\begin{cases}
        x=t^3\\
        y=t^2
    \end{cases}\,\, t\in[1,3]
\end{gather*}

Per poter disegnare la curva, bisogna convertire l'equazione parametrica in un'equazione cartesian, per poter disegnare l'arco di curva:
\begin{gather*}
    t=x^{1/3}\\
    t=y^{1/2}\\
    y=x^{2/3}
\end{gather*}
Gli estremi della curva sono $A=(1,1)$ e $B=(27,9)$, e l'orientamento è da $A$ a $B$. 
%% TODO add img curva nel piano, estremi ed orientamento
Si calcola la lunghezza della curva usando la formula:
\begin{gather*}
    \text{length}[\gamma(A,B)]=\int_1^3\sqrt{9t^4+4t^2}\df t=\int_1^3t\sqrt{9t^2+4}\df t
\end{gather*}
% Si sostituisce $t=4/9\tan\theta\to\df t=4/9\sec\theta\tan\theta\df\theta$:
% \begin{gather*}
%     \frac{4}{9}\int_{\theta(1)}^{\theta(3)}\tan^2\theta\sec^2\theta\df\theta
% \end{gather*}
% c^2+s^2=1
% 1+t^2=s^2
Considerando il differenziale di $9t^2+4$ si ha:
\begin{gather*}
    \frac{1}{18}\int_1^3(9t^2+4)^{1/2}\df(9t^2+4)=\frac{1}{8}\frac{(9t^2+4)^{2/3}}{18}\bigg|_1^3=\frac{85^{2/3}-13^{2/3}}{27}
\end{gather*}


L'integrale curvilineo di un campo scalare è definito da una funzione $f$ applicata su un sottoinsieme del piano $f:D_f\subseteq\mathbb{R}^2\to\mathbb{R}$. In realtà si parla di campo quando la dimensione del dominio e del codominio coincidono. 
Si definisce una curva $\gamma$ attraverso la quale bisogna calcolare l'integrale di questa funzione. Le componenti della curva $x(t),y(t)$ sono veri campi scalari. 
L'arco di curva deve essere contenuto al volume della funzione $f$: $\gamma\subset D_f$. 
In maniera simbolica, l'integrale lungo una curva $\gamma$ di una funzione $f$ si rappresenta come:
\begin{gather*}
    \int_{\gamma(A,B)}f \df s=\int_a^bf[x(t),y(t)]\sqrt{x'(t)^2+y'(t)^2}\df t
\end{gather*}
Dove $s$ è la variabile curvilinea sulla curva. Questo integrale ha un'interpretazione geometrica importante, per calcolare il baricentro di vari solidi, nello spazio, e aree nel piano. 


Calcolare il seguente integrale:
\begin{gather*}
    I=\int_{\gamma(A,B)}x^2y\df s
\end{gather*}
Dove la curva $\gamma$ è il minore dei due archi di curva di equazione cartesiana $x^2+y^2=9$ delimitata dai punti $A=(3,0)$ e $B=(-3/2,3\sqrt{3}/2)$. 
Il minore arco è quello presente nel primo e secondo quadrante. L'equazione parametrica della curva è:
\begin{gather*}
    \gamma:\begin{cases}
        x(t):3\cos t\\
        y(t):3\sin t
    \end{cases}\,\, t\in[0,2\pi/3]
\end{gather*}
Per calcolare gli intervalli si può utilizzare l'arcocoseno, poiché l'intervallo è compreso tra $0$ e $\pi$, mentre non è possibile utilizzare l'arcoseno, poiché si trova al di fuori del suo dominio di $[-\pi/2,\pi/2]$. Quindi è preferibile invertire la funzione che si trova già nel suo dominio di applicazione, oppure usare simmetrie delle funzioni. 
Si risolve l'integrale applicando la formula:
\begin{gather*}
    I=\int_0^{2\pi/3}9\cos^2 t\cdot3\sin t\cdot3\sqrt{\sin^2t+\cos^2t}\df t=
    81\int_0^{2\pi/3}\sin t\cos^2t\df t\\
    I=-27\int_0^{2\pi/3}\sin t\df(3\cos^2t)=-27\cos^3t\bigg|_0^{2\pi/3}=\frac{243}{8}
\end{gather*}


Calcolare l'integrale curvilineo:
\begin{gather*}
    I=\int_{\gamma(A,B)}xy\df s
\end{gather*}
Data la seguente curva, da $A=(1,1)$ a $B=(0,1)$:
%% TODO img curva (1,1) -- (0,1)
Questa curva si può parametrizzare in diversi modi, si preferisce la parametrizzazione più utile:
\begin{gather*}
    \gamma:\begin{cases}
        x=t\\y=1
    \end{cases}\,\, t\in[0,1]
\end{gather*}
La parametrizzazione effettuata è di verso opposto all'orientamento proposto, assegnato alla curva. Tuttavia si ottiene lo stesso risultato anche utilizzando la parametrizzazione inversa. L'integrale curvilineo non dipende dall'orientamento, mentre l'integrale curvilineo dei campi vettoriali dipende dall'orientamento, quindi il risultato sarebbe diverso. 
Si calcola l'integrale usando questa parametrizzazione:
\begin{gather*}
    I=\int_{\gamma}xy\df s=\int_0^1t\df t=\frac{1}{2}
\end{gather*}
Si considerano parametrizzazioni equivalenti per dimostrare che l'integrale curvilineo non dipende dall'orientamento:
\begin{gather*}
    \delta:\begin{cases}
        x=1-t\\y=1
    \end{cases}\,\,t\in[0,1]\\
    I=\int_{\delta}xy\df s=\int_0^1(1-t)\df t=\frac{1}{2}
\end{gather*}
Queste due parametrizzazioni si dicono equivalenti. 



Risolvere il seguente integrale curvilineo lungo una curva $\gamma$:
\begin{gather*}
    \int_\gamma(2x+y)df s
\end{gather*}
Dove la curva è il più piccolo arco di curva di equazione cartesiana:
\begin{gather*}
    x^2+y^2=25
\end{gather*}
Delimitato dai punti $A=(3,4)$ e $B=(4,3)$. L'equazione determina una circonferenza di raggio $r=5$, i due punti si trovano entrambi nel primo quadrante, quindi l'arco più piccolo si trova solamente nel primo quadrante. 
%% TODO add img curva
Si orienta in modo che vada dal punto $A$ al punto $B$. Si parametrizza la curva:
\begin{gather*}
    \gamma:\begin{cases}
        x=5\cos t\\y=5\sin t
    \end{cases}\,\,t\in[t_B=\arccos(4/5),t_A=\arcsin(4/5)]
\end{gather*}
Risolvendo ora l'integrale si ha:
\begin{gather*}
    \int_\gamma(2x+y)df s=5\int_{t_B}^{t_A}(10\cos t+5\sin t\df t)\sqrt{\sin^2t+\cos^2t}\df t=25\int_{t_B}^{t_A}2\cos t+\sin t\df t\\
    50\sin t-25\cos t\bigg|_{t_B}^{t_A}=50(\sin t_A-\sin t_B)-25(\cos t_A-\cos t_B)\\
    50(\sin(\arcsin(4/5))-\sin(\arcsin(3/5)))-25(\cos(\arccos(3/5))-\cos(\arccos(4/5)))=15
\end{gather*}

Per poter cambiare l'orientamento è possibile utilizzare la parametrizzazione $t=t_A+t_B-s$, usando la nuova variabile $s$, in questo modo è possibile seguire il senso della curva, se fosse richiesto
\begin{gather*}
    \gamma:\begin{cases}
        x=5\cos(t_A+t_B-s)\\y=5\sin(t_A+t_B-s)
    \end{cases}\,\, s\in[t_B,t_A]
\end{gather*}

\subsubsection{Integrali Curvilinei di Campi Vettoriali}

Fino ad ora si è trattato di funzioni a più variabili, con codominio l'insieme dei reali, ma è possibile utilizzare funzioni ad immagine a più variabile per effettuare integrali curvilinei. Si definisce campo vettoriale, una funzione il cuo dominio e codominio hanno la stessa dimensione. 
Si considera un campo vettoriale $\vec{F}:D_{\vec{F}}\subseteq\mathbb{R}^2\to\mathbb{R}^2$. Questa funzione può esprimere come:
\begin{gather*}
    (x,y)\to\vec{F}(x,y)=\begin{pmatrix}
        X(x,y)\\Y(x,y)
    \end{pmatrix}
\end{gather*}
Si considera una curva definite nel dominio del campo vettoriale $\gamma\in D_{\vec{F}}$:
\begin{gather*}
    \gamma:\begin{cases}
        x=x(t)\\y=y(t)
    \end{cases}\,\, t\in[t_A,t_B]
\end{gather*}
La curva ha anche un orientamento, ed in questo caso è rilevante per individuare la soluzione corretta. Nell'integrale curvilineo si indica per la curva anche i punti di partenza e di arrivo:
\begin{gather*}
    \int_{\gamma(A,B)}\vec{F}\cdot\df \vec{\alpha}=\int_{\gamma(A,B)}X(x,y)\df x+Y(x,y)\df y
\end{gather*}
In generale l'integrale di un campo vettoriale si rappresenta come il prodotto scalare tra il campo ed il differenziale del vettore direzione. 
Spesso la somma mostrata nel secondo integrale si chiama forma differenziale, del prodotto scalare del campo vettoriale. 
La formula per calcolare questo integrale è data da:
\begin{gather*}
    \int_{\gamma(A,B)}\vec{F}\cdot\df \vec{\alpha}=
    \pm\int_{t_A}^{t_B}\left[X(x(t),y(t))\cdot x'(t)+Y(x(t),y(t))\cdot y'(t)\right]\df t    
\end{gather*}
La scelta del segno dell'integrale dipende dall'orientamento della curva. Se l'orientamento scelto dalla parametrizzazione è opposto a quello richiesto bisogna invertire il segno, se è concorde allora bisogna mantenere il segno positivo. 



%% ESERCIZIO

Considerare il seguente campo vettoriale:
\begin{gather*}
    \vec{F}=\begin{pmatrix}
        2x+y\\y
    \end{pmatrix}
\end{gather*}
Calcolare l'integrale curvilineo lungo l'arco di curva $\gamma(A,B)$, di equazione cartesiana $x^2+y^2=4$, tra i punti $A=(2,0)$ e $B(0,2)$:
\begin{gather*}
    \gamma:\begin{cases}
        x=2\cos t\\y=2\sin t
    \end{cases}\,\, t\in[0,\pi/2]
\end{gather*}
Scegliendo questa parametrizzazione si sta andando in senso antiorario, in seguito bisogna mettere a confronto con l'orientamento della curva. Andando da $A$ a $B$ si va nello stesso senso della curva, quindi si sceglie il segno positivo. Si utilizza ora la formula:
\begin{gather*}
    \int_{\gamma(A,B)}\vec{F}\cdot\df\vec{\alpha}=\int_{0}^{\pi/2}(4\cos t+2\sin t)\cdot(-2\sin t)+2\sin t\cdot2\cos t\df t\\
    \int_{0}^{\pi/2}(4\cos t+2\sin t)\cdot(-2\sin t)+2\sin t\cdot2\cos t\df t=
    2\int_0^{\pi/2}{-4\cos t\sin t}-2\sin^2t+2\sin t\cos t\df t\\
    2\int_0^{\pi/2}-2\cos t\sin t-2\sin^2t\df t=
    \int_0^{\pi/2}(2\cos2t-2-2\sin2t)\df t\\
    \sin 2t\bigg|_0^{\pi/2}-\pi+\cos2t\bigg|_0^{\pi/2}=0-0-\pi-1+1
\end{gather*}
%% TODO rifare ?? -> \pi-2, il primo addendo diventa -2\sin^2t



Calcolare l'integrale curvilineo di questa forma differenziabile lungo la curva $\gamma(A,B)$:
\begin{gather*}
    \int_{\gamma(A,B)}(2x+y)\df x+y\df y
\end{gather*}
Dove $\gamma$ è l'arco di parabola di equazione cartesiana $x=2-x^2/2$ e $A=(2,0)$ e $B=(0,2)$. Si rappresenta in forma parametrica:
\begin{gather*}
    \gamma:\begin{cases}
        x=t\\y=\displaystyle\frac{\strut 4-t^2}{\strut2}
    \end{cases}\,\, t\in[0,2]
\end{gather*}
Questa parametrizzazione è di orientamento inverso rispetto alla curva, quindi si inverte il segno nella formula:
\begin{gather*}
    \int_{\gamma(A,B)}(2x+y)\df x+y\df y=-\int_0^22t+\frac{4-t^2}{2}+\left(\frac{4-t^2}{2}\right)\cdot(-t)\df t\\
    -\int_0^2\cancel{2t}+2-\frac{t^2}{2}-\bcancel{2t}+\frac{t^3}{2}\df t=-\int_0^22-\frac{t^2}{2}+\frac{t^3}{2}\df t=-\left[2t-\frac{t^3}{6}+\frac{t^4}{8}\right]_0^2\\
    -4+\frac{4}{3}-2=\frac{4-18}{3}=-\frac{14}{3}
\end{gather*}

\subsubsection{Campi Vettoriali Conservativi}

Si è già utilizzata la formula per calcolare integrali curvilinei su campi vettoriali, se il campo vettoriale è conservativo, il calcolo di questo integrale è considerevolmente semplificato. 

Un campo vettoriale $\vec{F}$:
\begin{gather*}
    \vec{F}(x,y)=\begin{pmatrix}
        X(x,y)\\Y(x,y)
    \end{pmatrix}
\end{gather*}
Si dice conservativo in un insieme $S\subseteq D_{\vec{F}}\subseteq\mathbb{R}^2$, se rispetta delle condizioni. 
Se esiste una funzione scalare, $\exists\varphi: S\to\mathbb{R}$, definita in $S$ e valore nel dominio reale, tale che per ogni punto dell'insieme $S$ si ha:
\begin{gather*}
    \forall(x,y)\in\mathbb{R}^2\to\displaystyle\frac{\partial \varphi}{\partial x}(x,y)=X(x,y)\land\frac{\partial \varphi}{\partial y}(x,y)=Y(x,y)
\end{gather*}
Spesso si scrive in maniera simbolico, definendo il gradiente $\nabla$ della funzione $\varphi$:
\begin{gather*}
    \vec{\nabla}\varphi(x,y)=\left(\frac{\partial\varphi}{\partial x}(x,y),\,\frac{\partial\varphi}{\partial y}(x,y)\right)
\end{gather*}
Tale che:
\begin{gather*}
    \vec{\nabla}\varphi(x,y)=\vec{F}(x,y)
\end{gather*}


%% TEOREMA

Supponendo di avere un campo conservativo $\vec{F}$, conservativo in un sottoinsieme $S\subseteq D_{\vec{F}}$ e sia $\varphi:S\to\mathbb{R}$, il suo potenziale. Da notare che è possibile definire un numero infinito di potenziali, è sufficiente infatti sommare una costante generica $c$, e la funzione risultante $\varphi(x,y)+c$ è anch'essa un potenziale. 
Sia $\gamma(A,B)\subset S$, una curva regolare, allora l'integrale curvilineo lungo la curva $\gamma$ del campo vettoriale è dato dalla seguente:
\begin{gather*}
    \int_{\gamma(A,B)}\vec{F}\cdot\df\vec{\alpha}=\varphi(B)-\varphi(A)
\end{gather*}
L'integrale curvilineo in $S$ su una curva in $S$, di un campo vettoriale conservativo non dipende dalla curva, ma solo dai suoi estremi. Date due curve qualsiasi $\gamma(A,B)$ e $\delta(A,B)$, il loro integrale curvilineo su un campo vettoriale conservativo è uguale. 
Se il punto iniziale e finale coincidono, allora l'integrale è nullo, la circuitazione su una qualsiasi curva chiusa di un campo vettoriale conservativo è sempre nulla:
\begin{gather*}
    \oint_{\gamma}\vec{F}\cdot\df\vec{\alpha}=0
\end{gather*}

Inoltre se un campo è conservativo, ma non si ha il suo potenziale, per calcolare l'integrale curvilineo è possibile scegliere una curva il più semplice possibile con gli stessi estremi dell'originale, in modo da semplificare notevolmente il calcolo. 

%% TEOREMA: condizioni sufficienti che il campo sia conservativo, condizioni su S e su \vec{F}

Le condizioni sufficienti affinché il campo vettoriale $\vec{F}$ sia conservativo in $S\subseteq D_{\vec{F}}$ sono:
\begin{enumerate}
    \item $\forall(x,y)\in S\to\displaystyle\frac{\partial X}{\partial y}(x,y)=\frac{\partial Y}{\partial x}(x,y)$
    \item $S$ è un'insieme semplicemente connesso. 
\end{enumerate}
Per la prima condizione le derivate miste devono essere uguali. Se è soddisfatta la prima condizione il campo vettoriale si dice chiuso. 
Un insieme $S\subseteq\mathbb{R}^2$ si dice semplicemente connesso, se una qualunque curva chiusa $\gamma$ contenuta in $S$ è la frontiera di un sottoinsieme interamente contenuto in $S$. Ovvero l'insieme $S$ non presenta ``buchi''. 





%% ESEMPIO

Considerare il seguente campo vettoriale:
\begin{gather*}
    \vec{F}=\begin{pmatrix}
        \displaystyle\frac{\strut-y}{\strut x^2+y^2}\\ \displaystyle\frac{\strut x}{\strut x^2+y^2}
    \end{pmatrix}
\end{gather*}
Determinare se è conservativa nell'insieme $\mathbb{R}^2\setminus\left\{(0,0)\right\}$:
\begin{gather*}
    \frac{\partial}{\partial y}\frac{\strut-y}{\strut x^2+y^2}=\frac{-x^2-y^2-2y(-y)}{(x^2+y^2)^2}=\frac{y^2-x^2}{(x^2+y^2)^2}\\
    \frac{\partial}{\partial x}\frac{\strut x}{\strut x^2+y^2}=\frac{x^2+y^2-x(2x)}{(x^2+y^2)^2}=\frac{y^2-x^2}{(x^2+y^2)^2}
\end{gather*}
Il campo vettoriale è chiuso, ma l'insieme $\mathbb{R}^2\setminus\left\{(0,0)\right\}$ non è semplicemente connesso, avendo un buco in $(0,0)$. 
Dato un insieme $S$:
\begin{gather*}
    S=\left\{(x,y)\in\mathbb{R}^2\big|x>1\right\}
\end{gather*}
Allora in questo insieme il campo vettoriale è conservativo, poiché non contiene il buco in $(0,0)$. 



%% ESERCIZI

Calcolare la circuitazione lungo la curva chiusa $\gamma$ di un campo vettoriale $\vec{F}$, lo stesso dell'esercizio precedente. 
\begin{gather*}
    \vec{F}=\begin{pmatrix}
        \displaystyle\frac{\strut-y}{\strut x^2+y^2}\\ \displaystyle\frac{\strut x}{\strut x^2+y^2}
    \end{pmatrix}
\end{gather*}
E $\gamma$ è la circonferenza, di equazione $(x-1)^2+(y+1)^2=1$, percorsa in senso antiorario. La circuitazione è nulla, essendo l'insieme di definizione della circonferenza un insieme semplicemente connesso, non contiene l'unico punto di discontinuità in $(0,0)$. Si può scegliere un qualsiasi insieme contenente la circonferenza $S$, si considera il sottoinsieme che rappresenta il quarto quadrante:
\begin{gather*}
    S=\left\{(x,y)\in\mathbb{R}^2\big| x>0\land y<0\right\}\cup\left\{(0,-1),(1,0)\right\}\subset\mathbb{R}^2\setminus\left\{(0,0)\right\}
\end{gather*}

Considerare ora come curva una circonferenza di equazione $x^2+y^2=1$, non è possibile identificare un sottoinsieme contenente la curva semplicemente connesso, quindi non si può applicare la proprietà dei campi vettoriali conservativi. 
Si parametrizza la curva:
\begin{gather*}
    \gamma:\begin{cases}
        x=\cos t\\y=\sin t
    \end{cases}\,\, t\in[0,2\pi]
\end{gather*}
La parametrizzazione è concorde con il senso della curva, quindi si mantiene il segno positivo:
\begin{gather*}
    \int_{\gamma}\vec{F}\cdot\df\vec{\alpha}=\int_0^{2\pi}-\sin t(-\sin t)+\cos t(\cos t)\df t=\int_0^{2\pi}\cos^2 t+\sin^2 t\df t=2\pi\neq0
\end{gather*}


Calcolare il seguente integrale:
\begin{gather*}
    \int_{\gamma(A,B)}(2x+5y^3)\df x+(15xy^2+2y)\df y
\end{gather*}
Dove $\gamma$ è il minore dei due archi di curva, di equazione cartesiana $(x-1)^2+(y-1)^2=1$, di estremi $A=(1,0)$ e $B=(2,1)$. 

Si controlla se il campo è conservativo:
\begin{gather*}
    \frac{\partial X}{\partial y}=15y^2=\frac{\partial Y}{\partial x}
\end{gather*}
Il dominio del campo vettoriale è anche sicuramente semplicemente connesso. A meno che non venga esplicitamente espresso che vada calcolato sulla curva indicata, si può calcolare su una traiettoria qualsiasi, oppure calcolando il potenziale. 
Il calcolo più semplice è scegliere una traiettoria più semplice. Invece di spostare il punto materiale sull'arco di circonferenza, si considerano due segmenti $\overline{AC}$ e $\overline{CB}$, dove $C=(2,0)$. I due segmenti vengono chiamati $\gamma_1$ e $\gamma_2$. L'integrale si divide quindi usando la proprietà additiva:
\begin{gather*}
    \int_{\gamma(A,B)}\vec{F}\cdot\df\vec{\alpha}=
    \overbrace{\int_{\gamma_1(A,C)}\vec{F}\cdot\df\vec{\alpha}}^{I_1}+
    \underbrace{\int_{\gamma_2(C,B)}\vec{F}\cdot\df\vec{\alpha}}_{I_2}
\end{gather*}
Si parametrizzano le due curve:
\begin{gather*}
    \gamma_1:\begin{cases}
        x=t\\y=0
    \end{cases}\,\, t\in[1,2]\\
    \gamma_2:\begin{cases}
        x=2\\y=t
    \end{cases}\,\, t\in[0,1]
\end{gather*}
Entrambe le parametrizzazioni sono concordi con l'orientamento. Si calcolano quindi i due integrali:
\begin{gather*}
    I_1=\int_1^22t\df t=t^2\bigg|_1^2=3\\
    I_2=\int_0^1 30t^2+2t\df t=10t^3+t^2\bigg|_0^1=11\\
    I=I_1+I_2=14
\end{gather*}


Si calcola ora mediante il potenziale $\varphi$:
\begin{gather*}
    \varphi(x,y)=\int X(x,y)\df x=\int2x+5y^3\df x=x^2+5xy^3+\alpha(y)\\
    \frac{\partial}{\partial y}(5xy^3+x^2+\alpha(y))=\cancel{15xy^2}+\alpha'(y)=Y(x,y)=\bcancel{15xy^2}+2y\\
    \alpha'(y)=2y\to\alpha(y)=y^2+c\\
    \varphi(x,y)=5xy^3+x^2+y^2+c
\end{gather*}
Si considera $c=0$ per semplicità, si calcola ora l'integrale:
\begin{gather*}
    I=\varphi(2,1)-\varphi(1,0)=5\cdot2+4+1-1=14
\end{gather*}


%% TODO casa (?)
Calcolare il seguente integrale:
\begin{gather*}
    \int_{\gamma(A,B)}(2xy+y^2+2xy^2)\df x+(x^2+2xy+2x^y)\df y
\end{gather*}
Dove $\gamma$ è l'arco minore della circonferenza $(x-1)^2+y^2=1$, di estremi $A=(0,0)$ e $B=(1,-1)$. 


\clearpage

\end{document}